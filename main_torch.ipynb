{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# load data and split into train and test sets\n",
    "from load_data import sim_arr\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# reshape from batch, height, width, channel, to batch, channel, height, width\n",
    "sim_arr_transformed = sim_arr.reshape(\n",
    "    sim_arr.shape[0], sim_arr.shape[3], sim_arr.shape[1], sim_arr.shape[2])\n",
    "train_set, test_set = train_test_split(\n",
    "    sim_arr_transformed, test_size=0.2, random_state=42)\n",
    "\n",
    "# convert to tensor\n",
    "train_set = torch.tensor(train_set, dtype=torch.float32)\n",
    "test_set = torch.tensor(test_set, dtype=torch.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-15 06:21:33,333] Using an existing study with name 'autoencoder_torch3' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'kernel_size_0': 9, 'kernel_size_1': 10, 'kernel_size_2': 13, 'kernel_size_3': 4, 'kernel_size_4': 11, 'dilation_0': 3, 'dilation_1': 2, 'dilation_2': 4, 'dilation_3': 4, 'dilation_4': 2, 'activation_0': 'nn.SELU', 'activation_1': 'nn.Softplus', 'activation_2': 'nn.Tanh', 'activation_3': 'nn.Softplus', 'activation_4': 'nn.Tanh'}\n",
      "Best value: 0.3946284880628809\n"
     ]
    }
   ],
   "source": [
    "from AE_torch import Autoencoder\n",
    "from search_space import search_space\n",
    "import optuna\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    #clear clutter from previous runs\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # define search space\n",
    "    num_layers, poolsize, channels, kernel_sizes, dilations, activations = search_space(trial, input_dim=3, output_dim=3)\n",
    "\n",
    "    # define model\n",
    "    model = Autoencoder(num_layers=num_layers,\n",
    "                        poolsize=poolsize,\n",
    "                        channels=channels,\n",
    "                        kernel_sizes=kernel_sizes,\n",
    "                        dilations=dilations,\n",
    "                        activations=activations,\n",
    "                        epochs=100,\n",
    "                        batch_size=32,\n",
    "                        learning_rate=1e-3,\n",
    "                        data=train_set)\n",
    "    \n",
    "    # train model with k-fold cross validation\n",
    "    val_losses = model.cross_val()\n",
    "    val_loss = sum(val_losses) / len(val_losses)\n",
    "    print(\"Validation loss:\", val_loss)\n",
    "    return val_loss\n",
    "\n",
    "# delete the study\n",
    "#optuna.delete_study(study_name=\"autoencoder_torch1\", storage=\"sqlite:///autoencoder.db\")\n",
    "\n",
    "# define study\n",
    "study = optuna.create_study(direction=\"minimize\",\n",
    "                            pruner=optuna.pruners.HyperbandPruner(),\n",
    "                            study_name=\"autoencoder_torch3\",\n",
    "                            storage=\"sqlite:///autoencoder.db\",\n",
    "                            load_if_exists=True)\n",
    "\n",
    "study.optimize(objective, n_trials=0)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(\"Best hyperparameters:\", str(best_params))\n",
    "print(\"Best value:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model with best hyperparameters\n",
    "num_layers, poolsize, channels, kernel_sizes, dilations, activations = search_space(\n",
    "    study.best_trial, input_dim=3, output_dim=3)\n",
    "\n",
    "model = Autoencoder(num_layers=num_layers,\n",
    "                    poolsize=poolsize,\n",
    "                    channels=channels,\n",
    "                    kernel_sizes=kernel_sizes,\n",
    "                    dilations=dilations,\n",
    "                    activations=activations,\n",
    "                    epochs=100,\n",
    "                    batch_size=32, \n",
    "                    learning_rate=1e-3,\n",
    "                    data=train_set)\n",
    "\n",
    "#model.cross_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import numpy as np\\nimport matplotlib.pyplot as plt\\n\\ni = np.random.randint(0, len(test_set))\\nin_sim = test_set[i: i + 1]\\nin_sim = in_sim.to(\\'cuda:0\\')\\nout_sim = model(in_sim)\\nin_sim = in_sim.detach().to(\\'cpu\\').numpy()\\nin_sim = in_sim.reshape(in_sim.shape[0], in_sim.shape[2], in_sim.shape[3], in_sim.shape[1])\\nout_sim = out_sim.detach().to(\\'cpu\\').numpy()\\nout_sim = out_sim.reshape(out_sim.shape[0], out_sim.shape[2], out_sim.shape[3], out_sim.shape[1])\\nfig, ax = plt.subplots(nrows=1, ncols=2)\\nax[0].imshow(in_sim[0, ..., 2], vmin=-1, vmax=1, cmap=\"RdBu\")\\nax[1].imshow(out_sim[0, ..., 2], vmin=-1, vmax=1, cmap=\"RdBu\")'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "i = np.random.randint(0, len(test_set))\n",
    "in_sim = test_set[i: i + 1]\n",
    "in_sim = in_sim.to('cuda:0')\n",
    "out_sim = model(in_sim)\n",
    "in_sim = in_sim.detach().to('cpu').numpy()\n",
    "in_sim = in_sim.reshape(in_sim.shape[0], in_sim.shape[2], in_sim.shape[3], in_sim.shape[1])\n",
    "out_sim = out_sim.detach().to('cpu').numpy()\n",
    "out_sim = out_sim.reshape(out_sim.shape[0], out_sim.shape[2], out_sim.shape[3], out_sim.shape[1])\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "ax[0].imshow(in_sim[0, ..., 2], vmin=-1, vmax=1, cmap=\"RdBu\")\n",
    "ax[1].imshow(out_sim[0, ..., 2], vmin=-1, vmax=1, cmap=\"RdBu\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder(\n",
      "  (encoder): Encoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): Conv2dSame(3, 11, kernel_size=(9, 9), stride=(1, 1), dilation=(3, 3))\n",
      "      (1): SELU()\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "      (3): Conv2dSame(11, 10, kernel_size=(10, 10), stride=(1, 1), dilation=(2, 2))\n",
      "      (4): Softplus(beta=1.0, threshold=20.0)\n",
      "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "      (6): Conv2dSame(10, 12, kernel_size=(13, 13), stride=(1, 1), dilation=(4, 4))\n",
      "      (7): Tanh()\n",
      "      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "      (9): Conv2dSame(12, 10, kernel_size=(4, 4), stride=(1, 1), dilation=(4, 4))\n",
      "      (10): Softplus(beta=1.0, threshold=20.0)\n",
      "      (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "      (12): Conv2dSame(10, 3, kernel_size=(11, 11), stride=(1, 1), dilation=(2, 2))\n",
      "      (13): Tanh()\n",
      "      (14): MaxPool2d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=True)\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): MaxUnpool2d(kernel_size=(5, 5), stride=(5, 5), padding=(0, 0))\n",
      "      (1): Tanh()\n",
      "      (2): Conv2dSame(3, 10, kernel_size=(11, 11), stride=(1, 1), dilation=(2, 2))\n",
      "      (3): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
      "      (4): Softplus(beta=1.0, threshold=20.0)\n",
      "      (5): Conv2dSame(10, 12, kernel_size=(4, 4), stride=(1, 1), dilation=(4, 4))\n",
      "      (6): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
      "      (7): Tanh()\n",
      "      (8): Conv2dSame(12, 10, kernel_size=(13, 13), stride=(1, 1), dilation=(4, 4))\n",
      "      (9): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
      "      (10): Softplus(beta=1.0, threshold=20.0)\n",
      "      (11): Conv2dSame(10, 11, kernel_size=(10, 10), stride=(1, 1), dilation=(2, 2))\n",
      "      (12): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
      "      (13): SELU()\n",
      "      (14): Conv2dSame(11, 3, kernel_size=(9, 9), stride=(1, 1), dilation=(3, 3))\n",
      "    )\n",
      "  )\n",
      "  (criterion): MSELoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# summarize the model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "(3, 1, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. KMeans expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 181\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28mset\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    176\u001b[0m model \u001b[38;5;241m=\u001b[39m JointAutoencoder(model\u001b[38;5;241m.\u001b[39mencoder,\n\u001b[1;32m    177\u001b[0m                          model\u001b[38;5;241m.\u001b[39mdecoder,\n\u001b[1;32m    178\u001b[0m                          KmeansLayer(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m),\n\u001b[1;32m    179\u001b[0m                          \u001b[38;5;28mset\u001b[39m)\n\u001b[0;32m--> 181\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_val\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[50], line 151\u001b[0m, in \u001b[0;36mJointAutoencoder.cross_val\u001b[0;34m(self, n_splits)\u001b[0m\n\u001b[1;32m    140\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata,\n\u001b[1;32m    142\u001b[0m     sampler\u001b[38;5;241m=\u001b[39mtrain_sampler,\n\u001b[1;32m    143\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m    144\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[1;32m    145\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata,\n\u001b[1;32m    147\u001b[0m     sampler\u001b[38;5;241m=\u001b[39mval_sampler,\n\u001b[1;32m    148\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m    149\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m--> 151\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_model(val_loader)\n\u001b[1;32m    153\u001b[0m val_losses\u001b[38;5;241m.\u001b[39mappend(val_loss)\n",
      "Cell \u001b[0;32mIn[50], line 99\u001b[0m, in \u001b[0;36mJointAutoencoder.train_model\u001b[0;34m(self, dataloader, device)\u001b[0m\n\u001b[1;32m     97\u001b[0m batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 99\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[50], line 77\u001b[0m, in \u001b[0;36mJointAutoencoder._get_loss\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculate the loss function.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     x_hat, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     reconstruction_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_reconstruction_loss(x, x_hat)\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/hyper-param-optim-4-vector-field-clustering/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/hyper-param-optim-4-vector-field-clustering/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[50], line 58\u001b[0m, in \u001b[0;36mJointAutoencoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     56\u001b[0m     feature_array \u001b[38;5;241m=\u001b[39m feature_array[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     57\u001b[0m     feature_array \u001b[38;5;241m=\u001b[39m feature_array\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m---> 58\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcluster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(x, indices_list)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, labels\n",
      "File \u001b[0;32m~/hyper-param-optim-4-vector-field-clustering/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/hyper-param-optim-4-vector-field-clustering/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[50], line 17\u001b[0m, in \u001b[0;36mKmeansLayer.forward\u001b[0;34m(self, feature_array)\u001b[0m\n\u001b[1;32m     15\u001b[0m kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(feature_array\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mkmeans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m kmeans\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[0;32m~/hyper-param-optim-4-vector-field-clustering/.venv/lib/python3.9/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/hyper-param-optim-4-vector-field-clustering/.venv/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:1481\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1453\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1454\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1455\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[1;32m   1456\u001b[0m \n\u001b[1;32m   1457\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1480\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1481\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1490\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params_vs_input(X)\n\u001b[1;32m   1492\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n",
      "File \u001b[0;32m~/hyper-param-optim-4-vector-field-clustering/.venv/lib/python3.9/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/hyper-param-optim-4-vector-field-clustering/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py:1043\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1039\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1041\u001b[0m     )\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m-> 1043\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1045\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1046\u001b[0m     )\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m   1049\u001b[0m     _assert_all_finite(\n\u001b[1;32m   1050\u001b[0m         array,\n\u001b[1;32m   1051\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m   1052\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m   1053\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1054\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. KMeans expected <= 2."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "class KmeansLayer(torch.nn.Module):\n",
    "    \"\"\"Kmeans layer that inherits from PyTorch's nn.Module class.\"\"\"\n",
    "\n",
    "    def __init__(self, n_clusters):\n",
    "        super(KmeansLayer, self).__init__()\n",
    "        self.n_clusters = n_clusters\n",
    "\n",
    "    def forward(self, feature_array):\n",
    "        \"\"\"Forward pass through the K-means layer.\"\"\"\n",
    "        # fit K-means model\n",
    "        kmeans = KMeans(n_clusters=self.n_clusters, random_state=42)\n",
    "        print(feature_array.shape)\n",
    "        kmeans.fit(feature_array)\n",
    "\n",
    "        return kmeans.labels_\n",
    "    \n",
    "    def _get_loss(self, feature_array, labels):\n",
    "        \"\"\"Calculate the silhouette score.\"\"\"\n",
    "        return silhouette_score(feature_array, labels)\n",
    "\n",
    "\n",
    "class Classifier(torch.nn.Module):\n",
    "    \"\"\"Classifier that inherits from PyTorch's nn.Module class.\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the classifier.\"\"\"\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class JointAutoencoder(torch.nn.Module):\n",
    "    def __init__(self, encoder, decoder, cluster, full_set):\n",
    "        super(JointAutoencoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.cluster = cluster\n",
    "        self.full_set = full_set\n",
    "        self.epochs = 100\n",
    "        self.batch_size = 64\n",
    "        self.data = train_set\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the ClusterAutoencoder.\"\"\"\n",
    "        x, indices_list = self.encoder(x)\n",
    "        with torch.no_grad():\n",
    "            feature_array, _ = self.encoder(self.full_set)\n",
    "            features = features.view(features.size(0), -1)\n",
    "            feature_array = feature_array.cpu().detach().numpy()\n",
    "        labels = self.cluster(feature_array)\n",
    "        x = self.decoder(x, indices_list)\n",
    "\n",
    "        return x, labels\n",
    "\n",
    "    def _get_reconstruction_loss(self, x, x_hat):\n",
    "        \"\"\"Calculate the reconstruction loss.\"\"\"\n",
    "        return torch.nn.functional.mse_loss(x_hat, x, reduction='mean')\n",
    "\n",
    "    def _get_cluster_loss(self, x, cluster_centers):\n",
    "        \"\"\"Calculate the clustering loss.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def _get_weighted_mse_loss(self, x, cluster_centers):\n",
    "        pass\n",
    "        \n",
    "\n",
    "    def _get_loss(self, x):\n",
    "        \"\"\"Calculate the loss function.\"\"\"\n",
    "        x_hat, labels = self(x)\n",
    "        reconstruction_loss = self._get_reconstruction_loss(x, x_hat)\n",
    "        with torch.no_grad():\n",
    "            feature_array, _ = self.encoder(self.full_set)\n",
    "            features = features.view(features.size(0), -1)\n",
    "            feature_array = feature_array.cpu().detach().numpy()\n",
    "        cluster_loss = self.cluster._get_loss(feature_array, labels)\n",
    "        return reconstruction_loss + cluster_loss\n",
    "\n",
    "    def train_model(self, dataloader, device=torch.device('cuda:0')):\n",
    "        \"\"\"Train the autoencoder.\"\"\"\n",
    "        self.to(device)\n",
    "        self.train()\n",
    "\n",
    "        best_loss = float('inf')\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for batch in dataloader:\n",
    "                batch = batch.to(device)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self._get_loss(batch)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                running_loss += loss.item() * batch.size(0)\n",
    "            epoch_loss = running_loss / len(dataloader)\n",
    "            print(f\"Epoch {epoch+1}/{self.epochs} Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "            # Early stopping\n",
    "            if epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                epochs_no_improve = 0\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                if epochs_no_improve == 5:\n",
    "                    print(f\"Early stopping after {epoch+1} epochs.\")\n",
    "                    break\n",
    "\n",
    "    def evaluate_model(self, dataloader, device=torch.device('cuda:0')):\n",
    "        \"\"\"Evaluate the autoencoder.\"\"\"\n",
    "        self.to(device)\n",
    "        self.eval()\n",
    "        total_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                batch = batch.to(device)\n",
    "                loss = self._get_loss(batch)\n",
    "                total_loss += loss.item() * batch.size(0)\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Validation Loss: {avg_loss:.4f}\")\n",
    "        return avg_loss\n",
    "\n",
    "    def cross_val(self, n_splits=5):\n",
    "        \"\"\"Perform cross-validation on the autoencoder.\"\"\"\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "        val_losses = []\n",
    "        for fold, (train_index, val_index) in enumerate(kf.split(self.data)):\n",
    "            print(f\"Fold {fold+1}/{n_splits}\")\n",
    "            train_sampler = torch.utils.data.SubsetRandomSampler(train_index)\n",
    "            val_sampler = torch.utils.data.SubsetRandomSampler(val_index)\n",
    "\n",
    "            train_loader = torch.utils.data.DataLoader(\n",
    "                self.data,\n",
    "                sampler=train_sampler,\n",
    "                batch_size=self.batch_size,\n",
    "                num_workers=12)\n",
    "            val_loader = torch.utils.data.DataLoader(\n",
    "                self.data,\n",
    "                sampler=val_sampler,\n",
    "                batch_size=self.batch_size,\n",
    "                num_workers=12)\n",
    "\n",
    "            self.train_model(train_loader)\n",
    "            val_loss = self.evaluate_model(val_loader)\n",
    "            val_losses.append(val_loss)\n",
    "        return val_losses\n",
    "\n",
    "\n",
    "\n",
    "# train model with best hyperparameters\n",
    "num_layers, poolsize, channels, kernel_sizes, dilations, activations = search_space(\n",
    "    study.best_trial, input_dim=3, output_dim=3)\n",
    "\n",
    "model = Autoencoder(num_layers=num_layers,\n",
    "                    poolsize=poolsize,\n",
    "                    channels=channels,\n",
    "                    kernel_sizes=kernel_sizes,\n",
    "                    dilations=dilations,\n",
    "                    activations=activations,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    learning_rate=1e-3,\n",
    "                    data=train_set)\n",
    "\n",
    "set = torch.tensor(sim_arr_transformed, dtype=torch.float32)\n",
    "set = set.to('cuda:0')\n",
    "\n",
    "model = JointAutoencoder(model.encoder,\n",
    "                         model.decoder,\n",
    "                         KmeansLayer(n_clusters=20),\n",
    "                         set)\n",
    "\n",
    "model.cross_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(init=array([[0.9999999 , 0.9999999 , 0.9999999 ],\n",
       "       [0.9999991 , 0.999999  , 0.9999984 ],\n",
       "       [0.9999991 , 0.999999  , 0.9999984 ],\n",
       "       [0.99999905, 0.999999  , 0.99999833],\n",
       "       [0.99999887, 0.9999988 , 0.99999815],\n",
       "       [0.99999905, 0.999999  , 0.99999833],\n",
       "       [0.99999905, 0.999999  , 0.99999833],\n",
       "       [0.99999994, 0.9999999 , 0.9999998 ],\n",
       "       [0.99999905, 0.999999  , 0.99999833],\n",
       "       [0.99999905, 0.999999  , 0.99999833],\n",
       "       [0.9999991 , 0.999999  , 0.9999984 ],\n",
       "       [0.9999991 , 0.999999  , 0.9999984 ],\n",
       "       [0.99999905, 0.9999989 , 0.99999833],\n",
       "       [0.99999905, 0.999999  , 0.9999984 ],\n",
       "       [0.9999991 , 0.999999  , 0.9999984 ],\n",
       "       [0.9999991 , 0.999999  , 0.9999984 ],\n",
       "       [0.99999905, 0.9999989 , 0.99999833],\n",
       "       [0.9999991 , 0.999999  , 0.9999984 ],\n",
       "       [0.9999991 , 0.999999  , 0.9999984 ],\n",
       "       [0.9999991 , 0.999999  , 0.9999984 ]], dtype=float32),\n",
       "       n_clusters=20, n_init=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;KMeans<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.cluster.KMeans.html\">?<span>Documentation for KMeans</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KMeans(init=array([[0.9999999 , 0.9999999 , 0.9999999 ],\n",
       "       [0.9999991 , 0.999999  , 0.9999984 ],\n",
       "       [0.9999991 , 0.999999  , 0.9999984 ],\n",
       "       [0.99999905, 0.999999  , 0.99999833],\n",
       "       [0.99999887, 0.9999988 , 0.99999815],\n",
       "       [0.99999905, 0.999999  , 0.99999833],\n",
       "       [0.99999905, 0.999999  , 0.99999833],\n",
       "       [0.99999994, 0.9999999 , 0.9999998 ],\n",
       "       [0.99999905, 0.999999  , 0.99999833],\n",
       "       [0.99999905, 0.999999  , 0.99999833],\n",
       "       [0.9999991 , 0.999999  , 0.9999984 ],\n",
       "       [0.9999991 , 0.999999  , 0.9999984 ],\n",
       "       [0.99999905, 0.9999989 , 0.99999833],\n",
       "       [0.99999905, 0.999999  , 0.9999984 ],\n",
       "       [0.9999991 , 0.999999  , 0.9999984 ],\n",
       "       [0.9999991 , 0.999999  , 0.9999984 ],\n",
       "       [0.99999905, 0.9999989 , 0.99999833],\n",
       "       [0.9999991 , 0.999999  , 0.9999984 ],\n",
       "       [0.9999991 , 0.999999  , 0.9999984 ],\n",
       "       [0.9999991 , 0.999999  , 0.9999984 ]], dtype=float32),\n",
       "       n_clusters=20, n_init=1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(init=array([[0.9999999 , 0.9999999 , 0.9999999 ],\n",
       "       [0.9999991 , 0.999999  , 0.9999984 ],\n",
       "       [0.9999991 , 0.999999  , 0.9999984 ],\n",
       "       [0.99999905, 0.999999  , 0.99999833],\n",
       "       [0.99999887, 0.9999988 , 0.99999815],\n",
       "       [0.99999905, 0.999999  , 0.99999833],\n",
       "       [0.99999905, 0.999999  , 0.99999833],\n",
       "       [0.99999994, 0.9999999 , 0.9999998 ],\n",
       "       [0.99999905, 0.999999  , 0.99999833],\n",
       "       [0.99999905, 0.999999  , 0.99999833],\n",
       "       [0.9999991 , 0.999999  , 0.9999984 ],\n",
       "       [0.9999991 , 0.999999  , 0.9999984 ],\n",
       "       [0.99999905, 0.9999989 , 0.99999833],\n",
       "       [0.99999905, 0.999999  , 0.9999984 ],\n",
       "       [0.9999991 , 0.999999  , 0.9999984 ],\n",
       "       [0.9999991 , 0.999999  , 0.9999984 ],\n",
       "       [0.99999905, 0.9999989 , 0.99999833],\n",
       "       [0.9999991 , 0.999999  , 0.9999984 ],\n",
       "       [0.9999991 , 0.999999  , 0.9999984 ],\n",
       "       [0.9999991 , 0.999999  , 0.9999984 ]], dtype=float32),\n",
       "       n_clusters=20, n_init=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set = torch.tensor(sim_arr_transformed, dtype=torch.float32)\n",
    "set = set.to('cuda:0')\n",
    "cluster_centers = model.predict(set)\n",
    "features = model.encoder(set)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=20, init=cluster_centers, n_init=1)\n",
    "features = features[0]\n",
    "features = features.view(features.size(0), -1)\n",
    "features = features.cpu().detach().numpy()\n",
    "kmeans.fit(features)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeans\n\u001b[1;32m      3\u001b[0m kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, init\u001b[38;5;241m=\u001b[39mcluster_centers, n_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m features \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mview(\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      6\u001b[0m kmeans\u001b[38;5;241m.\u001b[39mfit(features)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'size'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
