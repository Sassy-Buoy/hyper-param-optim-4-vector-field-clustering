{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a807aefe-0bad-422d-8173-8c48678e66de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# show gpu is available\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c47c326c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib as pl\n",
    "import discretisedfield as df\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "simulation_file_paths = list(\n",
    "    pl.Path(\"sims\").glob(\"Configs_*/drive-[0-9]/Configs_*.omf\")\n",
    ")\n",
    "\n",
    "sim_arr = np.array([df.Field.from_file(file).orientation.sel(\"z\").array for file in simulation_file_paths])\n",
    "\n",
    "parameters_dict = {}\n",
    "for path in simulation_file_paths:\n",
    "    json_file_path = path.parent / \"parameters_DE.json\"\n",
    "    with open(json_file_path, \"r\", encoding=\"utf-8\") as f_handle:\n",
    "        parameters_dict[str(path)] = json.load(f_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fac47bca-f435-4afa-8054-f9db22418c8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1926 482 602\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(sim_arr, test_size=0.2, random_state=42)\n",
    "train_set, valid_set = train_test_split(train_set, test_size=0.2, random_state=42)\n",
    "\n",
    "print(train_set.shape[0], valid_set.shape[0], test_set.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8b76ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:44:14,866] Using an existing study with name 'autoencoder' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m11/31\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3326"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1710323057.476089    4008 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3043"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1710323059.253443    4006 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_3', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - loss: 0.3027 - val_loss: 0.1650\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1540 - val_loss: 0.1245\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1180 - val_loss: 0.1009\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.1006 - val_loss: 0.0899\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0908 - val_loss: 0.0842\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0835 - val_loss: 0.0768\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0752 - val_loss: 0.0682\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0696 - val_loss: 0.0637\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0629 - val_loss: 0.0608\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0599 - val_loss: 0.0596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:44:25,529] Trial 10 finished with value: 0.05964725464582443 and parameters: {'num_layers': 2, 'num_filters_0': 9, 'num_filters_1': 12, 'kernel_size': 4, 'activation': 'relu'}. Best is trial 10 with value: 0.05964725464582443.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.2806 - val_loss: 0.1643\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.1490 - val_loss: 0.1091\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1051 - val_loss: 0.0952\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0942 - val_loss: 0.0872\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0875 - val_loss: 0.0782\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0760 - val_loss: 0.0708\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0697 - val_loss: 0.0657\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0663 - val_loss: 0.0638\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0631 - val_loss: 0.0631\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0645 - val_loss: 0.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:44:34,596] Trial 11 finished with value: 0.06249913200736046 and parameters: {'num_layers': 1, 'num_filters_0': 3, 'kernel_size': 8, 'activation': 'selu'}. Best is trial 10 with value: 0.05964725464582443.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.2828"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1710323084.496081    4004 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_7', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.2810 - val_loss: 0.1647\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.1615 - val_loss: 0.1503\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.1441 - val_loss: 0.1094\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.1028 - val_loss: 0.0879\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0860 - val_loss: 0.0750\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0746 - val_loss: 0.0673\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0655 - val_loss: 0.0639\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0648 - val_loss: 0.0616\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0629 - val_loss: 0.0599\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0599 - val_loss: 0.0597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:44:56,089] Trial 12 finished with value: 0.059670597314834595 and parameters: {'num_layers': 4, 'num_filters_0': 9, 'num_filters_1': 12, 'num_filters_2': 12, 'num_filters_3': 9, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 10 with value: 0.05964725464582443.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 0.2847 - val_loss: 0.1587\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1464 - val_loss: 0.1027\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0959 - val_loss: 0.0792\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0752 - val_loss: 0.0672\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0679 - val_loss: 0.0642\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0643 - val_loss: 0.0628\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0636 - val_loss: 0.0617\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0612 - val_loss: 0.0610\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0622 - val_loss: 0.0604\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0607 - val_loss: 0.0599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:45:06,102] Trial 13 finished with value: 0.05989615246653557 and parameters: {'num_layers': 2, 'num_filters_0': 6, 'num_filters_1': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 10 with value: 0.05964725464582443.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - loss: 0.3052 - val_loss: 0.1624\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1527 - val_loss: 0.1212\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1095 - val_loss: 0.0815\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0783 - val_loss: 0.0695\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0696 - val_loss: 0.0662\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0663 - val_loss: 0.0644\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0643 - val_loss: 0.0631\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0636 - val_loss: 0.0622\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0628 - val_loss: 0.0616\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0620 - val_loss: 0.0611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:45:13,287] Trial 14 finished with value: 0.06110745295882225 and parameters: {'num_layers': 1, 'num_filters_0': 6, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 10 with value: 0.05964725464582443.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 10:45:15.499492: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 119ms/step - loss: 0.2486 - val_loss: 0.1263\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.1150 - val_loss: 0.0774\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0753 - val_loss: 0.0685\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0685 - val_loss: 0.0660\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0660 - val_loss: 0.0635\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0651 - val_loss: 0.0628\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0623 - val_loss: 0.0619\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0623 - val_loss: 0.0611\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0615 - val_loss: 0.0611\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0620 - val_loss: 0.0604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:45:31,769] Trial 15 finished with value: 0.06036519631743431 and parameters: {'num_layers': 2, 'num_filters_0': 12, 'num_filters_1': 3, 'kernel_size': 8, 'activation': 'selu'}. Best is trial 10 with value: 0.05964725464582443.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.3074 - val_loss: 0.1707\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1595 - val_loss: 0.1275\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1217 - val_loss: 0.1009\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0974 - val_loss: 0.0819\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0797 - val_loss: 0.0710\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0712 - val_loss: 0.0666\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0677 - val_loss: 0.0645\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0639 - val_loss: 0.0631\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0641 - val_loss: 0.0620\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0633 - val_loss: 0.0613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:45:38,236] Trial 16 finished with value: 0.06127667427062988 and parameters: {'num_layers': 1, 'num_filters_0': 6, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 10 with value: 0.05964725464582443.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 136ms/step - loss: 0.2974 - val_loss: 0.1644\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1634 - val_loss: 0.1393\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1342 - val_loss: 0.1170\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1160 - val_loss: 0.1117\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1160 - val_loss: 0.1096\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1082 - val_loss: 0.1084\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.1106 - val_loss: 0.1076\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.1106 - val_loss: 0.1071\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.1083 - val_loss: 0.1065\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.1058 - val_loss: 0.1060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:45:52,626] Trial 17 finished with value: 0.10601606220006943 and parameters: {'num_layers': 4, 'num_filters_0': 12, 'num_filters_1': 12, 'num_filters_2': 12, 'num_filters_3': 6, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 10 with value: 0.05964725464582443.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - loss: 0.2188 - val_loss: 0.0967\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0899 - val_loss: 0.0715\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0696 - val_loss: 0.0658\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0665 - val_loss: 0.0636\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0628 - val_loss: 0.0622\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0629 - val_loss: 0.0612\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0614 - val_loss: 0.0605\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0605 - val_loss: 0.0601\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0612 - val_loss: 0.0595\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0603 - val_loss: 0.0592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:46:10,648] Trial 18 finished with value: 0.05923222750425339 and parameters: {'num_layers': 2, 'num_filters_0': 12, 'num_filters_1': 6, 'kernel_size': 8, 'activation': 'selu'}. Best is trial 18 with value: 0.05923222750425339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - loss: 0.2123 - val_loss: 0.0942\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0882 - val_loss: 0.0720\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0717 - val_loss: 0.0663\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0655 - val_loss: 0.0638\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0630 - val_loss: 0.0623\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0631 - val_loss: 0.0616\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0624 - val_loss: 0.0619\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0628 - val_loss: 0.0606\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0606 - val_loss: 0.0601\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0608 - val_loss: 0.0598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:46:26,662] Trial 19 finished with value: 0.05976198613643646 and parameters: {'num_layers': 2, 'num_filters_0': 9, 'num_filters_1': 6, 'kernel_size': 8, 'activation': 'selu'}. Best is trial 18 with value: 0.05923222750425339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.2749"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1710323192.493740    4006 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_5', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 118ms/step - loss: 0.2731 - val_loss: 0.1641\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.1620 - val_loss: 0.1437\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.1351 - val_loss: 0.1166\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.1171 - val_loss: 0.1116\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.1126 - val_loss: 0.1090\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.1106 - val_loss: 0.1077\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.1090 - val_loss: 0.1069\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.1072 - val_loss: 0.1062\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.1078 - val_loss: 0.1057\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.1091 - val_loss: 0.1054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:46:45,059] Trial 20 finished with value: 0.10536011308431625 and parameters: {'num_layers': 3, 'num_filters_0': 12, 'num_filters_1': 6, 'num_filters_2': 6, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 18 with value: 0.05923222750425339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3376"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1710323210.945046    4004 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_5', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 102ms/step - loss: 0.3374 - val_loss: 0.2976\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.2341 - val_loss: 0.1635\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.1591 - val_loss: 0.1475\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.1450 - val_loss: 0.1202\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.1182 - val_loss: 0.1071\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.1065 - val_loss: 0.0981\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0972 - val_loss: 0.0926\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0927 - val_loss: 0.0887\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0882 - val_loss: 0.0856\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0846 - val_loss: 0.0819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:46:57,328] Trial 21 finished with value: 0.08186302334070206 and parameters: {'num_layers': 3, 'num_filters_0': 9, 'num_filters_1': 9, 'num_filters_2': 9, 'kernel_size': 4, 'activation': 'relu'}. Best is trial 18 with value: 0.05923222750425339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.3146"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1710323221.995592    4007 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_3', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - loss: 0.3129 - val_loss: 0.1638\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.1569 - val_loss: 0.1419\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.1423 - val_loss: 0.1276\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.1272 - val_loss: 0.1162\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.1149 - val_loss: 0.1032\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.1020 - val_loss: 0.0949\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0950 - val_loss: 0.0894\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0900 - val_loss: 0.0841\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0832 - val_loss: 0.0789\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0795 - val_loss: 0.0726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:47:08,326] Trial 22 finished with value: 0.07264530658721924 and parameters: {'num_layers': 2, 'num_filters_0': 3, 'num_filters_1': 6, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 18 with value: 0.05923222750425339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3326"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1710323234.388926    4004 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_5', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 108ms/step - loss: 0.3321 - val_loss: 0.2308\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1943 - val_loss: 0.1639\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1595 - val_loss: 0.1424\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1397 - val_loss: 0.1228\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1231 - val_loss: 0.1157\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1156 - val_loss: 0.1123\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1144 - val_loss: 0.1105\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1114 - val_loss: 0.1095\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1102 - val_loss: 0.1086\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1085 - val_loss: 0.1078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:47:21,170] Trial 23 finished with value: 0.10775963962078094 and parameters: {'num_layers': 3, 'num_filters_0': 12, 'num_filters_1': 9, 'num_filters_2': 3, 'kernel_size': 4, 'activation': 'relu'}. Best is trial 18 with value: 0.05923222750425339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2652"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1710323246.082283    4007 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_3', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 96ms/step - loss: 0.2636 - val_loss: 0.1584\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.1569 - val_loss: 0.1171\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.1117 - val_loss: 0.0974\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0959 - val_loss: 0.0834\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0803 - val_loss: 0.0730\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0727 - val_loss: 0.0686\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0694 - val_loss: 0.0663\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0658 - val_loss: 0.0646\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0661 - val_loss: 0.0635\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0641 - val_loss: 0.0627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:47:36,075] Trial 24 finished with value: 0.06266035884618759 and parameters: {'num_layers': 2, 'num_filters_0': 9, 'num_filters_1': 3, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 18 with value: 0.05923222750425339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3141"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1710323261.923547    4006 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_5', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 102ms/step - loss: 0.3127 - val_loss: 0.1715\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1709 - val_loss: 0.1603\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1615 - val_loss: 0.1448\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1402 - val_loss: 0.1277\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1246 - val_loss: 0.1166\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.1145 - val_loss: 0.1070\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1063 - val_loss: 0.0981\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0993 - val_loss: 0.0929\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0929 - val_loss: 0.0863\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0863 - val_loss: 0.0815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:47:48,611] Trial 25 finished with value: 0.08147548884153366 and parameters: {'num_layers': 3, 'num_filters_0': 12, 'num_filters_1': 6, 'num_filters_2': 6, 'kernel_size': 4, 'activation': 'relu'}. Best is trial 18 with value: 0.05923222750425339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3120"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1710323271.487733    4007 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_1', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 0.3107 - val_loss: 0.1626\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1510 - val_loss: 0.1212\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1145 - val_loss: 0.1027\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1018 - val_loss: 0.0933\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0934 - val_loss: 0.0864\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0867 - val_loss: 0.0807\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0815 - val_loss: 0.0763\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0753 - val_loss: 0.0725\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0722 - val_loss: 0.0683\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0685 - val_loss: 0.0646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:47:56,472] Trial 26 finished with value: 0.06457871943712234 and parameters: {'num_layers': 1, 'num_filters_0': 9, 'kernel_size': 4, 'activation': 'relu'}. Best is trial 18 with value: 0.05923222750425339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 0.2160 - val_loss: 0.1042\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1002 - val_loss: 0.0766\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0748 - val_loss: 0.0667\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0658 - val_loss: 0.0649\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0651 - val_loss: 0.0629\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0613 - val_loss: 0.0620\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0625 - val_loss: 0.0614\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0611 - val_loss: 0.0608\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0616 - val_loss: 0.0606\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0606 - val_loss: 0.0600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:48:07,414] Trial 27 finished with value: 0.06004275754094124 and parameters: {'num_layers': 2, 'num_filters_0': 3, 'num_filters_1': 12, 'kernel_size': 8, 'activation': 'selu'}. Best is trial 18 with value: 0.05923222750425339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.2679"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1710323293.138285    4007 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_5', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - loss: 0.2661 - val_loss: 0.1632\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.1618 - val_loss: 0.1389\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.1343 - val_loss: 0.1130\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.1094 - val_loss: 0.1088\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.1100 - val_loss: 0.1064\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.1073 - val_loss: 0.1057\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.1051 - val_loss: 0.1051\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.1046 - val_loss: 0.1047\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.1063 - val_loss: 0.1048\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.1048 - val_loss: 0.1044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:48:24,071] Trial 28 finished with value: 0.10439018905162811 and parameters: {'num_layers': 3, 'num_filters_0': 9, 'num_filters_1': 12, 'num_filters_2': 9, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 18 with value: 0.05923222750425339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - loss: 0.2440 - val_loss: 0.1407\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1278 - val_loss: 0.0847\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0804 - val_loss: 0.0686\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0682 - val_loss: 0.0645\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0646 - val_loss: 0.0622\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0633 - val_loss: 0.0609\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0619 - val_loss: 0.0602\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0597 - val_loss: 0.0597\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0602 - val_loss: 0.0594\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0597 - val_loss: 0.0591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:48:32,619] Trial 29 finished with value: 0.05909831449389458 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 29 with value: 0.05909831449389458.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.2744 - val_loss: 0.1459\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1330 - val_loss: 0.0910\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0845 - val_loss: 0.0701\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0705 - val_loss: 0.0650\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0656 - val_loss: 0.0624\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0621 - val_loss: 0.0612\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0610 - val_loss: 0.0606\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0607 - val_loss: 0.0601\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0607 - val_loss: 0.0597\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0608 - val_loss: 0.0593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:48:40,482] Trial 30 finished with value: 0.05933361127972603 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 29 with value: 0.05909831449389458.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.2443 - val_loss: 0.1240\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1066 - val_loss: 0.0730\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0698 - val_loss: 0.0646\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0658 - val_loss: 0.0619\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0640 - val_loss: 0.0606\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0620 - val_loss: 0.0600\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0598 - val_loss: 0.0596\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0610 - val_loss: 0.0593\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0609 - val_loss: 0.0590\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0594 - val_loss: 0.0588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:48:48,316] Trial 31 finished with value: 0.05881578475236893 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 31 with value: 0.05881578475236893.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.2740 - val_loss: 0.1401\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1283 - val_loss: 0.0950\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0871 - val_loss: 0.0694\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0673 - val_loss: 0.0648\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0652 - val_loss: 0.0625\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0629 - val_loss: 0.0612\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0616 - val_loss: 0.0605\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0618 - val_loss: 0.0600\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0616 - val_loss: 0.0596\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0615 - val_loss: 0.0593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:48:56,226] Trial 32 finished with value: 0.05933002382516861 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 31 with value: 0.05881578475236893.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 0.2473 - val_loss: 0.1264\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1130 - val_loss: 0.0809\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0766 - val_loss: 0.0661\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0668 - val_loss: 0.0626\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0635 - val_loss: 0.0609\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0617 - val_loss: 0.0600\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0606 - val_loss: 0.0595\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0607 - val_loss: 0.0592\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0590 - val_loss: 0.0589\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0600 - val_loss: 0.0587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:49:04,712] Trial 33 finished with value: 0.05867857486009598 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 33 with value: 0.05867857486009598.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 0.2693 - val_loss: 0.1274\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1195 - val_loss: 0.0826\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0790 - val_loss: 0.0693\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0678 - val_loss: 0.0656\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0658 - val_loss: 0.0637\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0635 - val_loss: 0.0624\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0633 - val_loss: 0.0616\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0615 - val_loss: 0.0610\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0604 - val_loss: 0.0605\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0610 - val_loss: 0.0601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:49:12,740] Trial 34 finished with value: 0.06012125685811043 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 33 with value: 0.05867857486009598.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - loss: 0.3002 - val_loss: 0.1451\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1338 - val_loss: 0.0924\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0863 - val_loss: 0.0706\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0703 - val_loss: 0.0651\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0650 - val_loss: 0.0625\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0639 - val_loss: 0.0612\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0613 - val_loss: 0.0604\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0609 - val_loss: 0.0599\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0595 - val_loss: 0.0595\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0601 - val_loss: 0.0591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:49:20,687] Trial 35 finished with value: 0.05911898612976074 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 33 with value: 0.05867857486009598.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - loss: 0.2653 - val_loss: 0.1377\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1250 - val_loss: 0.0887\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0823 - val_loss: 0.0679\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0689 - val_loss: 0.0641\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0634 - val_loss: 0.0622\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0624 - val_loss: 0.0610\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0616 - val_loss: 0.0604\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0598 - val_loss: 0.0599\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0605 - val_loss: 0.0595\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0598 - val_loss: 0.0592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:49:28,859] Trial 36 finished with value: 0.0592317208647728 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 33 with value: 0.05867857486009598.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.2601 - val_loss: 0.1372\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1252 - val_loss: 0.0938\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0876 - val_loss: 0.0707\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0700 - val_loss: 0.0648\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0645 - val_loss: 0.0621\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0634 - val_loss: 0.0608\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0602 - val_loss: 0.0601\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0608 - val_loss: 0.0597\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0604 - val_loss: 0.0594\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0609 - val_loss: 0.0591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:49:36,910] Trial 37 finished with value: 0.059114232659339905 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 33 with value: 0.05867857486009598.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.2767 - val_loss: 0.1241\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1143 - val_loss: 0.0831\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0792 - val_loss: 0.0689\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0669 - val_loss: 0.0646\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0648 - val_loss: 0.0624\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0631 - val_loss: 0.0613\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0622 - val_loss: 0.0606\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0617 - val_loss: 0.0602\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0612 - val_loss: 0.0598\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0600 - val_loss: 0.0595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:49:44,762] Trial 38 finished with value: 0.05954327434301376 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 33 with value: 0.05867857486009598.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - loss: 0.2670 - val_loss: 0.1281\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1144 - val_loss: 0.0817\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0774 - val_loss: 0.0677\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0666 - val_loss: 0.0643\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0643 - val_loss: 0.0625\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0642 - val_loss: 0.0615\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0609 - val_loss: 0.0608\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0622 - val_loss: 0.0604\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0607 - val_loss: 0.0600\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0608 - val_loss: 0.0596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:49:52,645] Trial 39 finished with value: 0.059621214866638184 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 33 with value: 0.05867857486009598.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - loss: 0.3312 - val_loss: 0.1840\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1730 - val_loss: 0.1465\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1423 - val_loss: 0.1206\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1169 - val_loss: 0.1009\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0992 - val_loss: 0.0886\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0885 - val_loss: 0.0815\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0818 - val_loss: 0.0734\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0714 - val_loss: 0.0667\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0656 - val_loss: 0.0646\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0649 - val_loss: 0.0635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:50:01,412] Trial 40 finished with value: 0.06352455914020538 and parameters: {'num_layers': 2, 'num_filters_0': 3, 'num_filters_1': 9, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 33 with value: 0.05867857486009598.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 0.2880 - val_loss: 0.1449\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1296 - val_loss: 0.0975\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0913 - val_loss: 0.0717\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0703 - val_loss: 0.0656\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0652 - val_loss: 0.0629\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0641 - val_loss: 0.0614\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0620 - val_loss: 0.0604\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0605 - val_loss: 0.0599\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0603 - val_loss: 0.0594\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0596 - val_loss: 0.0591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:50:09,446] Trial 41 finished with value: 0.059130169451236725 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 33 with value: 0.05867857486009598.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.2636 - val_loss: 0.1482\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1344 - val_loss: 0.0940\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0880 - val_loss: 0.0701\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0693 - val_loss: 0.0641\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0642 - val_loss: 0.0615\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0630 - val_loss: 0.0604\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0598 - val_loss: 0.0598\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0595 - val_loss: 0.0594\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0601 - val_loss: 0.0591\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0583 - val_loss: 0.0588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:50:17,332] Trial 42 finished with value: 0.05880371853709221 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 33 with value: 0.05867857486009598.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.2695 - val_loss: 0.1449\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1338 - val_loss: 0.0972\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0883 - val_loss: 0.0709\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0704 - val_loss: 0.0649\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0651 - val_loss: 0.0620\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0607 - val_loss: 0.0607\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0615 - val_loss: 0.0600\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0598 - val_loss: 0.0596\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0590 - val_loss: 0.0593\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0596 - val_loss: 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:50:25,614] Trial 43 finished with value: 0.059011269360780716 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 33 with value: 0.05867857486009598.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.2539 - val_loss: 0.1596\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1544 - val_loss: 0.1230\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1141 - val_loss: 0.0853\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0810 - val_loss: 0.0709\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0708 - val_loss: 0.0673\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0681 - val_loss: 0.0656\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0674 - val_loss: 0.0644\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0652 - val_loss: 0.0635\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0637 - val_loss: 0.0628\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0640 - val_loss: 0.0622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:50:32,294] Trial 44 finished with value: 0.06222027167677879 and parameters: {'num_layers': 1, 'num_filters_0': 6, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 33 with value: 0.05867857486009598.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - loss: 0.2921 - val_loss: 0.1523\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1393 - val_loss: 0.0977\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0904 - val_loss: 0.0724\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0701 - val_loss: 0.0664\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0663 - val_loss: 0.0635\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0642 - val_loss: 0.0619\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0637 - val_loss: 0.0610\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0625 - val_loss: 0.0604\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0626 - val_loss: 0.0600\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0612 - val_loss: 0.0596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:50:40,402] Trial 45 finished with value: 0.05963115394115448 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 33 with value: 0.05867857486009598.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 0.2947 - val_loss: 0.1689\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.1594 - val_loss: 0.1368\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1288 - val_loss: 0.1007\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0976 - val_loss: 0.0883\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0867 - val_loss: 0.0842\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0841 - val_loss: 0.0813\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0818 - val_loss: 0.0778\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0781 - val_loss: 0.0733\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0727 - val_loss: 0.0673\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0666 - val_loss: 0.0638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:50:51,566] Trial 46 finished with value: 0.06381035596132278 and parameters: {'num_layers': 2, 'num_filters_0': 12, 'num_filters_1': 3, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 33 with value: 0.05867857486009598.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 114ms/step - loss: 0.3055 - val_loss: 0.1856\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1788 - val_loss: 0.1618\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1595 - val_loss: 0.1537\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1530 - val_loss: 0.1401\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1358 - val_loss: 0.1144\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1081 - val_loss: 0.0961\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0958 - val_loss: 0.0914\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0919 - val_loss: 0.0881\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0901 - val_loss: 0.0856\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0859 - val_loss: 0.0834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:51:04,041] Trial 47 finished with value: 0.08343787491321564 and parameters: {'num_layers': 4, 'num_filters_0': 6, 'num_filters_1': 3, 'num_filters_2': 3, 'num_filters_3': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 33 with value: 0.05867857486009598.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.3326 - val_loss: 0.2655\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2455 - val_loss: 0.1829\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1755 - val_loss: 0.1618\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1592 - val_loss: 0.1514\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1520 - val_loss: 0.1436\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1430 - val_loss: 0.1337\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1315 - val_loss: 0.1135\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1098 - val_loss: 0.0931\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0908 - val_loss: 0.0780\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0751 - val_loss: 0.0677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:51:10,717] Trial 48 finished with value: 0.06767696142196655 and parameters: {'num_layers': 1, 'num_filters_0': 3, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 33 with value: 0.05867857486009598.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.2465 - val_loss: 0.1225\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1108 - val_loss: 0.0764\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0730 - val_loss: 0.0655\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0650 - val_loss: 0.0626\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0623 - val_loss: 0.0612\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0622 - val_loss: 0.0604\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0616 - val_loss: 0.0598\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0600 - val_loss: 0.0594\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0599 - val_loss: 0.0590\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0597 - val_loss: 0.0587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:51:18,664] Trial 49 finished with value: 0.05867283046245575 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 49 with value: 0.05867283046245575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 0.2953 - val_loss: 0.1711\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1624 - val_loss: 0.1156\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1068 - val_loss: 0.0894\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0867 - val_loss: 0.0730\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0706 - val_loss: 0.0657\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0658 - val_loss: 0.0634\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0635 - val_loss: 0.0622\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0612 - val_loss: 0.0614\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0615 - val_loss: 0.0608\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0616 - val_loss: 0.0602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:51:28,611] Trial 50 finished with value: 0.06023892015218735 and parameters: {'num_layers': 2, 'num_filters_0': 6, 'num_filters_1': 9, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 49 with value: 0.05867283046245575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.2483 - val_loss: 0.1543\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1458 - val_loss: 0.1105\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1005 - val_loss: 0.0722\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0718 - val_loss: 0.0651\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0646 - val_loss: 0.0620\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0630 - val_loss: 0.0606\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0600 - val_loss: 0.0599\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0600 - val_loss: 0.0594\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0598 - val_loss: 0.0591\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0593 - val_loss: 0.0589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:51:36,450] Trial 51 finished with value: 0.05886566638946533 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 49 with value: 0.05867283046245575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.2635 - val_loss: 0.1468\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1357 - val_loss: 0.0980\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0905 - val_loss: 0.0712\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0713 - val_loss: 0.0662\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0670 - val_loss: 0.0637\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0647 - val_loss: 0.0621\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0641 - val_loss: 0.0611\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0625 - val_loss: 0.0605\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0615 - val_loss: 0.0600\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0609 - val_loss: 0.0597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:51:44,442] Trial 52 finished with value: 0.059679873287677765 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 49 with value: 0.05867283046245575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - loss: 0.2577 - val_loss: 0.1325\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1226 - val_loss: 0.0878\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0818 - val_loss: 0.0691\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0681 - val_loss: 0.0643\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0647 - val_loss: 0.0618\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0635 - val_loss: 0.0606\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0612 - val_loss: 0.0599\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0605 - val_loss: 0.0595\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0602 - val_loss: 0.0592\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0604 - val_loss: 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:51:52,611] Trial 53 finished with value: 0.05897964537143707 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 49 with value: 0.05867283046245575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 0.2691 - val_loss: 0.1399\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1318 - val_loss: 0.0994\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0915 - val_loss: 0.0736\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0731 - val_loss: 0.0666\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0669 - val_loss: 0.0633\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0626 - val_loss: 0.0614\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0611 - val_loss: 0.0605\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0613 - val_loss: 0.0600\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0610 - val_loss: 0.0597\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0615 - val_loss: 0.0594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:52:00,759] Trial 54 finished with value: 0.059407949447631836 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 49 with value: 0.05867283046245575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 0.2725 - val_loss: 0.1342\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1206 - val_loss: 0.0828\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0793 - val_loss: 0.0672\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0665 - val_loss: 0.0633\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0645 - val_loss: 0.0615\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0623 - val_loss: 0.0606\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0613 - val_loss: 0.0600\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0613 - val_loss: 0.0596\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0598 - val_loss: 0.0593\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0597 - val_loss: 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:52:08,889] Trial 55 finished with value: 0.05898623168468475 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 49 with value: 0.05867283046245575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 0.2775 - val_loss: 0.1524\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.1361 - val_loss: 0.0854\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0770 - val_loss: 0.0678\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0690 - val_loss: 0.0643\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0646 - val_loss: 0.0628\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0631 - val_loss: 0.0619\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0631 - val_loss: 0.0611\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0605 - val_loss: 0.0605\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0613 - val_loss: 0.0599\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0606 - val_loss: 0.0595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:52:20,063] Trial 56 finished with value: 0.059476420283317566 and parameters: {'num_layers': 2, 'num_filters_0': 12, 'num_filters_1': 9, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 49 with value: 0.05867283046245575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.2608 - val_loss: 0.1431\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1322 - val_loss: 0.0917\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0845 - val_loss: 0.0713\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0692 - val_loss: 0.0659\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0671 - val_loss: 0.0633\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0643 - val_loss: 0.0617\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0615 - val_loss: 0.0608\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0620 - val_loss: 0.0602\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0611 - val_loss: 0.0598\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0607 - val_loss: 0.0595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:52:28,035] Trial 57 finished with value: 0.059477850794792175 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 49 with value: 0.05867283046245575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.2430 - val_loss: 0.1328\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1198 - val_loss: 0.0833\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0781 - val_loss: 0.0664\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0658 - val_loss: 0.0623\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0616 - val_loss: 0.0608\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0617 - val_loss: 0.0602\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0611 - val_loss: 0.0597\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0605 - val_loss: 0.0594\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0591 - val_loss: 0.0591\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0597 - val_loss: 0.0589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:52:35,885] Trial 58 finished with value: 0.05889013037085533 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 49 with value: 0.05867283046245575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - loss: 0.2890 - val_loss: 0.1499\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.1319 - val_loss: 0.1011\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0984 - val_loss: 0.0859\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0839 - val_loss: 0.0767\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0783 - val_loss: 0.0726\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0725 - val_loss: 0.0702\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0703 - val_loss: 0.0681\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0694 - val_loss: 0.0662\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0673 - val_loss: 0.0649\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0654 - val_loss: 0.0640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:52:45,863] Trial 59 finished with value: 0.06400629132986069 and parameters: {'num_layers': 2, 'num_filters_0': 3, 'num_filters_1': 3, 'kernel_size': 8, 'activation': 'selu'}. Best is trial 49 with value: 0.05867283046245575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 109ms/step - loss: 0.3041 - val_loss: 0.1810\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1742 - val_loss: 0.1654\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1662 - val_loss: 0.1585\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1536 - val_loss: 0.1452\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1437 - val_loss: 0.1274\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1276 - val_loss: 0.1174\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1158 - val_loss: 0.1124\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1123 - val_loss: 0.1082\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1083 - val_loss: 0.1045\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1038 - val_loss: 0.1005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:52:58,119] Trial 60 finished with value: 0.10048841685056686 and parameters: {'num_layers': 4, 'num_filters_0': 6, 'num_filters_1': 3, 'num_filters_2': 6, 'num_filters_3': 3, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 49 with value: 0.05867283046245575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 0.2558 - val_loss: 0.1392\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1296 - val_loss: 0.1001\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0927 - val_loss: 0.0705\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0695 - val_loss: 0.0642\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0636 - val_loss: 0.0618\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0638 - val_loss: 0.0606\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0618 - val_loss: 0.0600\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0611 - val_loss: 0.0596\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0597 - val_loss: 0.0593\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0617 - val_loss: 0.0591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:53:06,042] Trial 61 finished with value: 0.05907499045133591 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 49 with value: 0.05867283046245575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.2852 - val_loss: 0.1464\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1355 - val_loss: 0.0992\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0914 - val_loss: 0.0708\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0671 - val_loss: 0.0640\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0648 - val_loss: 0.0618\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0621 - val_loss: 0.0607\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0613 - val_loss: 0.0601\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0608 - val_loss: 0.0597\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0610 - val_loss: 0.0594\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0602 - val_loss: 0.0592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:53:13,892] Trial 62 finished with value: 0.05916596204042435 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 49 with value: 0.05867283046245575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.2535 - val_loss: 0.1351\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1251 - val_loss: 0.0917\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0870 - val_loss: 0.0703\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0696 - val_loss: 0.0649\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0658 - val_loss: 0.0623\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0615 - val_loss: 0.0609\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0617 - val_loss: 0.0601\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0616 - val_loss: 0.0596\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0599 - val_loss: 0.0592\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0591 - val_loss: 0.0589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:53:21,753] Trial 63 finished with value: 0.05887740105390549 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 4, 'activation': 'selu'}. Best is trial 49 with value: 0.05867283046245575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.3171 - val_loss: 0.2020\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1711 - val_loss: 0.1193\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1128 - val_loss: 0.0971\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0952 - val_loss: 0.0875\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0859 - val_loss: 0.0775\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0751 - val_loss: 0.0678\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0671 - val_loss: 0.0641\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0645 - val_loss: 0.0622\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0628 - val_loss: 0.0610\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0629 - val_loss: 0.0602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:53:28,975] Trial 64 finished with value: 0.060163021087646484 and parameters: {'num_layers': 1, 'num_filters_0': 9, 'kernel_size': 4, 'activation': 'relu'}. Best is trial 49 with value: 0.05867283046245575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - loss: 0.1825 - val_loss: 0.0932\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0877 - val_loss: 0.0706\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0688 - val_loss: 0.0628\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0636 - val_loss: 0.0612\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0609 - val_loss: 0.0602\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0613 - val_loss: 0.0595\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0609 - val_loss: 0.0591\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0599 - val_loss: 0.0587\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0598 - val_loss: 0.0584\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0596 - val_loss: 0.0582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:53:43,406] Trial 65 finished with value: 0.0581817626953125 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 8, 'activation': 'selu'}. Best is trial 65 with value: 0.0581817626953125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 116ms/step - loss: 0.2051 - val_loss: 0.0818\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0785 - val_loss: 0.0676\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0678 - val_loss: 0.0642\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0651 - val_loss: 0.0624\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0613 - val_loss: 0.0613\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0626 - val_loss: 0.0607\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0607 - val_loss: 0.0603\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0610 - val_loss: 0.0597\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0593 - val_loss: 0.0592\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0594 - val_loss: 0.0588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:54:01,817] Trial 66 finished with value: 0.05883407220244408 and parameters: {'num_layers': 2, 'num_filters_0': 12, 'num_filters_1': 9, 'kernel_size': 8, 'activation': 'selu'}. Best is trial 65 with value: 0.0581817626953125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - loss: 0.2156 - val_loss: 0.0845\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0818 - val_loss: 0.0689\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0687 - val_loss: 0.0644\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0643 - val_loss: 0.0622\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0616 - val_loss: 0.0610\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0614 - val_loss: 0.0602\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0613 - val_loss: 0.0600\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0607 - val_loss: 0.0593\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0582 - val_loss: 0.0588\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0600 - val_loss: 0.0585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:54:17,372] Trial 67 finished with value: 0.058505646884441376 and parameters: {'num_layers': 2, 'num_filters_0': 12, 'num_filters_1': 9, 'kernel_size': 8, 'activation': 'selu'}. Best is trial 65 with value: 0.0581817626953125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2627"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1710323661.840448    4005 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_3', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - loss: 0.2609 - val_loss: 0.1265\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1239 - val_loss: 0.1129\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.1114 - val_loss: 0.1078\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1075 - val_loss: 0.1029\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.1001 - val_loss: 0.0875\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0883 - val_loss: 0.0835\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0841 - val_loss: 0.0670\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0658 - val_loss: 0.0615\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0636 - val_loss: 0.0597\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0614 - val_loss: 0.0588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:54:33,315] Trial 68 finished with value: 0.05883072316646576 and parameters: {'num_layers': 2, 'num_filters_0': 12, 'num_filters_1': 9, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 65 with value: 0.0581817626953125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 115ms/step - loss: 0.2185 - val_loss: 0.0988\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0893 - val_loss: 0.0700\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0688 - val_loss: 0.0652\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0654 - val_loss: 0.0629\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0630 - val_loss: 0.0617\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0624 - val_loss: 0.0610\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0613 - val_loss: 0.0602\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0604 - val_loss: 0.0599\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0601 - val_loss: 0.0594\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0605 - val_loss: 0.0589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:54:51,966] Trial 69 finished with value: 0.05889711529016495 and parameters: {'num_layers': 3, 'num_filters_0': 12, 'num_filters_1': 9, 'num_filters_2': 12, 'kernel_size': 8, 'activation': 'selu'}. Best is trial 65 with value: 0.0581817626953125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 98ms/step - loss: 0.2070 - val_loss: 0.0918\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0843 - val_loss: 0.0687\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0686 - val_loss: 0.0647\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0655 - val_loss: 0.0629\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0634 - val_loss: 0.0619\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0611 - val_loss: 0.0608\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0629 - val_loss: 0.0601\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0602 - val_loss: 0.0595\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0605 - val_loss: 0.0593\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0602 - val_loss: 0.0591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:55:07,861] Trial 70 finished with value: 0.05906468629837036 and parameters: {'num_layers': 2, 'num_filters_0': 9, 'num_filters_1': 9, 'kernel_size': 8, 'activation': 'selu'}. Best is trial 65 with value: 0.0581817626953125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - loss: 0.2442 - val_loss: 0.1304\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1214 - val_loss: 0.0980\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0946 - val_loss: 0.0789\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0744 - val_loss: 0.0645\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0625 - val_loss: 0.0610\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0622 - val_loss: 0.0597\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0598 - val_loss: 0.0588\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0592 - val_loss: 0.0583\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0590 - val_loss: 0.0579\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0585 - val_loss: 0.0576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:55:23,580] Trial 71 finished with value: 0.05757271870970726 and parameters: {'num_layers': 2, 'num_filters_0': 12, 'num_filters_1': 9, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - loss: 0.2708 - val_loss: 0.1350\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1251 - val_loss: 0.1111\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1119 - val_loss: 0.1079\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1091 - val_loss: 0.1063\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.1095 - val_loss: 0.1052\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1059 - val_loss: 0.1048\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1047 - val_loss: 0.1045\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1064 - val_loss: 0.1044\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1059 - val_loss: 0.1042\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1041 - val_loss: 0.1042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:55:38,763] Trial 72 finished with value: 0.10419091582298279 and parameters: {'num_layers': 2, 'num_filters_0': 12, 'num_filters_1': 9, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.2462"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1710323744.179851    4008 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_5', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step - loss: 0.2448 - val_loss: 0.1610\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.1560 - val_loss: 0.1189\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.1093 - val_loss: 0.0895\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0850 - val_loss: 0.0714\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0696 - val_loss: 0.0651\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0644 - val_loss: 0.0630\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0637 - val_loss: 0.0614\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0627 - val_loss: 0.0604\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0624 - val_loss: 0.0596\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0602 - val_loss: 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:55:56,259] Trial 73 finished with value: 0.05902475118637085 and parameters: {'num_layers': 3, 'num_filters_0': 12, 'num_filters_1': 9, 'num_filters_2': 9, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - loss: 0.2392 - val_loss: 0.1207\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1130 - val_loss: 0.0920\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0895 - val_loss: 0.0730\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0712 - val_loss: 0.0648\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0659 - val_loss: 0.0618\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0613 - val_loss: 0.0600\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0605 - val_loss: 0.0592\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0598 - val_loss: 0.0586\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0601 - val_loss: 0.0583\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0598 - val_loss: 0.0585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:56:11,467] Trial 74 finished with value: 0.05852661654353142 and parameters: {'num_layers': 2, 'num_filters_0': 12, 'num_filters_1': 9, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - loss: 0.2350 - val_loss: 0.1396\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1297 - val_loss: 0.1126\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1111 - val_loss: 0.1078\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.1092 - val_loss: 0.1062\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1067 - val_loss: 0.1058\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1049 - val_loss: 0.1055\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1063 - val_loss: 0.1050\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1059 - val_loss: 0.1047\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1046 - val_loss: 0.1050\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1063 - val_loss: 0.1045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:56:26,605] Trial 75 finished with value: 0.10454226285219193 and parameters: {'num_layers': 2, 'num_filters_0': 12, 'num_filters_1': 9, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - loss: 0.2387 - val_loss: 0.1209\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1184 - val_loss: 0.1101\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1086 - val_loss: 0.0983\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0951 - val_loss: 0.0856\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0850 - val_loss: 0.0716\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0711 - val_loss: 0.0647\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0641 - val_loss: 0.0621\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0618 - val_loss: 0.0606\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0597 - val_loss: 0.0597\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0612 - val_loss: 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:56:41,848] Trial 76 finished with value: 0.05900430679321289 and parameters: {'num_layers': 2, 'num_filters_0': 12, 'num_filters_1': 9, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.2723"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1710323806.226407    4007 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_3', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - loss: 0.2708 - val_loss: 0.1676\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1613 - val_loss: 0.1217\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1158 - val_loss: 0.1050\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1031 - val_loss: 0.0937\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0913 - val_loss: 0.0794\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0805 - val_loss: 0.0739\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0738 - val_loss: 0.0716\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0716 - val_loss: 0.0689\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0688 - val_loss: 0.0672\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0683 - val_loss: 0.0661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:56:52,936] Trial 77 finished with value: 0.06608682870864868 and parameters: {'num_layers': 2, 'num_filters_0': 3, 'num_filters_1': 9, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.2950"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1710323818.849325    4005 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_5', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - loss: 0.2933 - val_loss: 0.1682\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.1682 - val_loss: 0.1606\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.1620 - val_loss: 0.1418\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.1407 - val_loss: 0.1237\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.1199 - val_loss: 0.1168\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.1163 - val_loss: 0.1117\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.1106 - val_loss: 0.1070\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.1071 - val_loss: 0.1059\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.1058 - val_loss: 0.1054\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.1044 - val_loss: 0.1051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:57:10,770] Trial 78 finished with value: 0.10505903512239456 and parameters: {'num_layers': 3, 'num_filters_0': 12, 'num_filters_1': 9, 'num_filters_2': 3, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2345"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1710323835.777447    4006 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_3', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 95ms/step - loss: 0.2331 - val_loss: 0.1381\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1255 - val_loss: 0.1108\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.1095 - val_loss: 0.1066\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.1072 - val_loss: 0.1055\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1074 - val_loss: 0.1051\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.1058 - val_loss: 0.1045\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.1046 - val_loss: 0.1044\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.1053 - val_loss: 0.1044\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.1055 - val_loss: 0.1039\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.1045 - val_loss: 0.1038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:57:27,545] Trial 79 finished with value: 0.10375526547431946 and parameters: {'num_layers': 2, 'num_filters_0': 12, 'num_filters_1': 12, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - loss: 0.2469 - val_loss: 0.1299\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1243 - val_loss: 0.1115\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1105 - val_loss: 0.1078\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1061 - val_loss: 0.1066\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1089 - val_loss: 0.1059\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1062 - val_loss: 0.1051\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1057 - val_loss: 0.1047\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1071 - val_loss: 0.1044\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1044 - val_loss: 0.1042\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.1063 - val_loss: 0.1041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:57:42,686] Trial 80 finished with value: 0.10414277017116547 and parameters: {'num_layers': 2, 'num_filters_0': 12, 'num_filters_1': 9, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.2304"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1710323866.598295    4004 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_1', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - loss: 0.2284 - val_loss: 0.1096\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.1067 - val_loss: 0.0928\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0907 - val_loss: 0.0751\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0734 - val_loss: 0.0664\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0671 - val_loss: 0.0622\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0623 - val_loss: 0.0605\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0616 - val_loss: 0.0596\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0606 - val_loss: 0.0593\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0593 - val_loss: 0.0586\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0613 - val_loss: 0.0583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:57:56,846] Trial 81 finished with value: 0.05832592025399208 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - loss: 0.2220 - val_loss: 0.1073\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.1013 - val_loss: 0.0822\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0797 - val_loss: 0.0684\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0680 - val_loss: 0.0632\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0643 - val_loss: 0.0610\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0615 - val_loss: 0.0599\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0614 - val_loss: 0.0591\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0591 - val_loss: 0.0586\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0592 - val_loss: 0.0581\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0583 - val_loss: 0.0578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:58:09,912] Trial 82 finished with value: 0.05775165557861328 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - loss: 0.2277 - val_loss: 0.1211\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.1129 - val_loss: 0.0926\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0889 - val_loss: 0.0774\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0749 - val_loss: 0.0658\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0646 - val_loss: 0.0618\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0624 - val_loss: 0.0600\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0611 - val_loss: 0.0590\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0594 - val_loss: 0.0583\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0591 - val_loss: 0.0580\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0588 - val_loss: 0.0576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:58:22,837] Trial 83 finished with value: 0.05761324614286423 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - loss: 0.2487 - val_loss: 0.1121\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.1047 - val_loss: 0.0797\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0760 - val_loss: 0.0674\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0670 - val_loss: 0.0625\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0622 - val_loss: 0.0604\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0616 - val_loss: 0.0594\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0600 - val_loss: 0.0589\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0595 - val_loss: 0.0586\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0597 - val_loss: 0.0580\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0594 - val_loss: 0.0578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:58:35,675] Trial 84 finished with value: 0.05779731646180153 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - loss: 0.2393 - val_loss: 0.1101\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.1040 - val_loss: 0.0805\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0767 - val_loss: 0.0687\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0691 - val_loss: 0.0639\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0635 - val_loss: 0.0613\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0631 - val_loss: 0.0600\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0606 - val_loss: 0.0593\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0603 - val_loss: 0.0588\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0594 - val_loss: 0.0584\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0590 - val_loss: 0.0581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:58:48,639] Trial 85 finished with value: 0.05812632292509079 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2346"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1710323931.874252    4007 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_1', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - loss: 0.2328 - val_loss: 0.1127\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.1056 - val_loss: 0.0889\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0868 - val_loss: 0.0722\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0721 - val_loss: 0.0671\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0669 - val_loss: 0.0639\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0633 - val_loss: 0.0616\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0608 - val_loss: 0.0603\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0611 - val_loss: 0.0596\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0615 - val_loss: 0.0592\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0599 - val_loss: 0.0589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:59:00,733] Trial 86 finished with value: 0.058870892971754074 and parameters: {'num_layers': 1, 'num_filters_0': 9, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - loss: 0.2390 - val_loss: 0.1116\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.1068 - val_loss: 0.0883\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0853 - val_loss: 0.0718\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0696 - val_loss: 0.0642\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0669 - val_loss: 0.0610\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0606 - val_loss: 0.0598\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0591 - val_loss: 0.0590\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0598 - val_loss: 0.0586\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0604 - val_loss: 0.0582\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0597 - val_loss: 0.0580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:59:13,567] Trial 87 finished with value: 0.057954490184783936 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.2335"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1710323957.946840    4004 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_1', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - loss: 0.2319 - val_loss: 0.1315\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1249 - val_loss: 0.1066\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1042 - val_loss: 0.0956\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0930 - val_loss: 0.0849\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0811 - val_loss: 0.0753\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0742 - val_loss: 0.0706\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0711 - val_loss: 0.0672\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0682 - val_loss: 0.0650\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0661 - val_loss: 0.0636\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0660 - val_loss: 0.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:59:25,174] Trial 88 finished with value: 0.06254319101572037 and parameters: {'num_layers': 1, 'num_filters_0': 6, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - loss: 0.2287 - val_loss: 0.1134\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.1105 - val_loss: 0.0949\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0931 - val_loss: 0.0745\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0709 - val_loss: 0.0646\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0649 - val_loss: 0.0613\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0615 - val_loss: 0.0599\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0609 - val_loss: 0.0591\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0600 - val_loss: 0.0587\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0603 - val_loss: 0.0584\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0590 - val_loss: 0.0581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:59:38,137] Trial 89 finished with value: 0.05805067718029022 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - loss: 0.2124 - val_loss: 0.1106\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.1060 - val_loss: 0.0929\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0890 - val_loss: 0.0711\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0704 - val_loss: 0.0652\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0653 - val_loss: 0.0619\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0625 - val_loss: 0.0603\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0608 - val_loss: 0.0597\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0609 - val_loss: 0.0591\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0589 - val_loss: 0.0589\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0593 - val_loss: 0.0583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:59:51,271] Trial 90 finished with value: 0.058313868939876556 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - loss: 0.2206 - val_loss: 0.1067\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.1020 - val_loss: 0.0937\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0925 - val_loss: 0.0756\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0724 - val_loss: 0.0654\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0654 - val_loss: 0.0617\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0617 - val_loss: 0.0604\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0601 - val_loss: 0.0595\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0597 - val_loss: 0.0589\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0606 - val_loss: 0.0586\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0590 - val_loss: 0.0583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 11:00:04,342] Trial 91 finished with value: 0.05833228677511215 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - loss: 0.2283 - val_loss: 0.1087\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.1028 - val_loss: 0.0861\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0804 - val_loss: 0.0697\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0683 - val_loss: 0.0648\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0659 - val_loss: 0.0619\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0624 - val_loss: 0.0604\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0610 - val_loss: 0.0595\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0601 - val_loss: 0.0591\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0590 - val_loss: 0.0586\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0604 - val_loss: 0.0583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 11:00:17,857] Trial 92 finished with value: 0.05832265317440033 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - loss: 0.2328 - val_loss: 0.1121\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.1071 - val_loss: 0.0887\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0835 - val_loss: 0.0718\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0713 - val_loss: 0.0651\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0639 - val_loss: 0.0615\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0614 - val_loss: 0.0600\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0593 - val_loss: 0.0592\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0597 - val_loss: 0.0586\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0591 - val_loss: 0.0583\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0583 - val_loss: 0.0580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 11:00:31,333] Trial 93 finished with value: 0.05803029239177704 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - loss: 0.2314 - val_loss: 0.1118\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.1076 - val_loss: 0.0938\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0906 - val_loss: 0.0813\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0795 - val_loss: 0.0700\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0690 - val_loss: 0.0624\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0624 - val_loss: 0.0601\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0598 - val_loss: 0.0592\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0590 - val_loss: 0.0586\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0587 - val_loss: 0.0582\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0597 - val_loss: 0.0580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 11:00:44,793] Trial 94 finished with value: 0.05796317011117935 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - loss: 0.2181 - val_loss: 0.1078\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.1050 - val_loss: 0.0881\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0851 - val_loss: 0.0729\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0733 - val_loss: 0.0654\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0651 - val_loss: 0.0621\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0617 - val_loss: 0.0605\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0610 - val_loss: 0.0595\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0607 - val_loss: 0.0589\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0597 - val_loss: 0.0585\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0598 - val_loss: 0.0581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 11:00:59,018] Trial 95 finished with value: 0.05814409255981445 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - loss: 0.2322 - val_loss: 0.1115\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.1075 - val_loss: 0.0881\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0824 - val_loss: 0.0710\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0707 - val_loss: 0.0647\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0644 - val_loss: 0.0613\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0612 - val_loss: 0.0599\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0608 - val_loss: 0.0591\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0592 - val_loss: 0.0587\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0586 - val_loss: 0.0584\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0587 - val_loss: 0.0582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 11:01:12,697] Trial 96 finished with value: 0.05823053792119026 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3373"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1710324075.475911    4005 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_1', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - loss: 0.3368 - val_loss: 0.2711\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.2273 - val_loss: 0.1218\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1131 - val_loss: 0.1012\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1004 - val_loss: 0.0931\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0939 - val_loss: 0.0863\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0872 - val_loss: 0.0809\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0821 - val_loss: 0.0771\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0768 - val_loss: 0.0740\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0740 - val_loss: 0.0714\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0708 - val_loss: 0.0691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 11:01:21,009] Trial 97 finished with value: 0.06906455755233765 and parameters: {'num_layers': 1, 'num_filters_0': 3, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - loss: 0.2363 - val_loss: 0.1053\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0997 - val_loss: 0.0846\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0831 - val_loss: 0.0683\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0682 - val_loss: 0.0630\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0631 - val_loss: 0.0607\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0611 - val_loss: 0.0597\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0603 - val_loss: 0.0590\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0608 - val_loss: 0.0585\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0597 - val_loss: 0.0581\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0601 - val_loss: 0.0579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 11:01:34,579] Trial 98 finished with value: 0.05790617689490318 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - loss: 0.2205 - val_loss: 0.1085\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.1016 - val_loss: 0.0844\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0811 - val_loss: 0.0681\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0678 - val_loss: 0.0629\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0631 - val_loss: 0.0609\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0608 - val_loss: 0.0599\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0592 - val_loss: 0.0593\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0609 - val_loss: 0.0588\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0603 - val_loss: 0.0585\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0595 - val_loss: 0.0584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 11:01:48,022] Trial 99 finished with value: 0.0583634190261364 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - loss: 0.2458 - val_loss: 0.1091\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.1055 - val_loss: 0.0907\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0859 - val_loss: 0.0710\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0699 - val_loss: 0.0630\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0633 - val_loss: 0.0605\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0612 - val_loss: 0.0595\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0594 - val_loss: 0.0589\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0593 - val_loss: 0.0584\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0589 - val_loss: 0.0581\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0594 - val_loss: 0.0579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 11:02:01,555] Trial 100 finished with value: 0.05785254016518593 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - loss: 0.2241 - val_loss: 0.1098\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.1046 - val_loss: 0.0873\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0831 - val_loss: 0.0701\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0697 - val_loss: 0.0635\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0635 - val_loss: 0.0608\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0613 - val_loss: 0.0597\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0603 - val_loss: 0.0591\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0590 - val_loss: 0.0588\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0605 - val_loss: 0.0585\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0595 - val_loss: 0.0581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 11:02:15,205] Trial 101 finished with value: 0.0580935925245285 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - loss: 0.2353 - val_loss: 0.1109\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.1038 - val_loss: 0.0797\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0778 - val_loss: 0.0684\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0675 - val_loss: 0.0626\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0622 - val_loss: 0.0603\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0598 - val_loss: 0.0595\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0599 - val_loss: 0.0594\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0591 - val_loss: 0.0584\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0588 - val_loss: 0.0580\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0588 - val_loss: 0.0578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 11:02:28,428] Trial 102 finished with value: 0.05779879912734032 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - loss: 0.2319 - val_loss: 0.1118\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.1058 - val_loss: 0.0867\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0820 - val_loss: 0.0692\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0664 - val_loss: 0.0623\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0626 - val_loss: 0.0604\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0611 - val_loss: 0.0594\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0601 - val_loss: 0.0588\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0589 - val_loss: 0.0583\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0589 - val_loss: 0.0580\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0576 - val_loss: 0.0577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 11:02:41,055] Trial 103 finished with value: 0.05771568790078163 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 0.2237 - val_loss: 0.1020\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0970 - val_loss: 0.0793\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0768 - val_loss: 0.0677\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0663 - val_loss: 0.0626\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0625 - val_loss: 0.0604\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0613 - val_loss: 0.0594\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0604 - val_loss: 0.0588\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0600 - val_loss: 0.0583\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0589 - val_loss: 0.0580\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0596 - val_loss: 0.0577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 11:02:53,233] Trial 104 finished with value: 0.05772814527153969 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - loss: 0.2141 - val_loss: 0.1089\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.1024 - val_loss: 0.0816\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0785 - val_loss: 0.0673\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0663 - val_loss: 0.0629\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0623 - val_loss: 0.0606\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0614 - val_loss: 0.0594\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0608 - val_loss: 0.0587\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0606 - val_loss: 0.0583\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0596 - val_loss: 0.0579\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0587 - val_loss: 0.0577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 11:03:05,576] Trial 105 finished with value: 0.05770755559206009 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - loss: 0.2353 - val_loss: 0.1134\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.1091 - val_loss: 0.0886\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0831 - val_loss: 0.0691\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0672 - val_loss: 0.0623\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0624 - val_loss: 0.0604\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0601 - val_loss: 0.0594\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0589 - val_loss: 0.0588\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0586 - val_loss: 0.0584\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0590 - val_loss: 0.0581\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0587 - val_loss: 0.0579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 11:03:17,944] Trial 106 finished with value: 0.057860326021909714 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - loss: 0.2483 - val_loss: 0.1225\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1182 - val_loss: 0.1043\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1033 - val_loss: 0.0954\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0936 - val_loss: 0.0835\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0839 - val_loss: 0.0735\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0730 - val_loss: 0.0684\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0676 - val_loss: 0.0656\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0659 - val_loss: 0.0640\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0643 - val_loss: 0.0628\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0644 - val_loss: 0.0619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 11:03:27,597] Trial 107 finished with value: 0.0619446262717247 and parameters: {'num_layers': 1, 'num_filters_0': 6, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - loss: 0.2351 - val_loss: 0.1146\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.1085 - val_loss: 0.0866\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0826 - val_loss: 0.0712\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0704 - val_loss: 0.0651\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0633 - val_loss: 0.0616\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0617 - val_loss: 0.0602\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0603 - val_loss: 0.0596\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0598 - val_loss: 0.0590\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0588 - val_loss: 0.0587\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0601 - val_loss: 0.0584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 11:03:39,307] Trial 108 finished with value: 0.058364927768707275 and parameters: {'num_layers': 1, 'num_filters_0': 9, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - loss: 0.2094 - val_loss: 0.1079\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.1026 - val_loss: 0.0871\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0819 - val_loss: 0.0694\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0700 - val_loss: 0.0635\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0638 - val_loss: 0.0608\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0614 - val_loss: 0.0596\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0603 - val_loss: 0.0589\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0586 - val_loss: 0.0584\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0586 - val_loss: 0.0581\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0595 - val_loss: 0.0578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 11:03:52,444] Trial 109 finished with value: 0.057776693254709244 and parameters: {'num_layers': 1, 'num_filters_0': 12, 'kernel_size': 8, 'activation': 'relu'}. Best is trial 71 with value: 0.05757271870970726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Loss: 0.05757271870970726\n",
      "  Params: \n",
      "    num_layers: 2\n",
      "    num_filters_0: 12\n",
      "    num_filters_1: 9\n",
      "    kernel_size: 8\n",
      "    activation: relu\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (80, 80, 3)\n",
    "\n",
    "\n",
    "def create_model(trial):\n",
    "    # Define the parameters to search over\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 4)\n",
    "    num_filters = [trial.suggest_categorical(\n",
    "        f'num_filters_{i}', [3, 6, 9, 12]) for i in range(num_layers)]\n",
    "    kernel_size = trial.suggest_categorical('kernel_size', [4, 8])\n",
    "    activation = trial.suggest_categorical('activation', ['relu', 'selu'])\n",
    "\n",
    "    # Define the input layer\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    x = inputs\n",
    "    for i in range(num_layers):\n",
    "        x = Conv2D(num_filters[i], kernel_size,\n",
    "                   activation=activation, padding='same')(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "\n",
    "    # Decoder\n",
    "    for i in range(num_layers - 1, -1, -1):\n",
    "        x = Conv2DTranspose(num_filters[i], kernel_size, strides=(\n",
    "            2, 2), activation=activation, padding='same')(x)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = Conv2D(input_shape[-1], kernel_size,\n",
    "                     activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Create model\n",
    "    model = create_model(trial)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=Adam(), loss='mse')\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(train_set, train_set, batch_size=64, epochs=10,\n",
    "                        validation_data=(valid_set, valid_set))\n",
    "\n",
    "    # Return validation loss\n",
    "    return history.history['val_loss'][-1]\n",
    "\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction='minimize', study_name='autoencoder',\n",
    "                            storage='sqlite:///autoencoder.db', load_if_exists=True)\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print best hyperparameters\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print(f'  Loss: {trial.value}')\n",
    "print('  Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print(f'    {key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a4ee91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - loss: 0.2681 - val_loss: 0.1410\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1272 - val_loss: 0.1112\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1109 - val_loss: 0.1061\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1034 - val_loss: 0.0829\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0785 - val_loss: 0.0655\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0661 - val_loss: 0.0612\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0599 - val_loss: 0.0596\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0613 - val_loss: 0.0587\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0601 - val_loss: 0.0581\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0590 - val_loss: 0.0577\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05915943533182144"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_encoder = create_model(trial)\n",
    "auto_encoder.compile(optimizer=Adam(), loss='mse')\n",
    "auto_encoder.fit(train_set, train_set, batch_size=64, epochs=10,\n",
    "                 validation_data=(valid_set, valid_set))\n",
    "\n",
    "auto_encoder.evaluate(test_set, test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "881954d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_207\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_207\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_103 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_261 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,316</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_158               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                  │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_262 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,921</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_159               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                  │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_158            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,193</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_159            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,924</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_263 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,307</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_103 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_261 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m12\u001b[0m)     │         \u001b[38;5;34m2,316\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_158               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m12\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                  │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_262 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m9\u001b[0m)      │         \u001b[38;5;34m6,921\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_159               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m9\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                  │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_158            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m9\u001b[0m)      │         \u001b[38;5;34m5,193\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_159            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m12\u001b[0m)     │         \u001b[38;5;34m6,924\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_263 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │         \u001b[38;5;34m2,307\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,985</span> (277.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m70,985\u001b[0m (277.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,661</span> (92.43 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,661\u001b[0m (92.43 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,324</span> (184.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m47,324\u001b[0m (184.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "auto_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ec8da05-b5d5-4007-b54a-5e541cd1c87e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-o\u001b[39m\u001b[38;5;124m\"\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-o\u001b[39m\u001b[38;5;124m\"\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history[\"loss\"], \"-o\", label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"], \"-o\", label=\"validation loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Mean Squared Error\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bcf1b7-7f37-47c1-b87e-b02b4a50f46e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Autoencoder visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f74b0a4-0ea5-41e4-be4e-afd42275094f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x79b19d9ab310>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 25\n",
    "in_sim = test_set[i : i + 1]\n",
    "out_sim = auto_encoder(in_sim)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "ax[0].imshow(in_sim[0, ..., 2], vmin=-1, vmax=1, cmap=\"RdBu\")\n",
    "ax[1].imshow(out_sim[0, ..., 2], vmin=-1, vmax=1, cmap=\"RdBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5a76cc-4983-4679-b63c-fd418f1795a4",
   "metadata": {},
   "source": [
    "## Feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39f9c157-6556-4505-b2d7-8a86e6670122",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_261 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,316</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_158               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                  │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_262 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,921</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_159               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                  │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3600</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_261 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m12\u001b[0m)     │         \u001b[38;5;34m2,316\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_158               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m12\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                  │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_262 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m9\u001b[0m)      │         \u001b[38;5;34m6,921\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_159               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m9\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                  │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3600\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,237</span> (36.08 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,237\u001b[0m (36.08 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,237</span> (36.08 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,237\u001b[0m (36.08 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_extractor = tf.keras.models.Sequential(\n",
    "    [   # first 5 layers of the autoencoder\n",
    "        auto_encoder.layers[0],\n",
    "        auto_encoder.layers[1],\n",
    "        auto_encoder.layers[2],\n",
    "        auto_encoder.layers[3],\n",
    "        auto_encoder.layers[4],\n",
    "        tf.keras.layers.Flatten(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f03815ff-861e-4666-8943-fb590e0fdb5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feat_shape = auto_encoder.layers[4].output.shape[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "408381ec-5ad7-44a0-bed7-7bd12b1f5781",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 2s - 18ms/step\n"
     ]
    }
   ],
   "source": [
    "feature_arr = feature_extractor.predict(sim_arr, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5c72a9-28a9-473c-9c8a-d7f488631220",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81a4acae-8a75-4fa4-a7b3-d110458d4885",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14c65b3a-b2be-4d0a-963a-fc462f62cbbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "neighbors = NearestNeighbors(n_neighbors=5)\n",
    "neighbors_fit = neighbors.fit(feature_arr)\n",
    "distances, indices = neighbors_fit.kneighbors(feature_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36d57350-24dd-44df-a685-3d60981768bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "distances_sorted = np.sort(distances, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "657f6930-a2f0-411f-ab5e-8afedf8a595b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/paper-2023-machine-learning-based-classification-of-magnetization-main/.venv/lib/python3.11/site-packages/IPython/core/formatters.py:925\u001b[0m, in \u001b[0;36mIPythonDisplayFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    923\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 925\u001b[0m     \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    926\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/paper-2023-machine-learning-based-classification-of-magnetization-main/.venv/lib/python3.11/site-packages/plotly/basedatatypes.py:832\u001b[0m, in \u001b[0;36mBaseFigure._ipython_display_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpio\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pio\u001b[38;5;241m.\u001b[39mrenderers\u001b[38;5;241m.\u001b[39mrender_on_display \u001b[38;5;129;01mand\u001b[39;00m pio\u001b[38;5;241m.\u001b[39mrenderers\u001b[38;5;241m.\u001b[39mdefault:\n\u001b[0;32m--> 832\u001b[0m     \u001b[43mpio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n",
      "File \u001b[0;32m~/paper-2023-machine-learning-based-classification-of-magnetization-main/.venv/lib/python3.11/site-packages/plotly/io/_renderers.py:394\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    390\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m         )\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nbformat \u001b[38;5;129;01mor\u001b[39;00m Version(nbformat\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 394\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    395\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    396\u001b[0m         )\n\u001b[1;32m    398\u001b[0m     ipython_display\u001b[38;5;241m.\u001b[39mdisplay(bundle, raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    400\u001b[0m \u001b[38;5;66;03m# external renderers\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999,
          1000,
          1001,
          1002,
          1003,
          1004,
          1005,
          1006,
          1007,
          1008,
          1009,
          1010,
          1011,
          1012,
          1013,
          1014,
          1015,
          1016,
          1017,
          1018,
          1019,
          1020,
          1021,
          1022,
          1023,
          1024,
          1025,
          1026,
          1027,
          1028,
          1029,
          1030,
          1031,
          1032,
          1033,
          1034,
          1035,
          1036,
          1037,
          1038,
          1039,
          1040,
          1041,
          1042,
          1043,
          1044,
          1045,
          1046,
          1047,
          1048,
          1049,
          1050,
          1051,
          1052,
          1053,
          1054,
          1055,
          1056,
          1057,
          1058,
          1059,
          1060,
          1061,
          1062,
          1063,
          1064,
          1065,
          1066,
          1067,
          1068,
          1069,
          1070,
          1071,
          1072,
          1073,
          1074,
          1075,
          1076,
          1077,
          1078,
          1079,
          1080,
          1081,
          1082,
          1083,
          1084,
          1085,
          1086,
          1087,
          1088,
          1089,
          1090,
          1091,
          1092,
          1093,
          1094,
          1095,
          1096,
          1097,
          1098,
          1099,
          1100,
          1101,
          1102,
          1103,
          1104,
          1105,
          1106,
          1107,
          1108,
          1109,
          1110,
          1111,
          1112,
          1113,
          1114,
          1115,
          1116,
          1117,
          1118,
          1119,
          1120,
          1121,
          1122,
          1123,
          1124,
          1125,
          1126,
          1127,
          1128,
          1129,
          1130,
          1131,
          1132,
          1133,
          1134,
          1135,
          1136,
          1137,
          1138,
          1139,
          1140,
          1141,
          1142,
          1143,
          1144,
          1145,
          1146,
          1147,
          1148,
          1149,
          1150,
          1151,
          1152,
          1153,
          1154,
          1155,
          1156,
          1157,
          1158,
          1159,
          1160,
          1161,
          1162,
          1163,
          1164,
          1165,
          1166,
          1167,
          1168,
          1169,
          1170,
          1171,
          1172,
          1173,
          1174,
          1175,
          1176,
          1177,
          1178,
          1179,
          1180,
          1181,
          1182,
          1183,
          1184,
          1185,
          1186,
          1187,
          1188,
          1189,
          1190,
          1191,
          1192,
          1193,
          1194,
          1195,
          1196,
          1197,
          1198,
          1199,
          1200,
          1201,
          1202,
          1203,
          1204,
          1205,
          1206,
          1207,
          1208,
          1209,
          1210,
          1211,
          1212,
          1213,
          1214,
          1215,
          1216,
          1217,
          1218,
          1219,
          1220,
          1221,
          1222,
          1223,
          1224,
          1225,
          1226,
          1227,
          1228,
          1229,
          1230,
          1231,
          1232,
          1233,
          1234,
          1235,
          1236,
          1237,
          1238,
          1239,
          1240,
          1241,
          1242,
          1243,
          1244,
          1245,
          1246,
          1247,
          1248,
          1249,
          1250,
          1251,
          1252,
          1253,
          1254,
          1255,
          1256,
          1257,
          1258,
          1259,
          1260,
          1261,
          1262,
          1263,
          1264,
          1265,
          1266,
          1267,
          1268,
          1269,
          1270,
          1271,
          1272,
          1273,
          1274,
          1275,
          1276,
          1277,
          1278,
          1279,
          1280,
          1281,
          1282,
          1283,
          1284,
          1285,
          1286,
          1287,
          1288,
          1289,
          1290,
          1291,
          1292,
          1293,
          1294,
          1295,
          1296,
          1297,
          1298,
          1299,
          1300,
          1301,
          1302,
          1303,
          1304,
          1305,
          1306,
          1307,
          1308,
          1309,
          1310,
          1311,
          1312,
          1313,
          1314,
          1315,
          1316,
          1317,
          1318,
          1319,
          1320,
          1321,
          1322,
          1323,
          1324,
          1325,
          1326,
          1327,
          1328,
          1329,
          1330,
          1331,
          1332,
          1333,
          1334,
          1335,
          1336,
          1337,
          1338,
          1339,
          1340,
          1341,
          1342,
          1343,
          1344,
          1345,
          1346,
          1347,
          1348,
          1349,
          1350,
          1351,
          1352,
          1353,
          1354,
          1355,
          1356,
          1357,
          1358,
          1359,
          1360,
          1361,
          1362,
          1363,
          1364,
          1365,
          1366,
          1367,
          1368,
          1369,
          1370,
          1371,
          1372,
          1373,
          1374,
          1375,
          1376,
          1377,
          1378,
          1379,
          1380,
          1381,
          1382,
          1383,
          1384,
          1385,
          1386,
          1387,
          1388,
          1389,
          1390,
          1391,
          1392,
          1393,
          1394,
          1395,
          1396,
          1397,
          1398,
          1399,
          1400,
          1401,
          1402,
          1403,
          1404,
          1405,
          1406,
          1407,
          1408,
          1409,
          1410,
          1411,
          1412,
          1413,
          1414,
          1415,
          1416,
          1417,
          1418,
          1419,
          1420,
          1421,
          1422,
          1423,
          1424,
          1425,
          1426,
          1427,
          1428,
          1429,
          1430,
          1431,
          1432,
          1433,
          1434,
          1435,
          1436,
          1437,
          1438,
          1439,
          1440,
          1441,
          1442,
          1443,
          1444,
          1445,
          1446,
          1447,
          1448,
          1449,
          1450,
          1451,
          1452,
          1453,
          1454,
          1455,
          1456,
          1457,
          1458,
          1459,
          1460,
          1461,
          1462,
          1463,
          1464,
          1465,
          1466,
          1467,
          1468,
          1469,
          1470,
          1471,
          1472,
          1473,
          1474,
          1475,
          1476,
          1477,
          1478,
          1479,
          1480,
          1481,
          1482,
          1483,
          1484,
          1485,
          1486,
          1487,
          1488,
          1489,
          1490,
          1491,
          1492,
          1493,
          1494,
          1495,
          1496,
          1497,
          1498,
          1499,
          1500,
          1501,
          1502,
          1503,
          1504,
          1505,
          1506,
          1507,
          1508,
          1509,
          1510,
          1511,
          1512,
          1513,
          1514,
          1515,
          1516,
          1517,
          1518,
          1519,
          1520,
          1521,
          1522,
          1523,
          1524,
          1525,
          1526,
          1527,
          1528,
          1529,
          1530,
          1531,
          1532,
          1533,
          1534,
          1535,
          1536,
          1537,
          1538,
          1539,
          1540,
          1541,
          1542,
          1543,
          1544,
          1545,
          1546,
          1547,
          1548,
          1549,
          1550,
          1551,
          1552,
          1553,
          1554,
          1555,
          1556,
          1557,
          1558,
          1559,
          1560,
          1561,
          1562,
          1563,
          1564,
          1565,
          1566,
          1567,
          1568,
          1569,
          1570,
          1571,
          1572,
          1573,
          1574,
          1575,
          1576,
          1577,
          1578,
          1579,
          1580,
          1581,
          1582,
          1583,
          1584,
          1585,
          1586,
          1587,
          1588,
          1589,
          1590,
          1591,
          1592,
          1593,
          1594,
          1595,
          1596,
          1597,
          1598,
          1599,
          1600,
          1601,
          1602,
          1603,
          1604,
          1605,
          1606,
          1607,
          1608,
          1609,
          1610,
          1611,
          1612,
          1613,
          1614,
          1615,
          1616,
          1617,
          1618,
          1619,
          1620,
          1621,
          1622,
          1623,
          1624,
          1625,
          1626,
          1627,
          1628,
          1629,
          1630,
          1631,
          1632,
          1633,
          1634,
          1635,
          1636,
          1637,
          1638,
          1639,
          1640,
          1641,
          1642,
          1643,
          1644,
          1645,
          1646,
          1647,
          1648,
          1649,
          1650,
          1651,
          1652,
          1653,
          1654,
          1655,
          1656,
          1657,
          1658,
          1659,
          1660,
          1661,
          1662,
          1663,
          1664,
          1665,
          1666,
          1667,
          1668,
          1669,
          1670,
          1671,
          1672,
          1673,
          1674,
          1675,
          1676,
          1677,
          1678,
          1679,
          1680,
          1681,
          1682,
          1683,
          1684,
          1685,
          1686,
          1687,
          1688,
          1689,
          1690,
          1691,
          1692,
          1693,
          1694,
          1695,
          1696,
          1697,
          1698,
          1699,
          1700,
          1701,
          1702,
          1703,
          1704,
          1705,
          1706,
          1707,
          1708,
          1709,
          1710,
          1711,
          1712,
          1713,
          1714,
          1715,
          1716,
          1717,
          1718,
          1719,
          1720,
          1721,
          1722,
          1723,
          1724,
          1725,
          1726,
          1727,
          1728,
          1729,
          1730,
          1731,
          1732,
          1733,
          1734,
          1735,
          1736,
          1737,
          1738,
          1739,
          1740,
          1741,
          1742,
          1743,
          1744,
          1745,
          1746,
          1747,
          1748,
          1749,
          1750,
          1751,
          1752,
          1753,
          1754,
          1755,
          1756,
          1757,
          1758,
          1759,
          1760,
          1761,
          1762,
          1763,
          1764,
          1765,
          1766,
          1767,
          1768,
          1769,
          1770,
          1771,
          1772,
          1773,
          1774,
          1775,
          1776,
          1777,
          1778,
          1779,
          1780,
          1781,
          1782,
          1783,
          1784,
          1785,
          1786,
          1787,
          1788,
          1789,
          1790,
          1791,
          1792,
          1793,
          1794,
          1795,
          1796,
          1797,
          1798,
          1799,
          1800,
          1801,
          1802,
          1803,
          1804,
          1805,
          1806,
          1807,
          1808,
          1809,
          1810,
          1811,
          1812,
          1813,
          1814,
          1815,
          1816,
          1817,
          1818,
          1819,
          1820,
          1821,
          1822,
          1823,
          1824,
          1825,
          1826,
          1827,
          1828,
          1829,
          1830,
          1831,
          1832,
          1833,
          1834,
          1835,
          1836,
          1837,
          1838,
          1839,
          1840,
          1841,
          1842,
          1843,
          1844,
          1845,
          1846,
          1847,
          1848,
          1849,
          1850,
          1851,
          1852,
          1853,
          1854,
          1855,
          1856,
          1857,
          1858,
          1859,
          1860,
          1861,
          1862,
          1863,
          1864,
          1865,
          1866,
          1867,
          1868,
          1869,
          1870,
          1871,
          1872,
          1873,
          1874,
          1875,
          1876,
          1877,
          1878,
          1879,
          1880,
          1881,
          1882,
          1883,
          1884,
          1885,
          1886,
          1887,
          1888,
          1889,
          1890,
          1891,
          1892,
          1893,
          1894,
          1895,
          1896,
          1897,
          1898,
          1899,
          1900,
          1901,
          1902,
          1903,
          1904,
          1905,
          1906,
          1907,
          1908,
          1909,
          1910,
          1911,
          1912,
          1913,
          1914,
          1915,
          1916,
          1917,
          1918,
          1919,
          1920,
          1921,
          1922,
          1923,
          1924,
          1925,
          1926,
          1927,
          1928,
          1929,
          1930,
          1931,
          1932,
          1933,
          1934,
          1935,
          1936,
          1937,
          1938,
          1939,
          1940,
          1941,
          1942,
          1943,
          1944,
          1945,
          1946,
          1947,
          1948,
          1949,
          1950,
          1951,
          1952,
          1953,
          1954,
          1955,
          1956,
          1957,
          1958,
          1959,
          1960,
          1961,
          1962,
          1963,
          1964,
          1965,
          1966,
          1967,
          1968,
          1969,
          1970,
          1971,
          1972,
          1973,
          1974,
          1975,
          1976,
          1977,
          1978,
          1979,
          1980,
          1981,
          1982,
          1983,
          1984,
          1985,
          1986,
          1987,
          1988,
          1989,
          1990,
          1991,
          1992,
          1993,
          1994,
          1995,
          1996,
          1997,
          1998,
          1999,
          2000,
          2001,
          2002,
          2003,
          2004,
          2005,
          2006,
          2007,
          2008,
          2009,
          2010,
          2011,
          2012,
          2013,
          2014,
          2015,
          2016,
          2017,
          2018,
          2019,
          2020,
          2021,
          2022,
          2023,
          2024,
          2025,
          2026,
          2027,
          2028,
          2029,
          2030,
          2031,
          2032,
          2033,
          2034,
          2035,
          2036,
          2037,
          2038,
          2039,
          2040,
          2041,
          2042,
          2043,
          2044,
          2045,
          2046,
          2047,
          2048,
          2049,
          2050,
          2051,
          2052,
          2053,
          2054,
          2055,
          2056,
          2057,
          2058,
          2059,
          2060,
          2061,
          2062,
          2063,
          2064,
          2065,
          2066,
          2067,
          2068,
          2069,
          2070,
          2071,
          2072,
          2073,
          2074,
          2075,
          2076,
          2077,
          2078,
          2079,
          2080,
          2081,
          2082,
          2083,
          2084,
          2085,
          2086,
          2087,
          2088,
          2089,
          2090,
          2091,
          2092,
          2093,
          2094,
          2095,
          2096,
          2097,
          2098,
          2099,
          2100,
          2101,
          2102,
          2103,
          2104,
          2105,
          2106,
          2107,
          2108,
          2109,
          2110,
          2111,
          2112,
          2113,
          2114,
          2115,
          2116,
          2117,
          2118,
          2119,
          2120,
          2121,
          2122,
          2123,
          2124,
          2125,
          2126,
          2127,
          2128,
          2129,
          2130,
          2131,
          2132,
          2133,
          2134,
          2135,
          2136,
          2137,
          2138,
          2139,
          2140,
          2141,
          2142,
          2143,
          2144,
          2145,
          2146,
          2147,
          2148,
          2149,
          2150,
          2151,
          2152,
          2153,
          2154,
          2155,
          2156,
          2157,
          2158,
          2159,
          2160,
          2161,
          2162,
          2163,
          2164,
          2165,
          2166,
          2167,
          2168,
          2169,
          2170,
          2171,
          2172,
          2173,
          2174,
          2175,
          2176,
          2177,
          2178,
          2179,
          2180,
          2181,
          2182,
          2183,
          2184,
          2185,
          2186,
          2187,
          2188,
          2189,
          2190,
          2191,
          2192,
          2193,
          2194,
          2195,
          2196,
          2197,
          2198,
          2199,
          2200,
          2201,
          2202,
          2203,
          2204,
          2205,
          2206,
          2207,
          2208,
          2209,
          2210,
          2211,
          2212,
          2213,
          2214,
          2215,
          2216,
          2217,
          2218,
          2219,
          2220,
          2221,
          2222,
          2223,
          2224,
          2225,
          2226,
          2227,
          2228,
          2229,
          2230,
          2231,
          2232,
          2233,
          2234,
          2235,
          2236,
          2237,
          2238,
          2239,
          2240,
          2241,
          2242,
          2243,
          2244,
          2245,
          2246,
          2247,
          2248,
          2249,
          2250,
          2251,
          2252,
          2253,
          2254,
          2255,
          2256,
          2257,
          2258,
          2259,
          2260,
          2261,
          2262,
          2263,
          2264,
          2265,
          2266,
          2267,
          2268,
          2269,
          2270,
          2271,
          2272,
          2273,
          2274,
          2275,
          2276,
          2277,
          2278,
          2279,
          2280,
          2281,
          2282,
          2283,
          2284,
          2285,
          2286,
          2287,
          2288,
          2289,
          2290,
          2291,
          2292,
          2293,
          2294,
          2295,
          2296,
          2297,
          2298,
          2299,
          2300,
          2301,
          2302,
          2303,
          2304,
          2305,
          2306,
          2307,
          2308,
          2309,
          2310,
          2311,
          2312,
          2313,
          2314,
          2315,
          2316,
          2317,
          2318,
          2319,
          2320,
          2321,
          2322,
          2323,
          2324,
          2325,
          2326,
          2327,
          2328,
          2329,
          2330,
          2331,
          2332,
          2333,
          2334,
          2335,
          2336,
          2337,
          2338,
          2339,
          2340,
          2341,
          2342,
          2343,
          2344,
          2345,
          2346,
          2347,
          2348,
          2349,
          2350,
          2351,
          2352,
          2353,
          2354,
          2355,
          2356,
          2357,
          2358,
          2359,
          2360,
          2361,
          2362,
          2363,
          2364,
          2365,
          2366,
          2367,
          2368,
          2369,
          2370,
          2371,
          2372,
          2373,
          2374,
          2375,
          2376,
          2377,
          2378,
          2379,
          2380,
          2381,
          2382,
          2383,
          2384,
          2385,
          2386,
          2387,
          2388,
          2389,
          2390,
          2391,
          2392,
          2393,
          2394,
          2395,
          2396,
          2397,
          2398,
          2399,
          2400,
          2401,
          2402,
          2403,
          2404,
          2405,
          2406,
          2407,
          2408,
          2409,
          2410,
          2411,
          2412,
          2413,
          2414,
          2415,
          2416,
          2417,
          2418,
          2419,
          2420,
          2421,
          2422,
          2423,
          2424,
          2425,
          2426,
          2427,
          2428,
          2429,
          2430,
          2431,
          2432,
          2433,
          2434,
          2435,
          2436,
          2437,
          2438,
          2439,
          2440,
          2441,
          2442,
          2443,
          2444,
          2445,
          2446,
          2447,
          2448,
          2449,
          2450,
          2451,
          2452,
          2453,
          2454,
          2455,
          2456,
          2457,
          2458,
          2459,
          2460,
          2461,
          2462,
          2463,
          2464,
          2465,
          2466,
          2467,
          2468,
          2469,
          2470,
          2471,
          2472,
          2473,
          2474,
          2475,
          2476,
          2477,
          2478,
          2479,
          2480,
          2481,
          2482,
          2483,
          2484,
          2485,
          2486,
          2487,
          2488,
          2489,
          2490,
          2491,
          2492,
          2493,
          2494,
          2495,
          2496,
          2497,
          2498,
          2499,
          2500,
          2501,
          2502,
          2503,
          2504,
          2505,
          2506,
          2507,
          2508,
          2509,
          2510,
          2511,
          2512,
          2513,
          2514,
          2515,
          2516,
          2517,
          2518,
          2519,
          2520,
          2521,
          2522,
          2523,
          2524,
          2525,
          2526,
          2527,
          2528,
          2529,
          2530,
          2531,
          2532,
          2533,
          2534,
          2535,
          2536,
          2537,
          2538,
          2539,
          2540,
          2541,
          2542,
          2543,
          2544,
          2545,
          2546,
          2547,
          2548,
          2549,
          2550,
          2551,
          2552,
          2553,
          2554,
          2555,
          2556,
          2557,
          2558,
          2559,
          2560,
          2561,
          2562,
          2563,
          2564,
          2565,
          2566,
          2567,
          2568,
          2569,
          2570,
          2571,
          2572,
          2573,
          2574,
          2575,
          2576,
          2577,
          2578,
          2579,
          2580,
          2581,
          2582,
          2583,
          2584,
          2585,
          2586,
          2587,
          2588,
          2589,
          2590,
          2591,
          2592,
          2593,
          2594,
          2595,
          2596,
          2597,
          2598,
          2599,
          2600,
          2601,
          2602,
          2603,
          2604,
          2605,
          2606,
          2607,
          2608,
          2609,
          2610,
          2611,
          2612,
          2613,
          2614,
          2615,
          2616,
          2617,
          2618,
          2619,
          2620,
          2621,
          2622,
          2623,
          2624,
          2625,
          2626,
          2627,
          2628,
          2629,
          2630,
          2631,
          2632,
          2633,
          2634,
          2635,
          2636,
          2637,
          2638,
          2639,
          2640,
          2641,
          2642,
          2643,
          2644,
          2645,
          2646,
          2647,
          2648,
          2649,
          2650,
          2651,
          2652,
          2653,
          2654,
          2655,
          2656,
          2657,
          2658,
          2659,
          2660,
          2661,
          2662,
          2663,
          2664,
          2665,
          2666,
          2667,
          2668,
          2669,
          2670,
          2671,
          2672,
          2673,
          2674,
          2675,
          2676,
          2677,
          2678,
          2679,
          2680,
          2681,
          2682,
          2683,
          2684,
          2685,
          2686,
          2687,
          2688,
          2689,
          2690,
          2691,
          2692,
          2693,
          2694,
          2695,
          2696,
          2697,
          2698,
          2699,
          2700,
          2701,
          2702,
          2703,
          2704,
          2705,
          2706,
          2707,
          2708,
          2709,
          2710,
          2711,
          2712,
          2713,
          2714,
          2715,
          2716,
          2717,
          2718,
          2719,
          2720,
          2721,
          2722,
          2723,
          2724,
          2725,
          2726,
          2727,
          2728,
          2729,
          2730,
          2731,
          2732,
          2733,
          2734,
          2735,
          2736,
          2737,
          2738,
          2739,
          2740,
          2741,
          2742,
          2743,
          2744,
          2745,
          2746,
          2747,
          2748,
          2749,
          2750,
          2751,
          2752,
          2753,
          2754,
          2755,
          2756,
          2757,
          2758,
          2759,
          2760,
          2761,
          2762,
          2763,
          2764,
          2765,
          2766,
          2767,
          2768,
          2769,
          2770,
          2771,
          2772,
          2773,
          2774,
          2775,
          2776,
          2777,
          2778,
          2779,
          2780,
          2781,
          2782,
          2783,
          2784,
          2785,
          2786,
          2787,
          2788,
          2789,
          2790,
          2791,
          2792,
          2793,
          2794,
          2795,
          2796,
          2797,
          2798,
          2799,
          2800,
          2801,
          2802,
          2803,
          2804,
          2805,
          2806,
          2807,
          2808,
          2809,
          2810,
          2811,
          2812,
          2813,
          2814,
          2815,
          2816,
          2817,
          2818,
          2819,
          2820,
          2821,
          2822,
          2823,
          2824,
          2825,
          2826,
          2827,
          2828,
          2829,
          2830,
          2831,
          2832,
          2833,
          2834,
          2835,
          2836,
          2837,
          2838,
          2839,
          2840,
          2841,
          2842,
          2843,
          2844,
          2845,
          2846,
          2847,
          2848,
          2849,
          2850,
          2851,
          2852,
          2853,
          2854,
          2855,
          2856,
          2857,
          2858,
          2859,
          2860,
          2861,
          2862,
          2863,
          2864,
          2865,
          2866,
          2867,
          2868,
          2869,
          2870,
          2871,
          2872,
          2873,
          2874,
          2875,
          2876,
          2877,
          2878,
          2879,
          2880,
          2881,
          2882,
          2883,
          2884,
          2885,
          2886,
          2887,
          2888,
          2889,
          2890,
          2891,
          2892,
          2893,
          2894,
          2895,
          2896,
          2897,
          2898,
          2899,
          2900,
          2901,
          2902,
          2903,
          2904,
          2905,
          2906,
          2907,
          2908,
          2909,
          2910,
          2911,
          2912,
          2913,
          2914,
          2915,
          2916,
          2917,
          2918,
          2919,
          2920,
          2921,
          2922,
          2923,
          2924,
          2925,
          2926,
          2927,
          2928,
          2929,
          2930,
          2931,
          2932,
          2933,
          2934,
          2935,
          2936,
          2937,
          2938,
          2939,
          2940,
          2941,
          2942,
          2943,
          2944,
          2945,
          2946,
          2947,
          2948,
          2949,
          2950,
          2951,
          2952,
          2953,
          2954,
          2955,
          2956,
          2957,
          2958,
          2959,
          2960,
          2961,
          2962,
          2963,
          2964,
          2965,
          2966,
          2967,
          2968,
          2969,
          2970,
          2971,
          2972,
          2973,
          2974,
          2975,
          2976,
          2977,
          2978,
          2979,
          2980,
          2981,
          2982,
          2983,
          2984,
          2985,
          2986,
          2987,
          2988,
          2989,
          2990,
          2991,
          2992,
          2993,
          2994,
          2995,
          2996,
          2997,
          2998,
          2999,
          3000,
          3001,
          3002,
          3003,
          3004,
          3005,
          3006,
          3007,
          3008,
          3009
         ],
         "y": [
          0.000023822776711313054,
          0.000023975000658538193,
          0.00002412626417935826,
          0.00002427658546366729,
          0.000024425980882369913,
          0.000024425980882369913,
          0.00002457446862536017,
          0.000024722063244553283,
          0.000024722063244553283,
          0.000024722063244553283,
          0.000024722063244553283,
          0.000024722063244553283,
          0.000024722063244553283,
          0.000024722063244553283,
          0.000024722063244553283,
          0.00002486878292984329,
          0.00002486878292984329,
          0.00002486878292984329,
          0.000025014642233145423,
          0.000025014642233145423,
          0.000025014642233145423,
          0.000025014642233145423,
          0.000025014642233145423,
          0.000025014642233145423,
          0.000025014642233145423,
          0.000025014642233145423,
          0.000025159655706374906,
          0.000025159655706374906,
          0.000025303839720436372,
          0.000025303839720436372,
          0.000025303839720436372,
          0.000025303839720436372,
          0.000025303839720436372,
          0.000025303839720436372,
          0.000025303839720436372,
          0.000025303839720436372,
          0.000025303839720436372,
          0.000025303839720436372,
          0.000025303839720436372,
          0.000025303839720436372,
          0.000025303839720436372,
          0.000025303839720436372,
          0.000025303839720436372,
          0.000025447205189266242,
          0.000025589766664779745,
          0.000025589766664779745,
          0.000025589766664779745,
          0.000025589766664779745,
          0.000025589766664779745,
          0.000025589766664779745,
          0.000025589766664779745,
          0.000025589766664779745,
          0.000025589766664779745,
          0.000025589766664779745,
          0.000025589766664779745,
          0.000025589766664779745,
          0.000025589766664779745,
          0.000025589766664779745,
          0.000025589766664779745,
          0.000025589766664779745,
          0.000025589766664779745,
          0.000025731540517881513,
          0.000025731540517881513,
          0.000025731540517881513,
          0.000025731540517881513,
          0.000025731540517881513,
          0.000025731540517881513,
          0.000025731540517881513,
          0.000025731540517881513,
          0.000025872535843518563,
          0.000025872535843518563,
          0.000025872535843518563,
          0.000025872535843518563,
          0.000025872535843518563,
          0.000025872535843518563,
          0.000025872535843518563,
          0.000025872535843518563,
          0.000025872535843518563,
          0.000025872535843518563,
          0.000025872535843518563,
          0.000025872535843518563,
          0.000025872535843518563,
          0.000025872535843518563,
          0.000025872535843518563,
          0.000025872535843518563,
          0.000025872535843518563,
          0.000025872535843518563,
          0.000025872535843518563,
          0.000025872535843518563,
          0.000025872535843518563,
          0.000025872535843518563,
          0.000025872535843518563,
          0.000025872535843518563,
          0.000025872535843518563,
          0.000025872535843518563,
          0.000025872535843518563,
          0.000026012767193606123,
          0.000026012767193606123,
          0.000026012767193606123,
          0.000026012767193606123,
          0.000026012767193606123,
          0.000026012767193606123,
          0.000026012767193606123,
          0.000026012767193606123,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.00002615224730107002,
          0.000026290987079846673,
          0.000026290987079846673,
          0.000026290987079846673,
          0.000026290987079846673,
          0.000026290987079846673,
          0.000026290987079846673,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.000026428997443872504,
          0.00002656629294506274,
          0.00002656629294506274,
          0.00002656629294506274,
          0.00002656629294506274,
          0.00002656629294506274,
          0.00002656629294506274,
          0.000026702880859375,
          0.000026702880859375,
          0.000026702880859375,
          0.000026702880859375,
          0.000026702880859375,
          0.000026702880859375,
          0.000026702880859375,
          0.000026702880859375,
          0.000026702880859375,
          0.000026702880859375,
          0.000026702880859375,
          0.000026702880859375,
          0.000026702880859375,
          0.000026702880859375,
          0.000026702880859375,
          0.000026702880859375,
          0.000026702880859375,
          0.000026702880859375,
          0.000026702880859375,
          0.000026702880859375,
          0.000026702880859375,
          0.000026702880859375,
          0.000026702880859375,
          0.000026702880859375,
          0.000026702880859375,
          0.000026702880859375,
          0.000026702880859375,
          0.000026838773919735104,
          0.000026838773919735104,
          0.000026838773919735104,
          0.000026838773919735104,
          0.000026838773919735104,
          0.000026973983040079474,
          0.000026973983040079474,
          0.000026973983040079474,
          0.000026973983040079474,
          0.000026973983040079474,
          0.000026973983040079474,
          0.000026973983040079474,
          0.000026973983040079474,
          0.000026973983040079474,
          0.000026973983040079474,
          0.000026973983040079474,
          0.000026973983040079474,
          0.000026973983040079474,
          0.000026973983040079474,
          0.000026973983040079474,
          0.000026973983040079474,
          0.000026973983040079474,
          0.000026973983040079474,
          0.000026973983040079474,
          0.000026973983040079474,
          0.000026973983040079474,
          0.000026973983040079474,
          0.000026973983040079474,
          0.000026973983040079474,
          0.000026973983040079474,
          0.000026973983040079474,
          0.000026973983040079474,
          0.00002710851731535513,
          0.00002710851731535513,
          0.00002710851731535513,
          0.00002710851731535513,
          0.00002724238765949849,
          0.00002724238765949849,
          0.00002724238765949849,
          0.00002724238765949849,
          0.00002724238765949849,
          0.00002724238765949849,
          0.00002724238765949849,
          0.00002724238765949849,
          0.00002724238765949849,
          0.00002724238765949849,
          0.00002724238765949849,
          0.00002724238765949849,
          0.00002724238765949849,
          0.00002724238765949849,
          0.00002724238765949849,
          0.00002724238765949849,
          0.00002724238765949849,
          0.00002724238765949849,
          0.00002724238765949849,
          0.00002724238765949849,
          0.00002724238765949849,
          0.00002724238765949849,
          0.00002724238765949849,
          0.00002724238765949849,
          0.000027375603167456575,
          0.000027375603167456575,
          0.0000275081729341764,
          0.0000275081729341764,
          0.0000275081729341764,
          0.0000275081729341764,
          0.0000275081729341764,
          0.0000275081729341764,
          0.0000275081729341764,
          0.0000275081729341764,
          0.0000275081729341764,
          0.0000275081729341764,
          0.0000275081729341764,
          0.0000275081729341764,
          0.0000275081729341764,
          0.0000275081729341764,
          0.0000275081729341764,
          0.0000275081729341764,
          0.0000275081729341764,
          0.0000275081729341764,
          0.0000275081729341764,
          0.0000275081729341764,
          0.0000275081729341764,
          0.0000275081729341764,
          0.0000275081729341764,
          0.0000275081729341764,
          0.0000275081729341764,
          0.0000275081729341764,
          0.0000275081729341764,
          0.0000275081729341764,
          0.00002764010787359439,
          0.00002764010787359439,
          0.00002764010787359439,
          0.00002764010787359439,
          0.00002764010787359439,
          0.00002764010787359439,
          0.00002764010787359439,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027771415261668153,
          0.000027902104193344712,
          0.000027902104193344712,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028032185582560487,
          0.000028161664886283688,
          0.000028161664886283688,
          0.000028161664886283688,
          0.000028161664886283688,
          0.000028161664886283688,
          0.000028290551199461333,
          0.000028290551199461333,
          0.000028290551199461333,
          0.000028290551199461333,
          0.000028290551199461333,
          0.000028290551199461333,
          0.000028290551199461333,
          0.000028290551199461333,
          0.000028290551199461333,
          0.000028290551199461333,
          0.000028290551199461333,
          0.000028290551199461333,
          0.000028290551199461333,
          0.000028290551199461333,
          0.000028290551199461333,
          0.000028290551199461333,
          0.000028290551199461333,
          0.000028290551199461333,
          0.000028290551199461333,
          0.000028290551199461333,
          0.000028290551199461333,
          0.000028290551199461333,
          0.000028290551199461333,
          0.000028290551199461333,
          0.000028290551199461333,
          0.000028290551199461333,
          0.000028290551199461333,
          0.000028290551199461333,
          0.000028418855436029844,
          0.000028418855436029844,
          0.000028418855436029844,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.000028546581233968027,
          0.0000286737376882229,
          0.0000286737376882229,
          0.0000286737376882229,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028800332074752077,
          0.000028926373488502577,
          0.000028926373488502577,
          0.000028926373488502577,
          0.000028926373488502577,
          0.000028926373488502577,
          0.000029051869205432013,
          0.000029051869205432013,
          0.000029051869205432013,
          0.000029051869205432013,
          0.000029051869205432013,
          0.000029051869205432013,
          0.000029051869205432013,
          0.000029051869205432013,
          0.000029051869205432013,
          0.000029051869205432013,
          0.000029051869205432013,
          0.000029051869205432013,
          0.000029051869205432013,
          0.000029051869205432013,
          0.000029051869205432013,
          0.000029051869205432013,
          0.000029051869205432013,
          0.000029051869205432013,
          0.000029051869205432013,
          0.000029051869205432013,
          0.000029051869205432013,
          0.000029051869205432013,
          0.000029051869205432013,
          0.000029051869205432013,
          0.000029051869205432013,
          0.000029051869205432013,
          0.000029051869205432013,
          0.000029176822863519192,
          0.000029176822863519192,
          0.000029301245376700535,
          0.000029301245376700535,
          0.000029301245376700535,
          0.000029301245376700535,
          0.000029301245376700535,
          0.000029301245376700535,
          0.000029301245376700535,
          0.000029301245376700535,
          0.000029301245376700535,
          0.000029301245376700535,
          0.000029301245376700535,
          0.000029301245376700535,
          0.000029301245376700535,
          0.000029301245376700535,
          0.000029301245376700535,
          0.000029301245376700535,
          0.000029425142201944254,
          0.000029425142201944254,
          0.000029425142201944254,
          0.000029425142201944254,
          0.000029425142201944254,
          0.000029425142201944254,
          0.000029425142201944254,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002954851879621856,
          0.00002967138061649166,
          0.00002967138061649166,
          0.00002967138061649166,
          0.00002967138061649166,
          0.00002967138061649166,
          0.00002979373857669998,
          0.00002979373857669998,
          0.00002979373857669998,
          0.00002979373857669998,
          0.00002979373857669998,
          0.00002979373857669998,
          0.00002979373857669998,
          0.00002979373857669998,
          0.00002979373857669998,
          0.00002979373857669998,
          0.00002979373857669998,
          0.00002979373857669998,
          0.00002979373857669998,
          0.00002979373857669998,
          0.00002979373857669998,
          0.00002979373857669998,
          0.00002979373857669998,
          0.00002979373857669998,
          0.00002979373857669998,
          0.00002979373857669998,
          0.00002991559449583292,
          0.00002991559449583292,
          0.00002991559449583292,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030036955649848096,
          0.000030157829314703122,
          0.000030157829314703122,
          0.000030157829314703122,
          0.000030157829314703122,
          0.000030157829314703122,
          0.000030278220947366208,
          0.000030278220947366208,
          0.000030278220947366208,
          0.000030278220947366208,
          0.000030278220947366208,
          0.000030278220947366208,
          0.000030278220947366208,
          0.000030278220947366208,
          0.000030278220947366208,
          0.000030278220947366208,
          0.000030278220947366208,
          0.000030278220947366208,
          0.000030278220947366208,
          0.000030278220947366208,
          0.000030278220947366208,
          0.000030278220947366208,
          0.000030278220947366208,
          0.000030278220947366208,
          0.000030278220947366208,
          0.00003039813418581616,
          0.00003039813418581616,
          0.00003039813418581616,
          0.000030517578125,
          0.000030517578125,
          0.000030517578125,
          0.000030517578125,
          0.000030517578125,
          0.000030517578125,
          0.000030517578125,
          0.000030517578125,
          0.000030517578125,
          0.000030517578125,
          0.000030517578125,
          0.000030517578125,
          0.000030517578125,
          0.000030517578125,
          0.000030517578125,
          0.000030517578125,
          0.000030517578125,
          0.000030517578125,
          0.000030517578125,
          0.000030517578125,
          0.000030517578125,
          0.00003063655458390713,
          0.00003063655458390713,
          0.00003063655458390713,
          0.00003063655458390713,
          0.00003063655458390713,
          0.00003063655458390713,
          0.00003075507265748456,
          0.00003075507265748456,
          0.00003075507265748456,
          0.00003075507265748456,
          0.00003075507265748456,
          0.00003075507265748456,
          0.00003075507265748456,
          0.00003075507265748456,
          0.00003075507265748456,
          0.00003075507265748456,
          0.00003075507265748456,
          0.00003075507265748456,
          0.00003075507265748456,
          0.00003075507265748456,
          0.00003075507265748456,
          0.00003075507265748456,
          0.00003075507265748456,
          0.00003075507265748456,
          0.00003075507265748456,
          0.00003075507265748456,
          0.00003075507265748456,
          0.00003075507265748456,
          0.00003075507265748456,
          0.00003075507265748456,
          0.00003087313598371111,
          0.00003087313598371111,
          0.00003087313598371111,
          0.000030990748200565577,
          0.000030990748200565577,
          0.000030990748200565577,
          0.000030990748200565577,
          0.000030990748200565577,
          0.000030990748200565577,
          0.000030990748200565577,
          0.000030990748200565577,
          0.000030990748200565577,
          0.000030990748200565577,
          0.000030990748200565577,
          0.000030990748200565577,
          0.000030990748200565577,
          0.000030990748200565577,
          0.000030990748200565577,
          0.000030990748200565577,
          0.000030990748200565577,
          0.000030990748200565577,
          0.00003110791658400558,
          0.00003110791658400558,
          0.00003110791658400558,
          0.00003110791658400558,
          0.00003110791658400558,
          0.00003122464113403112,
          0.00003122464113403112,
          0.00003122464113403112,
          0.00003122464113403112,
          0.00003122464113403112,
          0.00003122464113403112,
          0.00003122464113403112,
          0.00003122464113403112,
          0.00003122464113403112,
          0.00003122464113403112,
          0.00003122464113403112,
          0.00003122464113403112,
          0.00003122464113403112,
          0.00003122464113403112,
          0.00003122464113403112,
          0.00003122464113403112,
          0.00003122464113403112,
          0.00003122464113403112,
          0.00003122464113403112,
          0.00003122464113403112,
          0.00003134093640255742,
          0.00003134093640255742,
          0.00003134093640255742,
          0.000031456798751605675,
          0.000031456798751605675,
          0.000031456798751605675,
          0.000031456798751605675,
          0.000031456798751605675,
          0.000031456798751605675,
          0.000031456798751605675,
          0.000031456798751605675,
          0.000031456798751605675,
          0.000031456798751605675,
          0.000031456798751605675,
          0.000031456798751605675,
          0.000031456798751605675,
          0.000031456798751605675,
          0.00003157223909511231,
          0.00003157223909511231,
          0.00003157223909511231,
          0.00003157223909511231,
          0.00003168725379509851,
          0.00003168725379509851,
          0.00003168725379509851,
          0.00003168725379509851,
          0.00003168725379509851,
          0.00003168725379509851,
          0.00003168725379509851,
          0.00003168725379509851,
          0.00003168725379509851,
          0.00003168725379509851,
          0.00003168725379509851,
          0.00003168725379509851,
          0.00003168725379509851,
          0.000031801857403479517,
          0.000031801857403479517,
          0.000031801857403479517,
          0.000031801857403479517,
          0.00003191604628227651,
          0.00003191604628227651,
          0.00003191604628227651,
          0.00003191604628227651,
          0.00003191604628227651,
          0.00003191604628227651,
          0.00003191604628227651,
          0.00003191604628227651,
          0.00003191604628227651,
          0.00003191604628227651,
          0.00003191604628227651,
          0.00003191604628227651,
          0.00003191604628227651,
          0.00003191604628227651,
          0.00003191604628227651,
          0.00003191604628227651,
          0.00003191604628227651,
          0.00003202983134542592,
          0.00003202983134542592,
          0.00003202983134542592,
          0.00003202983134542592,
          0.00003214320895494893,
          0.00003214320895494893,
          0.00003214320895494893,
          0.00003214320895494893,
          0.00003214320895494893,
          0.00003214320895494893,
          0.00003214320895494893,
          0.00003214320895494893,
          0.00003214320895494893,
          0.00003214320895494893,
          0.00003225619366276078,
          0.00003225619366276078,
          0.000032368778192903847,
          0.000032368778192903847,
          0.000032368778192903847,
          0.000032368778192903847,
          0.000032368778192903847,
          0.000032368778192903847,
          0.000032368778192903847,
          0.000032368778192903847,
          0.000032368778192903847,
          0.000032368778192903847,
          0.000032368778192903847,
          0.000032368778192903847,
          0.000032368778192903847,
          0.000032368778192903847,
          0.000032368778192903847,
          0.000032368778192903847,
          0.00003248097709729336,
          0.00003248097709729336,
          0.00003248097709729336,
          0.00003259278673795052,
          0.00003259278673795052,
          0.00003259278673795052,
          0.00003259278673795052,
          0.00003259278673795052,
          0.00003259278673795052,
          0.00003259278673795052,
          0.00003259278673795052,
          0.00003259278673795052,
          0.00003270421802881174,
          0.00003281526733189821,
          0.00003281526733189821,
          0.00003281526733189821,
          0.00003281526733189821,
          0.00003281526733189821,
          0.00003281526733189821,
          0.00003281526733189821,
          0.00003281526733189821,
          0.000032925941923167557,
          0.000032925941923167557,
          0.000032925941923167557,
          0.000032925941923167557,
          0.000032925941923167557,
          0.000032925941923167557,
          0.000032925941923167557,
          0.000033036249078577384,
          0.000033036249078577384,
          0.000033036249078577384,
          0.000033036249078577384,
          0.000033036249078577384,
          0.000033036249078577384,
          0.000033036249078577384,
          0.000033036249078577384,
          0.000033036249078577384,
          0.00003314618516014889,
          0.00003314618516014889,
          0.00003314618516014889,
          0.00003314618516014889,
          0.00003325576108181849,
          0.00003325576108181849,
          0.00003325576108181849,
          0.00003325576108181849,
          0.00003325576108181849,
          0.00003325576108181849,
          0.00003325576108181849,
          0.00003325576108181849,
          0.00003325576108181849,
          0.00003325576108181849,
          0.000033364973205607384,
          0.000033364973205607384,
          0.00003347383244545199,
          0.00003347383244545199,
          0.00003347383244545199,
          0.00003347383244545199,
          0.00003347383244545199,
          0.00003347383244545199,
          0.00003347383244545199,
          0.00003347383244545199,
          0.00003369049227330834,
          0.00003369049227330834,
          0.00003369049227330834,
          0.00003369049227330834,
          0.00003369049227330834,
          0.00003369049227330834,
          0.00003369049227330834,
          0.00003369049227330834,
          0.00003369049227330834,
          0.00003369049227330834,
          0.00003369049227330834,
          0.00003369049227330834,
          0.00003369049227330834,
          0.0000337983037752565,
          0.0000337983037752565,
          0.00003390576966921799,
          0.00003390576966921799,
          0.00003390576966921799,
          0.00003390576966921799,
          0.00003401289723115042,
          0.00003401289723115042,
          0.00003401289723115042,
          0.000034119690099032596,
          0.000034119690099032596,
          0.000034119690099032596,
          0.000034119690099032596,
          0.000034119690099032596,
          0.000034119690099032596,
          0.000034119690099032596,
          0.000034119690099032596,
          0.000034119690099032596,
          0.000034119690099032596,
          0.000034119690099032596,
          0.000034119690099032596,
          0.00003422614827286452,
          0.00003422614827286452,
          0.00003422614827286452,
          0.000034332275390625,
          0.000034332275390625,
          0.000034332275390625,
          0.000034332275390625,
          0.000034332275390625,
          0.000034332275390625,
          0.000034332275390625,
          0.000034332275390625,
          0.00003443807509029284,
          0.00003443807509029284,
          0.00003454355464782566,
          0.00003454355464782566,
          0.00003454355464782566,
          0.00003454355464782566,
          0.00003454355464782566,
          0.00003454355464782566,
          0.00003454355464782566,
          0.00003454355464782566,
          0.00003454355464782566,
          0.00003464870678726584,
          0.00003464870678726584,
          0.000034753546060528606,
          0.000034753546060528606,
          0.000034753546060528606,
          0.000034753546060528606,
          0.000034753546060528606,
          0.00003485806882963516,
          0.0000349622787325643,
          0.0000349622787325643,
          0.0000349622787325643,
          0.00003506617940729484,
          0.00003506617940729484,
          0.000035169770853826776,
          0.000035169770853826776,
          0.000035169770853826776,
          0.000035169770853826776,
          0.000035169770853826776,
          0.000035273060348117724,
          0.000035273060348117724,
          0.000035273060348117724,
          0.00003537604789016768,
          0.00003537604789016768,
          0.00003547873711795546,
          0.00003547873711795546,
          0.00003547873711795546,
          0.00003547873711795546,
          0.00003547873711795546,
          0.00003558112803148106,
          0.00003558112803148106,
          0.00003558112803148106,
          0.00003558112803148106,
          0.00003558112803148106,
          0.00003568322426872328,
          0.00003578503310563974,
          0.00003578503310563974,
          0.00003578503310563974,
          0.00003578503310563974,
          0.00003578503310563974,
          0.000035886550904251635,
          0.000035886550904251635,
          0.00003598778130253777,
          0.00003598778130253777,
          0.00003598778130253777,
          0.00003598778130253777,
          0.00003598778130253777,
          0.00003598778130253777,
          0.00003598778130253777,
          0.000036189394450047985,
          0.00003628978447522968,
          0.00003628978447522968,
          0.00003638989437604323,
          0.00003638989437604323,
          0.00003638989437604323,
          0.00003638989437604323,
          0.00003638989437604323,
          0.00003638989437604323,
          0.00003638989437604323,
          0.00003648972779046744,
          0.00003648972779046744,
          0.00003658929199445993,
          0.00003668858335004188,
          0.00003668858335004188,
          0.00003668858335004188,
          0.00003678760913317092,
          0.00003678760913317092,
          0.00003678760913317092,
          0.00003678760913317092,
          0.00003688636570586823,
          0.00003688636570586823,
          0.00003698486398207024,
          0.00003708309668581933,
          0.000037181071093073115,
          0.0000372787872038316,
          0.0000372787872038316,
          0.000037376248656073585,
          0.000037376248656073585,
          0.000037376248656073585,
          0.000037473455449799076,
          0.000037473455449799076,
          0.00003757041122298688,
          0.00003757041122298688,
          0.00003766711597563699,
          0.00003766711597563699,
          0.00003766711597563699,
          0.000037763576983707026,
          0.000037763576983707026,
          0.000037763576983707026,
          0.000037763576983707026,
          0.00003785979060921818,
          0.00003795575685217045,
          0.00003795575685217045,
          0.000038051486626500264,
          0.00003814697265625,
          0.00003814697265625,
          0.00003814697265625,
          0.000038242222217377275,
          0.000038242222217377275,
          0.00003833723167190328,
          0.00003833723167190328,
          0.00003833723167190328,
          0.000038432008295785636,
          0.000038432008295785636,
          0.000038432008295785636,
          0.000038526552089024335,
          0.000038526552089024335,
          0.000038526552089024335,
          0.000038526552089024335,
          0.00003862086668959819,
          0.00003862086668959819,
          0.00003862086668959819,
          0.00003862086668959819,
          0.000038808804674772546,
          0.00003890243169735186,
          0.00003899583316524513,
          0.00003899583316524513,
          0.00003908901635440998,
          0.000039181973988888785,
          0.00003927471334463917,
          0.00003927471334463917,
          0.00003927471334463917,
          0.00003927471334463917,
          0.000039367230783682317,
          0.000039367230783682317,
          0.00003955162173951976,
          0.000039643495256314054,
          0.000039643495256314054,
          0.000039643495256314054,
          0.000039643495256314054,
          0.000039643495256314054,
          0.00003991784979007207,
          0.00003991784979007207,
          0.000040008882933761925,
          0.00004037096005049534,
          0.00004090807124157436,
          0.00004090807124157436,
          0.00004099690340808593,
          0.000041085546399699524,
          0.000041173996578436345,
          0.000041262261220254004,
          0.00004135033304919489,
          0.00004152592009631917,
          0.00004161343531450257,
          0.00004161343531450257,
          0.00004161343531450257,
          0.00004178791641606949,
          0.00004178791641606949,
          0.00004178791641606949,
          0.000041961669921875,
          0.00004264961171429604,
          0.00004264961171429604,
          0.00004264961171429604,
          0.00004264961171429604,
          0.000042989453504560515,
          0.000042989453504560515,
          0.0000431583721365314,
          0.0000431583721365314,
          0.000043326632294338197,
          0.000043494241253938526,
          0.000043494241253938526,
          0.00004391046240925789,
          0.00004399323370307684,
          0.00004399323370307684,
          0.00004424061989993788,
          0.000044486630940809846,
          0.000044649885239778087,
          0.00004481254654820077,
          0.00004481254654820077,
          0.00004497461850405671,
          0.00004497461850405671,
          0.00004497461850405671,
          0.00004513610838330351,
          0.00004513610838330351,
          0.000045377262722468004,
          0.00004569682641886175,
          0.000045935037633171305,
          0.00004601416731020436,
          0.00004640779661713168,
          0.000047185199946397915,
          0.0000474159351142589,
          0.0000474159351142589,
          0.00004764555342262611,
          0.00004764555342262611,
          0.00004779802111443132,
          0.000047950001317076385,
          0.00004810150130651891,
          0.00004825252835871652,
          0.00004825252835871652,
          0.00004825252835871652,
          0.00004855317092733458,
          0.000048851961764739826,
          0.00004914893725072034,
          0.00004914893725072034,
          0.000049444126489106566,
          0.000049444126489106566,
          0.00004988363798474893,
          0.00004988363798474893,
          0.00004988363798474893,
          0.00004988363798474893,
          0.000050029284466290846,
          0.000050029284466290846,
          0.000050029284466290846,
          0.00005031931141274981,
          0.000050894410378532484,
          0.000050894410378532484,
          0.000050894410378532484,
          0.00005103717194288038,
          0.00005139234053785913,
          0.00005139234053785913,
          0.000051463081035763025,
          0.000051463081035763025,
          0.00005160426735528745,
          0.00005160426735528745,
          0.000052165200031595305,
          0.000052165200031595305,
          0.00005272016642265953,
          0.00005272016642265953,
          0.00005299546683090739,
          0.00005313258589012548,
          0.00005313258589012548,
          0.00005326934842742048,
          0.00005326934842742048,
          0.00005340576171875,
          0.00005340576171875,
          0.00005340576171875,
          0.00005354182576411404,
          0.00005541167774936184,
          0.00005541167774936184,
          0.000056064371165120974,
          0.000056064371165120974,
          0.00005645236524287611,
          0.00005658110239892267,
          0.00005670955215464346,
          0.00005683771087205969,
          0.00005683771087205969,
          0.00005683771087205969,
          0.00005683771087205969,
          0.00005696557855117135,
          0.00005822882667416707,
          0.00005822882667416707,
          0.00005885028440388851,
          0.00005909703759243712,
          0.00005909703759243712,
          0.00005934276123298332,
          0.00005934276123298332,
          0.00005983118899166584,
          0.000059952672017971054,
          0.00006007391129969619,
          0.000060194906836841255,
          0.000060556441894732416,
          0.000060556441894732416,
          0.00006151014531496912,
          0.00006151014531496912,
          0.00006209877028595656,
          0.00006244928226806223,
          0.00006256569031393155,
          0.00006268187280511484,
          0.0000627978442935273,
          0.00006302913971012458,
          0.00006383209256455302,
          0.00006383209256455302,
          0.00006428641790989786,
          0.0000643995008431375,
          0.00006451238732552156,
          0.00006462507008109242,
          0.00006496195419458672,
          0.00006496195419458672,
          0.00006496195419458672,
          0.00006496195419458672,
          0.00006607249815715477,
          0.00006607249815715477,
          0.00006607249815715477,
          0.00006651152216363698,
          0.00006694766489090398,
          0.00006727292202413082,
          0.00006823938019806519,
          0.00007002853089943528,
          0.00007013235881458968,
          0.00007033954170765355,
          0.00007033954170765355,
          0.00007044290396152064,
          0.00007116225606296211,
          0.00007136644853744656,
          0.00007136644853744656,
          0.00007136644853744656,
          0.00007136644853744656,
          0.00007167165313148871,
          0.0000728796876501292,
          0.00007347625796683133,
          0.00007367404032265767,
          0.00007377273141173646,
          0.00007396972796414047,
          0.00007396972796414047,
          0.00007416619337163866,
          0.00007445991650456563,
          0.00007445991650456563,
          0.00007533423195127398,
          0.0000759115137043409,
          0.00007610297325300053,
          0.00007667446334380656,
          0.00007686401659157127,
          0.00007686401659157127,
          0.00007714748062426224,
          0.00007733586971880868,
          0.00007780486339470372,
          0.0000778983230702579,
          0.00007873446156736463,
          0.00007873446156736463,
          0.00007873446156736463,
          0.00007873446156736463,
          0.00008092194912023842,
          0.00008208250073948875,
          0.00008225959027186036,
          0.00008305184019263834,
          0.00008461407560389489,
          0.00008495734073221684,
          0.00008495734073221684,
          0.00008546965545974672,
          0.000085724655946251,
          0.00008589424396632239,
          0.00008589424396632239,
          0.00008665326458867639,
          0.00008740569319343194,
          0.00008938121754908934,
          0.0000913936528377235,
          0.00009202833462040871,
          0.00009202833462040871,
          0.00009218632476404309,
          0.00009218632476404309,
          0.00009273716568714008,
          0.00009351845073979348,
          0.00009437039989279583,
          0.00009437039989279583,
          0.000095367431640625,
          0.00009574813884682953,
          0.00009605162631487474,
          0.00009635414608055726,
          0.00009650505671743304,
          0.00009650505671743304,
          0.00009650505671743304,
          0.00009658042108640075,
          0.00009688129648566246,
          0.00009688129648566246,
          0.00009710634185466915,
          0.00009859350393526256,
          0.00009888825297821313,
          0.00010078311606775969,
          0.00010107148409588262,
          0.00010128721623914316,
          0.00010171731264563277,
          0.00010171731264563277,
          0.00010178882075706497,
          0.00010178882075706497,
          0.00010200303950114176,
          0.00010200303950114176,
          0.00010200303950114176,
          0.00010306744661647826,
          0.00010530222789384425,
          0.00010537129855947569,
          0.00010564714466454461,
          0.00010599093366181478,
          0.00010612814367050305,
          0.00010633361671352759,
          0.0001064703828888014,
          0.00010667519381968305,
          0.00010667519381968305,
          0.00010701568680815399,
          0.00010715157986851409,
          0.00010735509567894042,
          0.00010749055945780128,
          0.00010755822586361319,
          0.00010762585588963702,
          0.00010796334390761331,
          0.00010796334390761331,
          0.00010796334390761331,
          0.0001080980509868823,
          0.0001080980509868823,
          0.00010883592767640948,
          0.00010936943726846948,
          0.00010936943726846948,
          0.00011016486678272486,
          0.00011016486678272486,
          0.00011016486678272486,
          0.00011029687448171899,
          0.00011075768270529807,
          0.00011134734813822433,
          0.00011154320964124054,
          0.00011154320964124054,
          0.00011160841677337885,
          0.00011186888150405139,
          0.00011193390673724934,
          0.00011193390673724934,
          0.00011219361476833001,
          0.00011219361476833001,
          0.00011277577141299844,
          0.00011303354403935373,
          0.00011431369057390839,
          0.00011431369057390839,
          0.00011456800712039694,
          0.00011456800712039694,
          0.00011456800712039694,
          0.00011576836550375447,
          0.00011583119339775294,
          0.00011583119339775294,
          0.00011583119339775294,
          0.0001159567545983009,
          0.00011627007188508287,
          0.00011627007188508287,
          0.00011633263056864962,
          0.00011645765334833413,
          0.00011664493649732322,
          0.00011676962458295748,
          0.00011708075908245519,
          0.00011708075908245519,
          0.00011720498150680214,
          0.00011856284982059151,
          0.00011935796646866947,
          0.00011996601097052917,
          0.00012032936501782387,
          0.00012063131725881249,
          0.00012087234063073993,
          0.0001220703125,
          0.0001220703125,
          0.00012313852494116873,
          0.0001237279939232394,
          0.00012419754057191312,
          0.00012449012137949467,
          0.00012460695870686322,
          0.00012460695870686322,
          0.00012466534099075943,
          0.00012466534099075943,
          0.00012495681585278362,
          0.00012495681585278362,
          0.00012507321662269533,
          0.00012571149272844195,
          0.00012669160787481815,
          0.00012777812662534416,
          0.0001284596073674038,
          0.000128799001686275,
          0.00012891193910036236,
          0.00012902477465104312,
          0.0001295874681090936,
          0.00012981185864191502,
          0.00012981185864191502,
          0.00012981185864191502,
          0.00013081687211524695,
          0.00013081687211524695,
          0.0001309836225118488,
          0.00013131648302078247,
          0.00013181421672925353,
          0.00013208991731517017,
          0.0001322550670010969,
          0.0001323650503763929,
          0.00013247494644019753,
          0.00013258474064059556,
          0.00013302304432727396,
          0.00013302304432727396,
          0.00013362335448618978,
          0.00013362335448618978,
          0.00013508553092833608,
          0.000135193215101026,
          0.00013556942576542497,
          0.00013562307867687196,
          0.00013562307867687196,
          0.00013567671703640372,
          0.00013583750114776194,
          0.0001359445886919275,
          0.0001359445886919275,
          0.0001359445886919275,
          0.00013615851639769971,
          0.00013637209485750645,
          0.00013637209485750645,
          0.00013669184409081936,
          0.00013669184409081936,
          0.0001367982622468844,
          0.00013690459309145808,
          0.00013764662435278296,
          0.00013801614113617688,
          0.00013827948714606464,
          0.00013833209231961519,
          0.00013833209231961519,
          0.00013917111209593713,
          0.00013990112347528338,
          0.0001400051114615053,
          0.0001406790834153071,
          0.0001406790834153071,
          0.00014232451212592423,
          0.00014465702406596392,
          0.00014565950550604612,
          0.00014565950550604612,
          0.00014620795263908803,
          0.00014620795263908803,
          0.0001501847873441875,
          0.0001542949612485245,
          0.0001545776322018355,
          0.00015518833242822438,
          0.00015546938811894506,
          0.00015560972678940743,
          0.00015589002578053623,
          0.00015589002578053623,
          0.00015700618678238243,
          0.00016008099191822112,
          0.000160580180818215,
          0.000160580180818215,
          0.000162472075317055,
          0.00016832284745760262,
          0.0001684524759184569,
          0.0001686251489445567,
          0.00016866829537320882,
          0.00016888385289348662,
          0.00016922815120778978,
          0.00016922815120778978,
          0.00017593159282114357,
          0.00017601427680347115,
          0.0001769213704392314,
          0.00017725006910040975,
          0.00017725006910040975,
          0.00018054443353321403,
          0.0001808263041311875,
          0.00018150905088987201,
          0.00018401713168714195,
          0.00018496364646125585,
          0.00018535660638008267,
          0.00018594448920339346,
          0.00018594448920339346,
          0.00018617910973262042,
          0.00018935659318231046,
          0.00019417521252762526,
          0.0001946990960277617,
          0.00019507243996486068,
          0.00019548229465726763,
          0.00019548229465726763,
          0.00019603980763349682,
          0.000203255724045448,
          0.00020350614795461297,
          0.00020372055587358773,
          0.00020407739793881774,
          0.0002041486877715215,
          0.00020421994850039482,
          0.00020436241175048053,
          0.00020436241175048053,
          0.00020443361427169293,
          0.00020443361427169293,
          0.00020991236669942737,
          0.00021170711261220276,
          0.0002145067701349035,
          0.00021477795962709934,
          0.00021525171177927405,
          0.0002153193054255098,
          0.0002153193054255098,
          0.00021880539134144783,
          0.0002201315073762089,
          0.00022032973356544971,
          0.00022098919725976884,
          0.00022125244140625,
          0.00022125244140625,
          0.00022568053100258112,
          0.00022587389685213566,
          0.00022738284314982593,
          0.0002339750062674284,
          0.00024071917869150639,
          0.00024077962734736502,
          0.00024138324079103768,
          0.00024138324079103768,
          0.0002416844799881801,
          0.00024624750949442387,
          0.00024624750949442387,
          0.00024660181952640414,
          0.00024660181952640414,
          0.00024660181952640414,
          0.0002474559878464788,
          0.000247573567321524,
          0.00024772045435383916,
          0.0002479259856045246,
          0.0002479259856045246,
          0.0002515676314942539,
          0.00025341191212646663,
          0.00025504324003122747,
          0.00025569857098162174,
          0.00025575546897016466,
          0.00025575546897016466,
          0.00025612502940930426,
          0.00025892214034684,
          0.00025909068062901497,
          0.00025951158022508025,
          0.0002597637940198183,
          0.00026051898021250963,
          0.00026051898021250963,
          0.0002737028698902577,
          0.0002770846476778388,
          0.0002773208834696561,
          0.00027802836848422885,
          0.00027805453282780945,
          0.00027805453282780945,
          0.0002794900501612574,
          0.0002835220948327333,
          0.0002900675463024527,
          0.00029141889535821974,
          0.0002916435187216848,
          0.00029181811260059476,
          0.00029181811260059476,
          0.00029251541127450764,
          0.00029288826044648886,
          0.0002946467720903456,
          0.00029499229276552796,
          0.0002959280682262033,
          0.0002959280682262033,
          0.0002966647734865546,
          0.00029786411323584616,
          0.000304889545077458,
          0.00031261902768164873,
          0.0003126423107460141,
          0.00031364141614176333,
          0.00031391967786476016,
          0.00031391967786476016,
          0.00032413704320788383,
          0.0003243838727939874,
          0.00032483215909451246,
          0.00032498891232535243,
          0.0003253916511312127,
          0.0003253916511312127,
          0.0003273090405855328,
          0.0003274423652328551,
          0.0003277533105574548,
          0.0003282413526903838,
          0.0003282413526903838,
          0.0003340856055729091,
          0.00033867123420350254,
          0.00033970086951740086,
          0.0003431319782976061,
          0.0003471793606877327,
          0.00034814205719158053,
          0.0003486432833597064,
          0.0003487476205918938,
          0.0003487476205918938,
          0.00034945624065585434,
          0.0003506825305521488,
          0.000351117952959612,
          0.00035190454218536615,
          0.000352400413248688,
          0.0003525655483826995,
          0.0003525655483826995,
          0.00036195426946505904,
          0.00036213514977134764,
          0.00036217531305737793,
          0.00036233599530532956,
          0.00036245645605959,
          0.00036245645605959,
          0.0003725145070347935,
          0.0003782325657084584,
          0.0003841875586658716,
          0.0003881067968904972,
          0.0003938755835406482,
          0.0003972783451899886,
          0.0004018308827653527,
          0.00040226519922725856,
          0.000402337551349774,
          0.00040253641782328486,
          0.0004027171526104212,
          0.00040295193321071565,
          0.00040295193321071565,
          0.00040304221329279244,
          0.00040396186523139477,
          0.00040396186523139477,
          0.00042646200745366514,
          0.0004581767425406724,
          0.0004585259885061532,
          0.00045855771168135107,
          0.00045885908184573054,
          0.00045885908184573054,
          0.00046863366151228547,
          0.000468726793769747,
          0.00046897510765120387,
          0.00046897510765120387,
          0.00046905266935937107,
          0.000475492503028363,
          0.00047558429650962353,
          0.00047587486915290356,
          0.00047587486915290356,
          0.00047604303108528256,
          0.00047814761637710035,
          0.00047852788702584803,
          0.00047877110773697495,
          0.00047877110773697495,
          0.00047909014392644167,
          0.00047909014392644167,
          0.00048034900100901723,
          0.000484421500004828,
          0.0004917409387417138,
          0.0004918297054246068,
          0.0004919480415992439,
          0.0004919480415992439,
          0.0004923028755001724,
          0.0004969366127625108,
          0.0005056884256191552,
          0.0005061342963017523,
          0.000514871091581881,
          0.0005208284128457308,
          0.0005211635725572705,
          0.0005252936389297247,
          0.0005275189760141075,
          0.0005276982556097209,
          0.0005307366955094039,
          0.0005381968803703785,
          0.0005528153269551694,
          0.0005642658215947449,
          0.0005644849734380841,
          0.0005653479020111263,
          0.0005653479020111263,
          0.0005653479020111263,
          0.0005774826859124005,
          0.0005795578472316265,
          0.0005839976365678012,
          0.000585714413318783,
          0.000625773158390075,
          0.0006350182229653001,
          0.0006705191917717457,
          0.0006841827416792512,
          0.0006844698218628764,
          0.0006848417688161135,
          0.0006848417688161135,
          0.0006848523626103997,
          0.0007259459816850722,
          0.0007371748215518892,
          0.0007504295790567994,
          0.0007695767562836409,
          0.0007700115675106645,
          0.0007702194270677865,
          0.000771597377024591,
          0.000771597377024591,
          0.0007793660624884069,
          0.0007794967968948185,
          0.0007795154233463109,
          0.0007801685715094209,
          0.0007801685715094209,
          0.00078927370486781,
          0.00078927370486781,
          0.0007893197471275926,
          0.0007893197471275926,
          0.0007894487935118377,
          0.0008003594703041017,
          0.0008665662026032805,
          0.0009025448234751821,
          0.0009027463383972645,
          0.000903318403288722,
          0.0009037613053806126,
          0.0009037613053806126,
          0.0009039142169058323,
          0.0010071523720398545,
          0.0010658717947080731,
          0.00108122278470546,
          0.00122234714217484,
          0.001384288421832025,
          0.0015143291093409061,
          0.0015268560964614153,
          0.0015393615467473865,
          0.0030459349509328604,
          0.005477872211486101,
          0.008249020203948021,
          0.00825070682913065,
          0.008251500315964222,
          0.008251500315964222,
          0.00825241394340992,
          0.008255756460130215,
          0.01203783880919218,
          0.022650523111224174,
          0.023080559447407722,
          0.024541204795241356,
          0.024548906832933426,
          0.024554600939154625,
          0.024554600939154625,
          0.024559974670410156,
          0.02456156350672245,
          0.025319406762719154,
          0.025662411004304886,
          0.0360565148293972,
          0.03652072325348854,
          0.03878064081072807,
          0.03954428806900978,
          0.04048147797584534,
          0.04217694699764252,
          0.04888121411204338,
          0.051648300141096115,
          0.05221191793680191,
          0.056980572640895844,
          0.060550518333911896,
          0.06184002384543419,
          0.06362199038267136,
          0.06362535059452057,
          0.06578996032476425,
          0.07003512233495712,
          0.07445784658193588,
          0.07446347922086716,
          0.07446561753749847,
          0.07446561753749847,
          0.07446944713592529,
          0.07447198778390884,
          0.07588234543800354,
          0.07769101113080978,
          0.07769377529621124,
          0.0776984915137291,
          0.0776984915137291,
          0.07770130783319473,
          0.07770927995443344,
          0.07857192307710648,
          0.08349283039569855,
          0.08898534625768661,
          0.08898553252220154,
          0.09209518879652023,
          0.09568092226982117,
          0.09652448445558548,
          0.09708701074123383,
          0.09708701074123383,
          0.0970873162150383,
          0.09709049016237259,
          0.09929168224334717,
          0.09930513054132462,
          0.09954231232404709,
          0.1009950190782547,
          0.1009950190782547,
          0.10101192444562912,
          0.10101675987243652,
          0.10280168056488037,
          0.10299953818321228,
          0.10461533069610596,
          0.10461932420730591,
          0.10463321954011917,
          0.10463321954011917,
          0.10463687777519226,
          0.10464133322238922,
          0.11008013039827347,
          0.11108347028493881,
          0.11554903537034988,
          0.1176232323050499,
          0.1176232323050499,
          0.12003771960735321,
          0.12613873183727264,
          0.13564810156822205,
          0.14071042835712433,
          0.14148113131523132,
          0.14148879051208496,
          0.14237043261528015,
          0.14237338304519653,
          0.14237748086452484,
          0.14237748086452484,
          0.14238038659095764,
          0.1423809677362442,
          0.1472063511610031,
          0.149118572473526,
          0.15233582258224487,
          0.15334512293338776,
          0.15351900458335876,
          0.1535239815711975,
          0.15353386104106903,
          0.15353386104106903,
          0.15354005992412567,
          0.15354761481285095,
          0.15506625175476074,
          0.15562501549720764,
          0.15771318972110748,
          0.1592167317867279,
          0.1592167317867279,
          0.15922869741916656,
          0.15923301875591278,
          0.15935476124286652,
          0.16284996271133423,
          0.16284996271133423,
          0.16883176565170288,
          0.171363964676857,
          0.17214389145374298,
          0.18193551898002625,
          0.18468961119651794,
          0.18708600103855133,
          0.18946947157382965,
          0.19071945548057556,
          0.19071945548057556,
          0.19072388112545013,
          0.190761536359787,
          0.1910131275653839,
          0.19216811656951904,
          0.2021237164735794,
          0.20493589341640472,
          0.20493589341640472,
          0.20953689515590668,
          0.2095557600259781,
          0.21103279292583466,
          0.21637184917926788,
          0.22000552713871002,
          0.22258135676383972,
          0.22583340108394623,
          0.2301177978515625,
          0.2350013703107834,
          0.24047939479351044,
          0.24047939479351044,
          0.24193908274173737,
          0.24501000344753265,
          0.2470572143793106,
          0.25228214263916016,
          0.25228506326675415,
          0.25652727484703064,
          0.2565302550792694,
          0.2571536898612976,
          0.25836431980133057,
          0.25836628675460815,
          0.2632279396057129,
          0.2632279396057129,
          0.26323240995407104,
          0.26323264837265015,
          0.266875296831131,
          0.26687896251678467,
          0.26815882325172424,
          0.26816317439079285,
          0.26844659447669983,
          0.26844659447669983,
          0.27048519253730774,
          0.27259278297424316,
          0.2725967764854431,
          0.2772282660007477,
          0.2777051329612732,
          0.27937185764312744,
          0.27937185764312744,
          0.27937185764312744,
          0.2793732285499573,
          0.27951866388320923,
          0.27952685952186584,
          0.283231645822525,
          0.28323233127593994,
          0.2845456302165985,
          0.28555211424827576,
          0.2861363887786865,
          0.2884657680988312,
          0.2922910451889038,
          0.2925421893596649,
          0.2941340208053589,
          0.2941380739212036,
          0.2961338460445404,
          0.2992266118526459,
          0.3036663830280304,
          0.30450716614723206,
          0.3053090274333954,
          0.30724063515663147,
          0.3072419762611389,
          0.3164265751838684,
          0.31912994384765625,
          0.31912994384765625,
          0.319452166557312,
          0.31946149468421936,
          0.3194641172885895,
          0.3194641172885895,
          0.3194669187068939,
          0.31947189569473267,
          0.3223867118358612,
          0.3229687809944153,
          0.32305049896240234,
          0.3256053924560547,
          0.3257502615451813,
          0.3257502615451813,
          0.32767462730407715,
          0.32767635583877563,
          0.3286435008049011,
          0.3286549746990204,
          0.3286605179309845,
          0.3293367922306061,
          0.329534113407135,
          0.33163756132125854,
          0.33225804567337036,
          0.3322591483592987,
          0.3327041566371918,
          0.33449891209602356,
          0.33450353145599365,
          0.33451876044273376,
          0.3345205783843994,
          0.3345205783843994,
          0.3345242142677307,
          0.3345373272895813,
          0.3357400894165039,
          0.3357400894165039,
          0.33583590388298035,
          0.3364066481590271,
          0.33671513199806213,
          0.33672332763671875,
          0.3367302119731903,
          0.3382346034049988,
          0.3401612937450409,
          0.3418014645576477,
          0.34358617663383484,
          0.3453308939933777,
          0.3515664339065552,
          0.35349372029304504,
          0.35349568724632263,
          0.3534986078739166,
          0.35610294342041016,
          0.3568545877933502,
          0.3568545877933502,
          0.35719960927963257,
          0.35754716396331787,
          0.3575609624385834,
          0.35785335302352905,
          0.35805580019950867,
          0.35909128189086914,
          0.3590940535068512,
          0.359167218208313,
          0.359167218208313,
          0.359231173992157,
          0.359231173992157,
          0.36010777950286865,
          0.3619116246700287,
          0.36369967460632324,
          0.3638453483581543,
          0.3643348813056946,
          0.36516234278678894,
          0.36600756645202637,
          0.3660196363925934,
          0.36604127287864685,
          0.36748620867729187,
          0.3681015372276306,
          0.3698880672454834,
          0.3736932873725891,
          0.3736932873725891,
          0.37369412183761597,
          0.3736976981163025,
          0.37427857518196106,
          0.3784348666667938,
          0.38408520817756653,
          0.38540470600128174,
          0.3874392807483673,
          0.38949450850486755,
          0.38949450850486755,
          0.38949552178382874,
          0.3894995450973511,
          0.39003893733024597,
          0.39017292857170105,
          0.39017292857170105,
          0.39017820358276367,
          0.39018818736076355,
          0.39077135920524597,
          0.3928823173046112,
          0.3935604989528656,
          0.3937050998210907,
          0.39550265669822693,
          0.3957100510597229,
          0.39585673809051514,
          0.3964443802833557,
          0.3991805613040924,
          0.4030250906944275,
          0.4050958752632141,
          0.40846264362335205,
          0.40847229957580566,
          0.408637672662735,
          0.40946054458618164,
          0.4096241295337677,
          0.4096285104751587,
          0.4096760153770447,
          0.4096854031085968,
          0.41063275933265686,
          0.4130665063858032,
          0.41307151317596436,
          0.41308093070983887,
          0.41351908445358276,
          0.4162423014640808,
          0.4162423014640808,
          0.4167187213897705,
          0.4167414903640747,
          0.41737014055252075,
          0.4196547567844391,
          0.42088747024536133,
          0.4210590720176697,
          0.423053503036499,
          0.42543020844459534,
          0.42544856667518616,
          0.4263007342815399,
          0.42635491490364075,
          0.4263574481010437,
          0.4275166988372803,
          0.4290335476398468,
          0.4290335476398468,
          0.4291052222251892,
          0.434762179851532,
          0.4348091781139374,
          0.4349516034126282,
          0.43553441762924194,
          0.4372669458389282,
          0.4372754991054535,
          0.4389992952346802,
          0.44275471568107605,
          0.4436477720737457,
          0.4443542957305908,
          0.4465692937374115,
          0.4471176564693451,
          0.4479730427265167,
          0.45095762610435486,
          0.45217639207839966,
          0.4574967920780182,
          0.4576031565666199,
          0.4587450921535492,
          0.45874708890914917,
          0.45906609296798706,
          0.46499133110046387,
          0.46611353754997253,
          0.4661199748516083,
          0.4702525734901428,
          0.4702533781528473,
          0.4708547592163086,
          0.4708593785762787,
          0.4727855324745178,
          0.4727855324745178,
          0.4795236587524414,
          0.48382410407066345,
          0.48460903763771057,
          0.4860217869281769,
          0.488363116979599,
          0.488363116979599,
          0.4959176182746887,
          0.4971763491630554,
          0.5023117065429688,
          0.5042964816093445,
          0.5050824284553528,
          0.5050972104072571,
          0.505097508430481,
          0.505097508430481,
          0.5050978064537048,
          0.5051047205924988,
          0.5088903903961182,
          0.5088903903961182,
          0.5090233087539673,
          0.5090243220329285,
          0.5092368125915527,
          0.5092368125915527,
          0.5113470554351807,
          0.5137291550636292,
          0.5165554881095886,
          0.5168680548667908,
          0.5168849229812622,
          0.5178543925285339,
          0.5189054012298584,
          0.518925130367279,
          0.5189307928085327,
          0.5243127942085266,
          0.5243127942085266,
          0.5250057578086853,
          0.5256666541099548,
          0.5286405086517334,
          0.5324262380599976,
          0.5331915616989136,
          0.5331915616989136,
          0.5345459580421448,
          0.5399209260940552,
          0.5399259328842163,
          0.5430481433868408,
          0.5434662103652954,
          0.5449917912483215,
          0.5457623600959778,
          0.54756760597229,
          0.5487728714942932,
          0.5491310358047485,
          0.5505409240722656,
          0.5505409240722656,
          0.5508880019187927,
          0.551467776298523,
          0.5521489977836609,
          0.5541126132011414,
          0.5541126132011414,
          0.554396390914917,
          0.554894745349884,
          0.555088222026825,
          0.555088222026825,
          0.558111846446991,
          0.5602549910545349,
          0.5609023571014404,
          0.5613090991973877,
          0.5618491768836975,
          0.5647465586662292,
          0.5652133226394653,
          0.5656397342681885,
          0.565646231174469,
          0.5668230056762695,
          0.5691843032836914,
          0.5695197582244873,
          0.573432981967926,
          0.5744340419769287,
          0.5825794339179993,
          0.5825795531272888,
          0.5825795531272888,
          0.5825796127319336,
          0.582580029964447,
          0.5825810432434082,
          0.5825815796852112,
          0.5837964415550232,
          0.5846550464630127,
          0.5860182046890259,
          0.5904210805892944,
          0.5922104120254517,
          0.5962371826171875,
          0.5976076126098633,
          0.5983397364616394,
          0.5999302268028259,
          0.6009273529052734,
          0.6011806130409241,
          0.6033780574798584,
          0.6069674491882324,
          0.6090445518493652,
          0.610990583896637,
          0.6180011034011841,
          0.6180011034011841,
          0.6180048584938049,
          0.6180247664451599,
          0.619962751865387,
          0.6226824522018433,
          0.6276262402534485,
          0.6313779354095459,
          0.6313904523849487,
          0.6332095265388489,
          0.6351884603500366,
          0.6383557915687561,
          0.6416638493537903,
          0.6442606449127197,
          0.6442606449127197,
          0.6496574282646179,
          0.6513798832893372,
          0.6518263816833496,
          0.6529021859169006,
          0.6552501916885376,
          0.6552632451057434,
          0.660072386264801,
          0.6608012318611145,
          0.6609731912612915,
          0.6611005067825317,
          0.6611005067825317,
          0.662100076675415,
          0.662100076675415,
          0.6630004644393921,
          0.6678768992424011,
          0.6729322671890259,
          0.6729505062103271,
          0.674098789691925,
          0.674098789691925,
          0.6754745841026306,
          0.6797197461128235,
          0.6807955503463745,
          0.6823747754096985,
          0.6830898523330688,
          0.6846746802330017,
          0.6853594183921814,
          0.6880795955657959,
          0.6884888410568237,
          0.689618706703186,
          0.6907504200935364,
          0.6912476420402527,
          0.6912476420402527,
          0.6913639903068542,
          0.6913639903068542,
          0.6920415163040161,
          0.6920415163040161,
          0.6951441168785095,
          0.7021076679229736,
          0.7024878859519958,
          0.7034072279930115,
          0.7054291367530823,
          0.7054291367530823,
          0.7059946060180664,
          0.7060084939002991,
          0.7083004117012024,
          0.7090834379196167,
          0.7092223763465881,
          0.7092861533164978,
          0.7111043334007263,
          0.7111167907714844,
          0.7111309170722961,
          0.7187799215316772,
          0.7195215821266174,
          0.7233957052230835,
          0.7234109044075012,
          0.7234207391738892,
          0.7234207391738892,
          0.723429799079895,
          0.723432183265686,
          0.7250043749809265,
          0.7255299687385559,
          0.7273116111755371,
          0.7273116111755371,
          0.7278642058372498,
          0.7278642058372498,
          0.731401264667511,
          0.7343049645423889,
          0.7377973198890686,
          0.739340603351593,
          0.739495575428009,
          0.7412846088409424,
          0.7433462738990784,
          0.7451158761978149,
          0.7467190623283386,
          0.7480459213256836,
          0.7487056851387024,
          0.7533144950866699,
          0.7535225749015808,
          0.7535225749015808,
          0.7575500011444092,
          0.7575510740280151,
          0.7577317357063293,
          0.7613252997398376,
          0.7619670629501343,
          0.763778567314148,
          0.7658746838569641,
          0.7663120627403259,
          0.7676218748092651,
          0.7744508981704712,
          0.7744524478912354,
          0.7801703214645386,
          0.7801799178123474,
          0.7851488590240479,
          0.7891906499862671,
          0.7911887764930725,
          0.7919684052467346,
          0.7927255034446716,
          0.7932630181312561,
          0.797235906124115,
          0.7972487807273865,
          0.8004407286643982,
          0.812640905380249,
          0.8165396451950073,
          0.8165396451950073,
          0.8166940808296204,
          0.8176649808883667,
          0.8179557919502258,
          0.8196212649345398,
          0.8197438716888428,
          0.8199599385261536,
          0.8212286233901978,
          0.8212844729423523,
          0.8212844729423523,
          0.8238439559936523,
          0.8251259326934814,
          0.8254387378692627,
          0.8288801312446594,
          0.830030620098114,
          0.8307803869247437,
          0.8314699530601501,
          0.833355188369751,
          0.8333611488342285,
          0.8372481465339661,
          0.8409048914909363,
          0.8409048914909363,
          0.841296911239624,
          0.841296911239624,
          0.8413266539573669,
          0.8435357213020325,
          0.8435357213020325,
          0.8456830978393555,
          0.8456870913505554,
          0.8492451310157776,
          0.8495276570320129,
          0.8501108288764954,
          0.8537101745605469,
          0.8539178371429443,
          0.8539178371429443,
          0.8545756340026855,
          0.8553500771522522,
          0.855356752872467,
          0.8566988110542297,
          0.8584110140800476,
          0.8585273623466492,
          0.8618189096450806,
          0.8618201613426208,
          0.8618223667144775,
          0.8618223667144775,
          0.861824095249176,
          0.8618243336677551,
          0.8622800707817078,
          0.8666160106658936,
          0.8676528930664062,
          0.8676528930664062,
          0.8684753179550171,
          0.8688101768493652,
          0.8705454468727112,
          0.8733558654785156,
          0.8763723373413086,
          0.8763723373413086,
          0.8772287368774414,
          0.8772287368774414,
          0.8772348165512085,
          0.8772363066673279,
          0.8782873153686523,
          0.8824974894523621,
          0.8866346478462219,
          0.8866931200027466,
          0.8909333348274231,
          0.8909430503845215,
          0.8916671872138977,
          0.8949896693229675,
          0.8974927067756653,
          0.8975163102149963,
          0.9027025103569031,
          0.9043044447898865,
          0.9058942198753357,
          0.9058942198753357,
          0.9100490808486938,
          0.9100503921508789,
          0.9112115502357483,
          0.9112115502357483,
          0.9149564504623413,
          0.915652871131897,
          0.918688178062439,
          0.9190136790275574,
          0.9260053634643555,
          0.9260061979293823,
          0.9324339628219604,
          0.9324447512626648,
          0.9328678846359253,
          0.9328678846359253,
          0.9328727126121521,
          0.9328740835189819,
          0.9332227110862732,
          0.9332227110862732,
          0.9332234263420105,
          0.9332253336906433,
          0.9364520311355591,
          0.94004225730896,
          0.9439138174057007,
          0.9469943642616272,
          0.9502249956130981,
          0.9502249956130981,
          0.9509828090667725,
          0.9567432403564453,
          0.9595614671707153,
          0.9647497534751892,
          0.9705511331558228,
          0.9705511331558228,
          0.9717268347740173,
          0.9717411398887634,
          0.9717540144920349,
          0.9748754501342773,
          0.9748754501342773,
          0.980492115020752,
          0.9812118411064148,
          0.9812118411064148,
          0.9824295043945312,
          0.9898541569709778,
          0.9898556470870972,
          0.989858865737915,
          0.9906978607177734,
          0.9907060861587524,
          0.9951720237731934,
          0.9962278604507446,
          1.014529824256897,
          1.0154625177383423,
          1.0222524404525757,
          1.0251237154006958,
          1.0273258686065674,
          1.0287847518920898,
          1.0300544500350952,
          1.0316650867462158,
          1.033352255821228,
          1.0337995290756226,
          1.0338000059127808,
          1.0512748956680298,
          1.0553269386291504,
          1.0570780038833618,
          1.0732134580612183,
          1.0770326852798462,
          1.085732340812683,
          1.0859078168869019,
          1.086254596710205,
          1.0862584114074707,
          1.086276888847351,
          1.0877697467803955,
          1.0904651880264282,
          1.0915178060531616,
          1.0975029468536377,
          1.1004923582077026,
          1.1102373600006104,
          1.1174514293670654,
          1.1193609237670898,
          1.1261893510818481,
          1.1291612386703491,
          1.1291612386703491,
          1.1291687488555908,
          1.1291699409484863,
          1.1337075233459473,
          1.1361647844314575,
          1.1364305019378662,
          1.1390398740768433,
          1.142353892326355,
          1.1444547176361084,
          1.1447006464004517,
          1.1449612379074097,
          1.1492434740066528,
          1.1492527723312378,
          1.1566797494888306,
          1.1566797494888306,
          1.1600780487060547,
          1.1607236862182617,
          1.1607236862182617,
          1.1660089492797852,
          1.1683586835861206,
          1.1705363988876343,
          1.173093557357788,
          1.1781902313232422,
          1.1781902313232422,
          1.17819344997406,
          1.1781938076019287,
          1.182371735572815,
          1.1844407320022583,
          1.1917810440063477,
          1.1917893886566162,
          1.1940834522247314,
          1.2033251523971558,
          1.2063566446304321,
          1.2067933082580566,
          1.2107354402542114,
          1.2115461826324463,
          1.2238847017288208,
          1.2241111993789673,
          1.2241162061691284,
          1.2241184711456299,
          1.2241559028625488,
          1.2363617420196533,
          1.2420097589492798,
          1.2420097589492798,
          1.2424280643463135,
          1.2424280643463135,
          1.250899314880371,
          1.2509078979492188,
          1.2532089948654175,
          1.2544351816177368,
          1.2567633390426636,
          1.260742425918579,
          1.2632914781570435,
          1.2661958932876587,
          1.2671340703964233,
          1.2696493864059448,
          1.2703193426132202,
          1.2770941257476807,
          1.2835298776626587,
          1.2843855619430542,
          1.2875186204910278,
          1.2940630912780762,
          1.3000452518463135,
          1.3062292337417603,
          1.3068618774414062,
          1.3088096380233765,
          1.3088152408599854,
          1.3090457916259766,
          1.3207920789718628,
          1.3207920789718628,
          1.3216569423675537,
          1.3216569423675537,
          1.3388829231262207,
          1.342970848083496,
          1.3469185829162598,
          1.3471559286117554,
          1.3511338233947754,
          1.3511357307434082,
          1.354841947555542,
          1.3570562601089478,
          1.360901117324829,
          1.3614827394485474,
          1.3632797002792358,
          1.365458607673645,
          1.365645408630371,
          1.371476411819458,
          1.3796383142471313,
          1.3827394247055054,
          1.3869715929031372,
          1.3885576725006104,
          1.3990118503570557,
          1.3990265130996704,
          1.4002398252487183,
          1.4015954732894897,
          1.4123374223709106,
          1.4123437404632568,
          1.4123437404632568,
          1.4123437404632568,
          1.4123455286026,
          1.4123493432998657,
          1.4134701490402222,
          1.4179177284240723,
          1.4185954332351685,
          1.4196752309799194,
          1.419819951057434,
          1.430379033088684,
          1.4305185079574585,
          1.4368312358856201,
          1.4379833936691284,
          1.4434691667556763,
          1.4434691667556763,
          1.444564700126648,
          1.4482582807540894,
          1.4498363733291626,
          1.4514853954315186,
          1.45220947265625,
          1.4565643072128296,
          1.462360143661499,
          1.4762197732925415,
          1.477159857749939,
          1.4775327444076538,
          1.477537751197815,
          1.4801757335662842,
          1.481902837753296,
          1.481907606124878,
          1.48293936252594,
          1.4829415082931519,
          1.4840518236160278,
          1.4848257303237915,
          1.4913363456726074,
          1.4914838075637817,
          1.4924038648605347,
          1.4959056377410889,
          1.4996984004974365,
          1.5008009672164917,
          1.5185056924819946,
          1.5185080766677856,
          1.5220481157302856,
          1.522059679031372,
          1.5253818035125732,
          1.5336713790893555,
          1.5349916219711304,
          1.5376503467559814,
          1.540669322013855,
          1.5441397428512573,
          1.5441479682922363,
          1.5484205484390259,
          1.5484240055084229,
          1.5669448375701904,
          1.5669448375701904,
          1.567907452583313,
          1.5775190591812134,
          1.5785624980926514,
          1.5800299644470215,
          1.5806466341018677,
          1.5831838846206665,
          1.585568904876709,
          1.5855743885040283,
          1.5871846675872803,
          1.5871949195861816,
          1.5920705795288086,
          1.5920705795288086,
          1.593934178352356,
          1.5949573516845703,
          1.5994377136230469,
          1.6073031425476074,
          1.6073291301727295,
          1.612865924835205,
          1.61287260055542,
          1.6159136295318604,
          1.6167877912521362,
          1.6204866170883179,
          1.6204866170883179,
          1.6330788135528564,
          1.6402626037597656,
          1.6410046815872192,
          1.6451953649520874,
          1.6520675420761108,
          1.6540815830230713,
          1.6568201780319214,
          1.6568201780319214,
          1.6568856239318848,
          1.65688955783844,
          1.6574437618255615,
          1.6625102758407593,
          1.6664860248565674,
          1.6669766902923584,
          1.6756930351257324,
          1.6756943464279175,
          1.6756943464279175,
          1.6756972074508667,
          1.6757036447525024,
          1.6774789094924927,
          1.685190200805664,
          1.6851969957351685,
          1.6893930435180664,
          1.6900362968444824,
          1.6900362968444824,
          1.6952083110809326,
          1.70393705368042,
          1.7045284509658813,
          1.7107073068618774,
          1.710900902748108,
          1.7113020420074463,
          1.717665433883667,
          1.7176792621612549,
          1.722401738166809,
          1.7225558757781982,
          1.7304162979125977,
          1.7409740686416626,
          1.7577906847000122,
          1.7577906847000122,
          1.7658882141113281,
          1.7722673416137695,
          1.7838718891143799,
          1.800353765487671,
          1.8003571033477783,
          1.809327483177185,
          1.8093425035476685,
          1.8153513669967651,
          1.8153513669967651,
          1.8302674293518066,
          1.8319379091262817,
          1.8418132066726685,
          1.8418132066726685,
          1.8465386629104614,
          1.8530420064926147,
          1.8582911491394043,
          1.863723874092102,
          1.868141531944275,
          1.8764375448226929,
          1.88614022731781,
          1.8871053457260132,
          1.8885525465011597,
          1.8898725509643555,
          1.8898868560791016,
          1.892253041267395,
          1.8936375379562378,
          1.8937817811965942,
          1.8937817811965942,
          1.896453619003296,
          1.8964606523513794,
          1.8969674110412598,
          1.9069808721542358,
          1.909347653388977,
          1.9133156538009644,
          1.9197460412979126,
          1.922955870628357,
          1.9307878017425537,
          1.9395501613616943,
          1.9429652690887451,
          1.942966341972351,
          1.9429802894592285,
          1.9514836072921753,
          1.9515331983566284,
          1.952938199043274,
          1.9624741077423096,
          1.9624741077423096,
          1.9624789953231812,
          1.9624899625778198,
          1.9629026651382446,
          1.9638090133666992,
          1.9656604528427124,
          1.9656604528427124,
          1.9678983688354492,
          1.9693636894226074,
          1.9731491804122925,
          1.973465919494629,
          1.9738125801086426,
          1.9794143438339233,
          1.9794200658798218,
          1.9911998510360718,
          1.9912091493606567,
          1.9924306869506836,
          1.9924306869506836,
          1.9936580657958984,
          1.9966371059417725,
          1.997925043106079,
          2.0086312294006348,
          2.0110578536987305,
          2.025968074798584,
          2.025968074798584,
          2.0266098976135254,
          2.030493974685669,
          2.0323188304901123,
          2.0468339920043945,
          2.0472939014434814,
          2.0508038997650146,
          2.0542376041412354,
          2.0761215686798096,
          2.0761356353759766,
          2.078317642211914,
          2.0804221630096436,
          2.0804684162139893,
          2.089547872543335,
          2.0906710624694824,
          2.0951802730560303,
          2.1084866523742676,
          2.1087775230407715,
          2.1121721267700195,
          2.1204118728637695,
          2.1211354732513428,
          2.1223342418670654,
          2.1233391761779785,
          2.1250226497650146,
          2.1403496265411377,
          2.141495704650879,
          2.1428427696228027,
          2.1452696323394775,
          2.150036573410034,
          2.1504786014556885,
          2.1504786014556885,
          2.157637357711792,
          2.1595706939697266,
          2.164529323577881,
          2.1704702377319336,
          2.1704702377319336,
          2.171804666519165,
          2.17745041847229,
          2.179720640182495,
          2.1797232627868652,
          2.1835315227508545,
          2.1837313175201416,
          2.183785915374756,
          2.1977944374084473,
          2.2029879093170166,
          2.206237316131592,
          2.206251382827759,
          2.217878818511963,
          2.2283194065093994,
          2.246943950653076,
          2.249095916748047,
          2.2493398189544678,
          2.2589914798736572,
          2.2655766010284424,
          2.26581072807312,
          2.26582407951355,
          2.265873908996582,
          2.2848691940307617,
          2.2965075969696045,
          2.327195644378662,
          2.3453304767608643,
          2.3463101387023926,
          2.3524835109710693,
          2.3524835109710693,
          2.3549582958221436,
          2.3594918251037598,
          2.3594918251037598,
          2.36006236076355,
          2.362884044647217,
          2.3665096759796143,
          2.3721909523010254,
          2.3741343021392822,
          2.3789777755737305,
          2.382342576980591,
          2.402597427368164,
          2.411290407180786,
          2.4115209579467773,
          2.426743745803833,
          2.43196439743042,
          2.4335408210754395,
          2.4423940181732178,
          2.4601900577545166,
          2.4662342071533203,
          2.4662342071533203,
          2.4662387371063232,
          2.466240644454956,
          2.469766139984131,
          2.470979928970337,
          2.4709815979003906,
          2.473501443862915,
          2.473501443862915,
          2.4759418964385986,
          2.4780657291412354,
          2.487117052078247,
          2.4871227741241455,
          2.4872796535491943,
          2.4894440174102783,
          2.493403911590576,
          2.501417636871338,
          2.502908229827881,
          2.5029149055480957,
          2.507404088973999,
          2.507404088973999,
          2.5170528888702393,
          2.525351047515869,
          2.5340209007263184,
          2.5438811779022217,
          2.5439696311950684,
          2.5478789806365967,
          2.5552430152893066,
          2.5583934783935547,
          2.561108112335205,
          2.571084976196289,
          2.573629379272461,
          2.573629379272461,
          2.5736515522003174,
          2.57367205619812,
          2.5746052265167236,
          2.5753889083862305,
          2.581057071685791,
          2.6051738262176514,
          2.605185031890869,
          2.6056463718414307,
          2.624436616897583,
          2.624971389770508,
          2.6263527870178223,
          2.659972667694092,
          2.659980297088623,
          2.6716103553771973,
          2.682307481765747,
          2.684561014175415,
          2.6845617294311523,
          2.7026796340942383,
          2.7096645832061768,
          2.709669351577759,
          2.715580940246582,
          2.7198526859283447,
          2.7219769954681396,
          2.738957405090332,
          2.738961696624756,
          2.738961696624756,
          2.738970994949341,
          2.7389774322509766,
          2.774254322052002,
          2.779162645339966,
          2.788011312484741,
          2.7991466522216797,
          2.8115217685699463,
          2.829921245574951,
          2.8299684524536133,
          2.8396475315093994,
          2.845935821533203,
          2.850527286529541,
          2.8532745838165283,
          2.85329008102417,
          2.8617777824401855,
          2.873211622238159,
          2.873213529586792,
          2.9023330211639404,
          2.902336597442627,
          2.9096221923828125,
          2.9096503257751465,
          2.921546697616577,
          2.9279141426086426,
          2.955354690551758,
          2.9661991596221924,
          2.984853744506836,
          2.984853744506836,
          2.9848592281341553,
          2.9848649501800537,
          3.0136938095092773,
          3.0213301181793213,
          3.028913974761963,
          3.062980890274048,
          3.1004116535186768,
          3.100850820541382,
          3.1044654846191406,
          3.1153979301452637,
          3.115412712097168,
          3.1179628372192383,
          3.1179628372192383,
          3.132131814956665,
          3.1408324241638184,
          3.1720597743988037,
          3.179990530014038,
          3.202437400817871,
          3.2134993076324463,
          3.2571938037872314,
          3.3196358680725098,
          3.321406126022339,
          3.330950975418091,
          3.3468048572540283,
          3.415384292602539,
          3.440028190612793,
          3.4645187854766846,
          3.4872894287109375,
          3.5042026042938232,
          3.504216194152832,
          3.5085294246673584,
          3.5085577964782715,
          3.549659252166748,
          3.652848243713379,
          3.6798970699310303,
          3.7038590908050537,
          3.733917236328125,
          3.7629787921905518,
          3.7904012203216553,
          3.8320024013519287,
          3.9471168518066406,
          3.9648704528808594,
          3.9791147708892822,
          3.979132652282715,
          3.987490177154541,
          4.0088090896606445,
          4.03474760055542,
          4.0602498054504395,
          4.07943058013916,
          4.07943058013916,
          4.100521564483643,
          4.116880893707275,
          4.141443729400635,
          4.162281513214111,
          4.174187660217285,
          4.192168235778809,
          4.192168235778809,
          4.20224142074585,
          4.20224142074585,
          4.202242374420166,
          4.202254295349121,
          4.2054901123046875,
          4.378623962402344,
          4.393458843231201,
          4.417349815368652,
          4.506014823913574,
          4.5242180824279785,
          4.605929374694824,
          4.715191841125488,
          4.76943826675415,
          4.769464492797852,
          5.057713985443115,
          5.130300045013428,
          5.177319526672363,
          5.194574356079102,
          5.413733959197998,
          5.4236860275268555,
          5.431927680969238,
          5.431956768035889,
          5.484041690826416,
          5.676769733428955,
          5.676874160766602,
          5.818920612335205,
          5.916632175445557,
          5.916671276092529,
          6.0907063484191895,
          6.136951446533203,
          6.137069225311279,
          6.164646148681641,
          6.347757339477539,
          6.401012420654297,
          7.222805023193359,
          7.411506175994873,
          7.411506175994873,
          7.580981254577637,
          7.62407922744751,
          7.624763488769531,
          7.713517665863037,
          7.713517665863037,
          7.860332489013672,
          7.949744701385498,
          8.196724891662598,
          8.264861106872559,
          8.45398998260498,
          8.5648193359375,
          9.017565727233887,
          9.017690658569336,
          9.931218147277832,
          10.545502662658691,
          10.8806791305542,
          12.28197956085205,
          13.024867057800293,
          13.024970054626465,
          13.165056228637695,
          13.165092468261719,
          14.621964454650879,
          14.894187927246094,
          15.86564826965332,
          15.865677833557129,
          20.029396057128906,
          20.26714324951172,
          20.267480850219727,
          65.23036193847656,
          65.4332275390625,
          70.78983306884766,
          72.65277099609375,
          98.24201202392578,
          98.50687408447266,
          98.5245361328125
         ]
        }
       ],
       "layout": {
        "autosize": false,
        "height": 300,
        "margin": {
         "b": 25,
         "l": 10,
         "r": 10,
         "t": 25
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 990,
        "xaxis": {
         "title": {
          "text": "Instance"
         }
        },
        "yaxis": {
         "title": {
          "text": "Euclidian distance"
         }
        }
       }
      },
      "text/html": [
       "<div>                        <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.29.1.min.js\"></script>                <div id=\"09f77b82-a644-4cb0-8e1a-2c7ff1644c6e\" class=\"plotly-graph-div\" style=\"height:300px; width:990px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"09f77b82-a644-4cb0-8e1a-2c7ff1644c6e\")) {                    Plotly.newPlot(                        \"09f77b82-a644-4cb0-8e1a-2c7ff1644c6e\",                        [{\"mode\":\"markers\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,2181,2182,2183,2184,2185,2186,2187,2188,2189,2190,2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,2221,2222,2223,2224,2225,2226,2227,2228,2229,2230,2231,2232,2233,2234,2235,2236,2237,2238,2239,2240,2241,2242,2243,2244,2245,2246,2247,2248,2249,2250,2251,2252,2253,2254,2255,2256,2257,2258,2259,2260,2261,2262,2263,2264,2265,2266,2267,2268,2269,2270,2271,2272,2273,2274,2275,2276,2277,2278,2279,2280,2281,2282,2283,2284,2285,2286,2287,2288,2289,2290,2291,2292,2293,2294,2295,2296,2297,2298,2299,2300,2301,2302,2303,2304,2305,2306,2307,2308,2309,2310,2311,2312,2313,2314,2315,2316,2317,2318,2319,2320,2321,2322,2323,2324,2325,2326,2327,2328,2329,2330,2331,2332,2333,2334,2335,2336,2337,2338,2339,2340,2341,2342,2343,2344,2345,2346,2347,2348,2349,2350,2351,2352,2353,2354,2355,2356,2357,2358,2359,2360,2361,2362,2363,2364,2365,2366,2367,2368,2369,2370,2371,2372,2373,2374,2375,2376,2377,2378,2379,2380,2381,2382,2383,2384,2385,2386,2387,2388,2389,2390,2391,2392,2393,2394,2395,2396,2397,2398,2399,2400,2401,2402,2403,2404,2405,2406,2407,2408,2409,2410,2411,2412,2413,2414,2415,2416,2417,2418,2419,2420,2421,2422,2423,2424,2425,2426,2427,2428,2429,2430,2431,2432,2433,2434,2435,2436,2437,2438,2439,2440,2441,2442,2443,2444,2445,2446,2447,2448,2449,2450,2451,2452,2453,2454,2455,2456,2457,2458,2459,2460,2461,2462,2463,2464,2465,2466,2467,2468,2469,2470,2471,2472,2473,2474,2475,2476,2477,2478,2479,2480,2481,2482,2483,2484,2485,2486,2487,2488,2489,2490,2491,2492,2493,2494,2495,2496,2497,2498,2499,2500,2501,2502,2503,2504,2505,2506,2507,2508,2509,2510,2511,2512,2513,2514,2515,2516,2517,2518,2519,2520,2521,2522,2523,2524,2525,2526,2527,2528,2529,2530,2531,2532,2533,2534,2535,2536,2537,2538,2539,2540,2541,2542,2543,2544,2545,2546,2547,2548,2549,2550,2551,2552,2553,2554,2555,2556,2557,2558,2559,2560,2561,2562,2563,2564,2565,2566,2567,2568,2569,2570,2571,2572,2573,2574,2575,2576,2577,2578,2579,2580,2581,2582,2583,2584,2585,2586,2587,2588,2589,2590,2591,2592,2593,2594,2595,2596,2597,2598,2599,2600,2601,2602,2603,2604,2605,2606,2607,2608,2609,2610,2611,2612,2613,2614,2615,2616,2617,2618,2619,2620,2621,2622,2623,2624,2625,2626,2627,2628,2629,2630,2631,2632,2633,2634,2635,2636,2637,2638,2639,2640,2641,2642,2643,2644,2645,2646,2647,2648,2649,2650,2651,2652,2653,2654,2655,2656,2657,2658,2659,2660,2661,2662,2663,2664,2665,2666,2667,2668,2669,2670,2671,2672,2673,2674,2675,2676,2677,2678,2679,2680,2681,2682,2683,2684,2685,2686,2687,2688,2689,2690,2691,2692,2693,2694,2695,2696,2697,2698,2699,2700,2701,2702,2703,2704,2705,2706,2707,2708,2709,2710,2711,2712,2713,2714,2715,2716,2717,2718,2719,2720,2721,2722,2723,2724,2725,2726,2727,2728,2729,2730,2731,2732,2733,2734,2735,2736,2737,2738,2739,2740,2741,2742,2743,2744,2745,2746,2747,2748,2749,2750,2751,2752,2753,2754,2755,2756,2757,2758,2759,2760,2761,2762,2763,2764,2765,2766,2767,2768,2769,2770,2771,2772,2773,2774,2775,2776,2777,2778,2779,2780,2781,2782,2783,2784,2785,2786,2787,2788,2789,2790,2791,2792,2793,2794,2795,2796,2797,2798,2799,2800,2801,2802,2803,2804,2805,2806,2807,2808,2809,2810,2811,2812,2813,2814,2815,2816,2817,2818,2819,2820,2821,2822,2823,2824,2825,2826,2827,2828,2829,2830,2831,2832,2833,2834,2835,2836,2837,2838,2839,2840,2841,2842,2843,2844,2845,2846,2847,2848,2849,2850,2851,2852,2853,2854,2855,2856,2857,2858,2859,2860,2861,2862,2863,2864,2865,2866,2867,2868,2869,2870,2871,2872,2873,2874,2875,2876,2877,2878,2879,2880,2881,2882,2883,2884,2885,2886,2887,2888,2889,2890,2891,2892,2893,2894,2895,2896,2897,2898,2899,2900,2901,2902,2903,2904,2905,2906,2907,2908,2909,2910,2911,2912,2913,2914,2915,2916,2917,2918,2919,2920,2921,2922,2923,2924,2925,2926,2927,2928,2929,2930,2931,2932,2933,2934,2935,2936,2937,2938,2939,2940,2941,2942,2943,2944,2945,2946,2947,2948,2949,2950,2951,2952,2953,2954,2955,2956,2957,2958,2959,2960,2961,2962,2963,2964,2965,2966,2967,2968,2969,2970,2971,2972,2973,2974,2975,2976,2977,2978,2979,2980,2981,2982,2983,2984,2985,2986,2987,2988,2989,2990,2991,2992,2993,2994,2995,2996,2997,2998,2999,3000,3001,3002,3003,3004,3005,3006,3007,3008,3009],\"y\":[2.3822776711313054e-05,2.3975000658538193e-05,2.412626417935826e-05,2.427658546366729e-05,2.4425980882369913e-05,2.4425980882369913e-05,2.457446862536017e-05,2.4722063244553283e-05,2.4722063244553283e-05,2.4722063244553283e-05,2.4722063244553283e-05,2.4722063244553283e-05,2.4722063244553283e-05,2.4722063244553283e-05,2.4722063244553283e-05,2.486878292984329e-05,2.486878292984329e-05,2.486878292984329e-05,2.5014642233145423e-05,2.5014642233145423e-05,2.5014642233145423e-05,2.5014642233145423e-05,2.5014642233145423e-05,2.5014642233145423e-05,2.5014642233145423e-05,2.5014642233145423e-05,2.5159655706374906e-05,2.5159655706374906e-05,2.5303839720436372e-05,2.5303839720436372e-05,2.5303839720436372e-05,2.5303839720436372e-05,2.5303839720436372e-05,2.5303839720436372e-05,2.5303839720436372e-05,2.5303839720436372e-05,2.5303839720436372e-05,2.5303839720436372e-05,2.5303839720436372e-05,2.5303839720436372e-05,2.5303839720436372e-05,2.5303839720436372e-05,2.5303839720436372e-05,2.5447205189266242e-05,2.5589766664779745e-05,2.5589766664779745e-05,2.5589766664779745e-05,2.5589766664779745e-05,2.5589766664779745e-05,2.5589766664779745e-05,2.5589766664779745e-05,2.5589766664779745e-05,2.5589766664779745e-05,2.5589766664779745e-05,2.5589766664779745e-05,2.5589766664779745e-05,2.5589766664779745e-05,2.5589766664779745e-05,2.5589766664779745e-05,2.5589766664779745e-05,2.5589766664779745e-05,2.5731540517881513e-05,2.5731540517881513e-05,2.5731540517881513e-05,2.5731540517881513e-05,2.5731540517881513e-05,2.5731540517881513e-05,2.5731540517881513e-05,2.5731540517881513e-05,2.5872535843518563e-05,2.5872535843518563e-05,2.5872535843518563e-05,2.5872535843518563e-05,2.5872535843518563e-05,2.5872535843518563e-05,2.5872535843518563e-05,2.5872535843518563e-05,2.5872535843518563e-05,2.5872535843518563e-05,2.5872535843518563e-05,2.5872535843518563e-05,2.5872535843518563e-05,2.5872535843518563e-05,2.5872535843518563e-05,2.5872535843518563e-05,2.5872535843518563e-05,2.5872535843518563e-05,2.5872535843518563e-05,2.5872535843518563e-05,2.5872535843518563e-05,2.5872535843518563e-05,2.5872535843518563e-05,2.5872535843518563e-05,2.5872535843518563e-05,2.5872535843518563e-05,2.5872535843518563e-05,2.6012767193606123e-05,2.6012767193606123e-05,2.6012767193606123e-05,2.6012767193606123e-05,2.6012767193606123e-05,2.6012767193606123e-05,2.6012767193606123e-05,2.6012767193606123e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.615224730107002e-05,2.6290987079846673e-05,2.6290987079846673e-05,2.6290987079846673e-05,2.6290987079846673e-05,2.6290987079846673e-05,2.6290987079846673e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.6428997443872504e-05,2.656629294506274e-05,2.656629294506274e-05,2.656629294506274e-05,2.656629294506274e-05,2.656629294506274e-05,2.656629294506274e-05,2.6702880859375e-05,2.6702880859375e-05,2.6702880859375e-05,2.6702880859375e-05,2.6702880859375e-05,2.6702880859375e-05,2.6702880859375e-05,2.6702880859375e-05,2.6702880859375e-05,2.6702880859375e-05,2.6702880859375e-05,2.6702880859375e-05,2.6702880859375e-05,2.6702880859375e-05,2.6702880859375e-05,2.6702880859375e-05,2.6702880859375e-05,2.6702880859375e-05,2.6702880859375e-05,2.6702880859375e-05,2.6702880859375e-05,2.6702880859375e-05,2.6702880859375e-05,2.6702880859375e-05,2.6702880859375e-05,2.6702880859375e-05,2.6702880859375e-05,2.6838773919735104e-05,2.6838773919735104e-05,2.6838773919735104e-05,2.6838773919735104e-05,2.6838773919735104e-05,2.6973983040079474e-05,2.6973983040079474e-05,2.6973983040079474e-05,2.6973983040079474e-05,2.6973983040079474e-05,2.6973983040079474e-05,2.6973983040079474e-05,2.6973983040079474e-05,2.6973983040079474e-05,2.6973983040079474e-05,2.6973983040079474e-05,2.6973983040079474e-05,2.6973983040079474e-05,2.6973983040079474e-05,2.6973983040079474e-05,2.6973983040079474e-05,2.6973983040079474e-05,2.6973983040079474e-05,2.6973983040079474e-05,2.6973983040079474e-05,2.6973983040079474e-05,2.6973983040079474e-05,2.6973983040079474e-05,2.6973983040079474e-05,2.6973983040079474e-05,2.6973983040079474e-05,2.6973983040079474e-05,2.710851731535513e-05,2.710851731535513e-05,2.710851731535513e-05,2.710851731535513e-05,2.724238765949849e-05,2.724238765949849e-05,2.724238765949849e-05,2.724238765949849e-05,2.724238765949849e-05,2.724238765949849e-05,2.724238765949849e-05,2.724238765949849e-05,2.724238765949849e-05,2.724238765949849e-05,2.724238765949849e-05,2.724238765949849e-05,2.724238765949849e-05,2.724238765949849e-05,2.724238765949849e-05,2.724238765949849e-05,2.724238765949849e-05,2.724238765949849e-05,2.724238765949849e-05,2.724238765949849e-05,2.724238765949849e-05,2.724238765949849e-05,2.724238765949849e-05,2.724238765949849e-05,2.7375603167456575e-05,2.7375603167456575e-05,2.75081729341764e-05,2.75081729341764e-05,2.75081729341764e-05,2.75081729341764e-05,2.75081729341764e-05,2.75081729341764e-05,2.75081729341764e-05,2.75081729341764e-05,2.75081729341764e-05,2.75081729341764e-05,2.75081729341764e-05,2.75081729341764e-05,2.75081729341764e-05,2.75081729341764e-05,2.75081729341764e-05,2.75081729341764e-05,2.75081729341764e-05,2.75081729341764e-05,2.75081729341764e-05,2.75081729341764e-05,2.75081729341764e-05,2.75081729341764e-05,2.75081729341764e-05,2.75081729341764e-05,2.75081729341764e-05,2.75081729341764e-05,2.75081729341764e-05,2.75081729341764e-05,2.764010787359439e-05,2.764010787359439e-05,2.764010787359439e-05,2.764010787359439e-05,2.764010787359439e-05,2.764010787359439e-05,2.764010787359439e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7771415261668153e-05,2.7902104193344712e-05,2.7902104193344712e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8032185582560487e-05,2.8161664886283688e-05,2.8161664886283688e-05,2.8161664886283688e-05,2.8161664886283688e-05,2.8161664886283688e-05,2.8290551199461333e-05,2.8290551199461333e-05,2.8290551199461333e-05,2.8290551199461333e-05,2.8290551199461333e-05,2.8290551199461333e-05,2.8290551199461333e-05,2.8290551199461333e-05,2.8290551199461333e-05,2.8290551199461333e-05,2.8290551199461333e-05,2.8290551199461333e-05,2.8290551199461333e-05,2.8290551199461333e-05,2.8290551199461333e-05,2.8290551199461333e-05,2.8290551199461333e-05,2.8290551199461333e-05,2.8290551199461333e-05,2.8290551199461333e-05,2.8290551199461333e-05,2.8290551199461333e-05,2.8290551199461333e-05,2.8290551199461333e-05,2.8290551199461333e-05,2.8290551199461333e-05,2.8290551199461333e-05,2.8290551199461333e-05,2.8418855436029844e-05,2.8418855436029844e-05,2.8418855436029844e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.8546581233968027e-05,2.86737376882229e-05,2.86737376882229e-05,2.86737376882229e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8800332074752077e-05,2.8926373488502577e-05,2.8926373488502577e-05,2.8926373488502577e-05,2.8926373488502577e-05,2.8926373488502577e-05,2.9051869205432013e-05,2.9051869205432013e-05,2.9051869205432013e-05,2.9051869205432013e-05,2.9051869205432013e-05,2.9051869205432013e-05,2.9051869205432013e-05,2.9051869205432013e-05,2.9051869205432013e-05,2.9051869205432013e-05,2.9051869205432013e-05,2.9051869205432013e-05,2.9051869205432013e-05,2.9051869205432013e-05,2.9051869205432013e-05,2.9051869205432013e-05,2.9051869205432013e-05,2.9051869205432013e-05,2.9051869205432013e-05,2.9051869205432013e-05,2.9051869205432013e-05,2.9051869205432013e-05,2.9051869205432013e-05,2.9051869205432013e-05,2.9051869205432013e-05,2.9051869205432013e-05,2.9051869205432013e-05,2.9176822863519192e-05,2.9176822863519192e-05,2.9301245376700535e-05,2.9301245376700535e-05,2.9301245376700535e-05,2.9301245376700535e-05,2.9301245376700535e-05,2.9301245376700535e-05,2.9301245376700535e-05,2.9301245376700535e-05,2.9301245376700535e-05,2.9301245376700535e-05,2.9301245376700535e-05,2.9301245376700535e-05,2.9301245376700535e-05,2.9301245376700535e-05,2.9301245376700535e-05,2.9301245376700535e-05,2.9425142201944254e-05,2.9425142201944254e-05,2.9425142201944254e-05,2.9425142201944254e-05,2.9425142201944254e-05,2.9425142201944254e-05,2.9425142201944254e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.954851879621856e-05,2.967138061649166e-05,2.967138061649166e-05,2.967138061649166e-05,2.967138061649166e-05,2.967138061649166e-05,2.979373857669998e-05,2.979373857669998e-05,2.979373857669998e-05,2.979373857669998e-05,2.979373857669998e-05,2.979373857669998e-05,2.979373857669998e-05,2.979373857669998e-05,2.979373857669998e-05,2.979373857669998e-05,2.979373857669998e-05,2.979373857669998e-05,2.979373857669998e-05,2.979373857669998e-05,2.979373857669998e-05,2.979373857669998e-05,2.979373857669998e-05,2.979373857669998e-05,2.979373857669998e-05,2.979373857669998e-05,2.991559449583292e-05,2.991559449583292e-05,2.991559449583292e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0036955649848096e-05,3.0157829314703122e-05,3.0157829314703122e-05,3.0157829314703122e-05,3.0157829314703122e-05,3.0157829314703122e-05,3.0278220947366208e-05,3.0278220947366208e-05,3.0278220947366208e-05,3.0278220947366208e-05,3.0278220947366208e-05,3.0278220947366208e-05,3.0278220947366208e-05,3.0278220947366208e-05,3.0278220947366208e-05,3.0278220947366208e-05,3.0278220947366208e-05,3.0278220947366208e-05,3.0278220947366208e-05,3.0278220947366208e-05,3.0278220947366208e-05,3.0278220947366208e-05,3.0278220947366208e-05,3.0278220947366208e-05,3.0278220947366208e-05,3.039813418581616e-05,3.039813418581616e-05,3.039813418581616e-05,3.0517578125e-05,3.0517578125e-05,3.0517578125e-05,3.0517578125e-05,3.0517578125e-05,3.0517578125e-05,3.0517578125e-05,3.0517578125e-05,3.0517578125e-05,3.0517578125e-05,3.0517578125e-05,3.0517578125e-05,3.0517578125e-05,3.0517578125e-05,3.0517578125e-05,3.0517578125e-05,3.0517578125e-05,3.0517578125e-05,3.0517578125e-05,3.0517578125e-05,3.0517578125e-05,3.063655458390713e-05,3.063655458390713e-05,3.063655458390713e-05,3.063655458390713e-05,3.063655458390713e-05,3.063655458390713e-05,3.075507265748456e-05,3.075507265748456e-05,3.075507265748456e-05,3.075507265748456e-05,3.075507265748456e-05,3.075507265748456e-05,3.075507265748456e-05,3.075507265748456e-05,3.075507265748456e-05,3.075507265748456e-05,3.075507265748456e-05,3.075507265748456e-05,3.075507265748456e-05,3.075507265748456e-05,3.075507265748456e-05,3.075507265748456e-05,3.075507265748456e-05,3.075507265748456e-05,3.075507265748456e-05,3.075507265748456e-05,3.075507265748456e-05,3.075507265748456e-05,3.075507265748456e-05,3.075507265748456e-05,3.087313598371111e-05,3.087313598371111e-05,3.087313598371111e-05,3.0990748200565577e-05,3.0990748200565577e-05,3.0990748200565577e-05,3.0990748200565577e-05,3.0990748200565577e-05,3.0990748200565577e-05,3.0990748200565577e-05,3.0990748200565577e-05,3.0990748200565577e-05,3.0990748200565577e-05,3.0990748200565577e-05,3.0990748200565577e-05,3.0990748200565577e-05,3.0990748200565577e-05,3.0990748200565577e-05,3.0990748200565577e-05,3.0990748200565577e-05,3.0990748200565577e-05,3.110791658400558e-05,3.110791658400558e-05,3.110791658400558e-05,3.110791658400558e-05,3.110791658400558e-05,3.122464113403112e-05,3.122464113403112e-05,3.122464113403112e-05,3.122464113403112e-05,3.122464113403112e-05,3.122464113403112e-05,3.122464113403112e-05,3.122464113403112e-05,3.122464113403112e-05,3.122464113403112e-05,3.122464113403112e-05,3.122464113403112e-05,3.122464113403112e-05,3.122464113403112e-05,3.122464113403112e-05,3.122464113403112e-05,3.122464113403112e-05,3.122464113403112e-05,3.122464113403112e-05,3.122464113403112e-05,3.134093640255742e-05,3.134093640255742e-05,3.134093640255742e-05,3.1456798751605675e-05,3.1456798751605675e-05,3.1456798751605675e-05,3.1456798751605675e-05,3.1456798751605675e-05,3.1456798751605675e-05,3.1456798751605675e-05,3.1456798751605675e-05,3.1456798751605675e-05,3.1456798751605675e-05,3.1456798751605675e-05,3.1456798751605675e-05,3.1456798751605675e-05,3.1456798751605675e-05,3.157223909511231e-05,3.157223909511231e-05,3.157223909511231e-05,3.157223909511231e-05,3.168725379509851e-05,3.168725379509851e-05,3.168725379509851e-05,3.168725379509851e-05,3.168725379509851e-05,3.168725379509851e-05,3.168725379509851e-05,3.168725379509851e-05,3.168725379509851e-05,3.168725379509851e-05,3.168725379509851e-05,3.168725379509851e-05,3.168725379509851e-05,3.1801857403479517e-05,3.1801857403479517e-05,3.1801857403479517e-05,3.1801857403479517e-05,3.191604628227651e-05,3.191604628227651e-05,3.191604628227651e-05,3.191604628227651e-05,3.191604628227651e-05,3.191604628227651e-05,3.191604628227651e-05,3.191604628227651e-05,3.191604628227651e-05,3.191604628227651e-05,3.191604628227651e-05,3.191604628227651e-05,3.191604628227651e-05,3.191604628227651e-05,3.191604628227651e-05,3.191604628227651e-05,3.191604628227651e-05,3.202983134542592e-05,3.202983134542592e-05,3.202983134542592e-05,3.202983134542592e-05,3.214320895494893e-05,3.214320895494893e-05,3.214320895494893e-05,3.214320895494893e-05,3.214320895494893e-05,3.214320895494893e-05,3.214320895494893e-05,3.214320895494893e-05,3.214320895494893e-05,3.214320895494893e-05,3.225619366276078e-05,3.225619366276078e-05,3.2368778192903847e-05,3.2368778192903847e-05,3.2368778192903847e-05,3.2368778192903847e-05,3.2368778192903847e-05,3.2368778192903847e-05,3.2368778192903847e-05,3.2368778192903847e-05,3.2368778192903847e-05,3.2368778192903847e-05,3.2368778192903847e-05,3.2368778192903847e-05,3.2368778192903847e-05,3.2368778192903847e-05,3.2368778192903847e-05,3.2368778192903847e-05,3.248097709729336e-05,3.248097709729336e-05,3.248097709729336e-05,3.259278673795052e-05,3.259278673795052e-05,3.259278673795052e-05,3.259278673795052e-05,3.259278673795052e-05,3.259278673795052e-05,3.259278673795052e-05,3.259278673795052e-05,3.259278673795052e-05,3.270421802881174e-05,3.281526733189821e-05,3.281526733189821e-05,3.281526733189821e-05,3.281526733189821e-05,3.281526733189821e-05,3.281526733189821e-05,3.281526733189821e-05,3.281526733189821e-05,3.2925941923167557e-05,3.2925941923167557e-05,3.2925941923167557e-05,3.2925941923167557e-05,3.2925941923167557e-05,3.2925941923167557e-05,3.2925941923167557e-05,3.3036249078577384e-05,3.3036249078577384e-05,3.3036249078577384e-05,3.3036249078577384e-05,3.3036249078577384e-05,3.3036249078577384e-05,3.3036249078577384e-05,3.3036249078577384e-05,3.3036249078577384e-05,3.314618516014889e-05,3.314618516014889e-05,3.314618516014889e-05,3.314618516014889e-05,3.325576108181849e-05,3.325576108181849e-05,3.325576108181849e-05,3.325576108181849e-05,3.325576108181849e-05,3.325576108181849e-05,3.325576108181849e-05,3.325576108181849e-05,3.325576108181849e-05,3.325576108181849e-05,3.3364973205607384e-05,3.3364973205607384e-05,3.347383244545199e-05,3.347383244545199e-05,3.347383244545199e-05,3.347383244545199e-05,3.347383244545199e-05,3.347383244545199e-05,3.347383244545199e-05,3.347383244545199e-05,3.369049227330834e-05,3.369049227330834e-05,3.369049227330834e-05,3.369049227330834e-05,3.369049227330834e-05,3.369049227330834e-05,3.369049227330834e-05,3.369049227330834e-05,3.369049227330834e-05,3.369049227330834e-05,3.369049227330834e-05,3.369049227330834e-05,3.369049227330834e-05,3.37983037752565e-05,3.37983037752565e-05,3.390576966921799e-05,3.390576966921799e-05,3.390576966921799e-05,3.390576966921799e-05,3.401289723115042e-05,3.401289723115042e-05,3.401289723115042e-05,3.4119690099032596e-05,3.4119690099032596e-05,3.4119690099032596e-05,3.4119690099032596e-05,3.4119690099032596e-05,3.4119690099032596e-05,3.4119690099032596e-05,3.4119690099032596e-05,3.4119690099032596e-05,3.4119690099032596e-05,3.4119690099032596e-05,3.4119690099032596e-05,3.422614827286452e-05,3.422614827286452e-05,3.422614827286452e-05,3.4332275390625e-05,3.4332275390625e-05,3.4332275390625e-05,3.4332275390625e-05,3.4332275390625e-05,3.4332275390625e-05,3.4332275390625e-05,3.4332275390625e-05,3.443807509029284e-05,3.443807509029284e-05,3.454355464782566e-05,3.454355464782566e-05,3.454355464782566e-05,3.454355464782566e-05,3.454355464782566e-05,3.454355464782566e-05,3.454355464782566e-05,3.454355464782566e-05,3.454355464782566e-05,3.464870678726584e-05,3.464870678726584e-05,3.4753546060528606e-05,3.4753546060528606e-05,3.4753546060528606e-05,3.4753546060528606e-05,3.4753546060528606e-05,3.485806882963516e-05,3.49622787325643e-05,3.49622787325643e-05,3.49622787325643e-05,3.506617940729484e-05,3.506617940729484e-05,3.5169770853826776e-05,3.5169770853826776e-05,3.5169770853826776e-05,3.5169770853826776e-05,3.5169770853826776e-05,3.5273060348117724e-05,3.5273060348117724e-05,3.5273060348117724e-05,3.537604789016768e-05,3.537604789016768e-05,3.547873711795546e-05,3.547873711795546e-05,3.547873711795546e-05,3.547873711795546e-05,3.547873711795546e-05,3.558112803148106e-05,3.558112803148106e-05,3.558112803148106e-05,3.558112803148106e-05,3.558112803148106e-05,3.568322426872328e-05,3.578503310563974e-05,3.578503310563974e-05,3.578503310563974e-05,3.578503310563974e-05,3.578503310563974e-05,3.5886550904251635e-05,3.5886550904251635e-05,3.598778130253777e-05,3.598778130253777e-05,3.598778130253777e-05,3.598778130253777e-05,3.598778130253777e-05,3.598778130253777e-05,3.598778130253777e-05,3.6189394450047985e-05,3.628978447522968e-05,3.628978447522968e-05,3.638989437604323e-05,3.638989437604323e-05,3.638989437604323e-05,3.638989437604323e-05,3.638989437604323e-05,3.638989437604323e-05,3.638989437604323e-05,3.648972779046744e-05,3.648972779046744e-05,3.658929199445993e-05,3.668858335004188e-05,3.668858335004188e-05,3.668858335004188e-05,3.678760913317092e-05,3.678760913317092e-05,3.678760913317092e-05,3.678760913317092e-05,3.688636570586823e-05,3.688636570586823e-05,3.698486398207024e-05,3.708309668581933e-05,3.7181071093073115e-05,3.72787872038316e-05,3.72787872038316e-05,3.7376248656073585e-05,3.7376248656073585e-05,3.7376248656073585e-05,3.7473455449799076e-05,3.7473455449799076e-05,3.757041122298688e-05,3.757041122298688e-05,3.766711597563699e-05,3.766711597563699e-05,3.766711597563699e-05,3.7763576983707026e-05,3.7763576983707026e-05,3.7763576983707026e-05,3.7763576983707026e-05,3.785979060921818e-05,3.795575685217045e-05,3.795575685217045e-05,3.8051486626500264e-05,3.814697265625e-05,3.814697265625e-05,3.814697265625e-05,3.8242222217377275e-05,3.8242222217377275e-05,3.833723167190328e-05,3.833723167190328e-05,3.833723167190328e-05,3.8432008295785636e-05,3.8432008295785636e-05,3.8432008295785636e-05,3.8526552089024335e-05,3.8526552089024335e-05,3.8526552089024335e-05,3.8526552089024335e-05,3.862086668959819e-05,3.862086668959819e-05,3.862086668959819e-05,3.862086668959819e-05,3.8808804674772546e-05,3.890243169735186e-05,3.899583316524513e-05,3.899583316524513e-05,3.908901635440998e-05,3.9181973988888785e-05,3.927471334463917e-05,3.927471334463917e-05,3.927471334463917e-05,3.927471334463917e-05,3.9367230783682317e-05,3.9367230783682317e-05,3.955162173951976e-05,3.9643495256314054e-05,3.9643495256314054e-05,3.9643495256314054e-05,3.9643495256314054e-05,3.9643495256314054e-05,3.991784979007207e-05,3.991784979007207e-05,4.0008882933761925e-05,4.037096005049534e-05,4.090807124157436e-05,4.090807124157436e-05,4.099690340808593e-05,4.1085546399699524e-05,4.1173996578436345e-05,4.1262261220254004e-05,4.135033304919489e-05,4.152592009631917e-05,4.161343531450257e-05,4.161343531450257e-05,4.161343531450257e-05,4.178791641606949e-05,4.178791641606949e-05,4.178791641606949e-05,4.1961669921875e-05,4.264961171429604e-05,4.264961171429604e-05,4.264961171429604e-05,4.264961171429604e-05,4.2989453504560515e-05,4.2989453504560515e-05,4.31583721365314e-05,4.31583721365314e-05,4.3326632294338197e-05,4.3494241253938526e-05,4.3494241253938526e-05,4.391046240925789e-05,4.399323370307684e-05,4.399323370307684e-05,4.424061989993788e-05,4.4486630940809846e-05,4.4649885239778087e-05,4.481254654820077e-05,4.481254654820077e-05,4.497461850405671e-05,4.497461850405671e-05,4.497461850405671e-05,4.513610838330351e-05,4.513610838330351e-05,4.5377262722468004e-05,4.569682641886175e-05,4.5935037633171305e-05,4.601416731020436e-05,4.640779661713168e-05,4.7185199946397915e-05,4.74159351142589e-05,4.74159351142589e-05,4.764555342262611e-05,4.764555342262611e-05,4.779802111443132e-05,4.7950001317076385e-05,4.810150130651891e-05,4.825252835871652e-05,4.825252835871652e-05,4.825252835871652e-05,4.855317092733458e-05,4.8851961764739826e-05,4.914893725072034e-05,4.914893725072034e-05,4.9444126489106566e-05,4.9444126489106566e-05,4.988363798474893e-05,4.988363798474893e-05,4.988363798474893e-05,4.988363798474893e-05,5.0029284466290846e-05,5.0029284466290846e-05,5.0029284466290846e-05,5.031931141274981e-05,5.0894410378532484e-05,5.0894410378532484e-05,5.0894410378532484e-05,5.103717194288038e-05,5.139234053785913e-05,5.139234053785913e-05,5.1463081035763025e-05,5.1463081035763025e-05,5.160426735528745e-05,5.160426735528745e-05,5.2165200031595305e-05,5.2165200031595305e-05,5.272016642265953e-05,5.272016642265953e-05,5.299546683090739e-05,5.313258589012548e-05,5.313258589012548e-05,5.326934842742048e-05,5.326934842742048e-05,5.340576171875e-05,5.340576171875e-05,5.340576171875e-05,5.354182576411404e-05,5.541167774936184e-05,5.541167774936184e-05,5.6064371165120974e-05,5.6064371165120974e-05,5.645236524287611e-05,5.658110239892267e-05,5.670955215464346e-05,5.683771087205969e-05,5.683771087205969e-05,5.683771087205969e-05,5.683771087205969e-05,5.696557855117135e-05,5.822882667416707e-05,5.822882667416707e-05,5.885028440388851e-05,5.909703759243712e-05,5.909703759243712e-05,5.934276123298332e-05,5.934276123298332e-05,5.983118899166584e-05,5.9952672017971054e-05,6.007391129969619e-05,6.0194906836841255e-05,6.0556441894732416e-05,6.0556441894732416e-05,6.151014531496912e-05,6.151014531496912e-05,6.209877028595656e-05,6.244928226806223e-05,6.256569031393155e-05,6.268187280511484e-05,6.27978442935273e-05,6.302913971012458e-05,6.383209256455302e-05,6.383209256455302e-05,6.428641790989786e-05,6.43995008431375e-05,6.451238732552156e-05,6.462507008109242e-05,6.496195419458672e-05,6.496195419458672e-05,6.496195419458672e-05,6.496195419458672e-05,6.607249815715477e-05,6.607249815715477e-05,6.607249815715477e-05,6.651152216363698e-05,6.694766489090398e-05,6.727292202413082e-05,6.823938019806519e-05,7.002853089943528e-05,7.013235881458968e-05,7.033954170765355e-05,7.033954170765355e-05,7.044290396152064e-05,7.116225606296211e-05,7.136644853744656e-05,7.136644853744656e-05,7.136644853744656e-05,7.136644853744656e-05,7.167165313148871e-05,7.28796876501292e-05,7.347625796683133e-05,7.367404032265767e-05,7.377273141173646e-05,7.396972796414047e-05,7.396972796414047e-05,7.416619337163866e-05,7.445991650456563e-05,7.445991650456563e-05,7.533423195127398e-05,7.59115137043409e-05,7.610297325300053e-05,7.667446334380656e-05,7.686401659157127e-05,7.686401659157127e-05,7.714748062426224e-05,7.733586971880868e-05,7.780486339470372e-05,7.78983230702579e-05,7.873446156736463e-05,7.873446156736463e-05,7.873446156736463e-05,7.873446156736463e-05,8.092194912023842e-05,8.208250073948875e-05,8.225959027186036e-05,8.305184019263834e-05,8.461407560389489e-05,8.495734073221684e-05,8.495734073221684e-05,8.546965545974672e-05,8.5724655946251e-05,8.589424396632239e-05,8.589424396632239e-05,8.665326458867639e-05,8.740569319343194e-05,8.938121754908934e-05,9.13936528377235e-05,9.202833462040871e-05,9.202833462040871e-05,9.218632476404309e-05,9.218632476404309e-05,9.273716568714008e-05,9.351845073979348e-05,9.437039989279583e-05,9.437039989279583e-05,9.5367431640625e-05,9.574813884682953e-05,9.605162631487474e-05,9.635414608055726e-05,9.650505671743304e-05,9.650505671743304e-05,9.650505671743304e-05,9.658042108640075e-05,9.688129648566246e-05,9.688129648566246e-05,9.710634185466915e-05,9.859350393526256e-05,9.888825297821313e-05,0.00010078311606775969,0.00010107148409588262,0.00010128721623914316,0.00010171731264563277,0.00010171731264563277,0.00010178882075706497,0.00010178882075706497,0.00010200303950114176,0.00010200303950114176,0.00010200303950114176,0.00010306744661647826,0.00010530222789384425,0.00010537129855947569,0.00010564714466454461,0.00010599093366181478,0.00010612814367050305,0.00010633361671352759,0.0001064703828888014,0.00010667519381968305,0.00010667519381968305,0.00010701568680815399,0.00010715157986851409,0.00010735509567894042,0.00010749055945780128,0.00010755822586361319,0.00010762585588963702,0.00010796334390761331,0.00010796334390761331,0.00010796334390761331,0.0001080980509868823,0.0001080980509868823,0.00010883592767640948,0.00010936943726846948,0.00010936943726846948,0.00011016486678272486,0.00011016486678272486,0.00011016486678272486,0.00011029687448171899,0.00011075768270529807,0.00011134734813822433,0.00011154320964124054,0.00011154320964124054,0.00011160841677337885,0.00011186888150405139,0.00011193390673724934,0.00011193390673724934,0.00011219361476833001,0.00011219361476833001,0.00011277577141299844,0.00011303354403935373,0.00011431369057390839,0.00011431369057390839,0.00011456800712039694,0.00011456800712039694,0.00011456800712039694,0.00011576836550375447,0.00011583119339775294,0.00011583119339775294,0.00011583119339775294,0.0001159567545983009,0.00011627007188508287,0.00011627007188508287,0.00011633263056864962,0.00011645765334833413,0.00011664493649732322,0.00011676962458295748,0.00011708075908245519,0.00011708075908245519,0.00011720498150680214,0.00011856284982059151,0.00011935796646866947,0.00011996601097052917,0.00012032936501782387,0.00012063131725881249,0.00012087234063073993,0.0001220703125,0.0001220703125,0.00012313852494116873,0.0001237279939232394,0.00012419754057191312,0.00012449012137949467,0.00012460695870686322,0.00012460695870686322,0.00012466534099075943,0.00012466534099075943,0.00012495681585278362,0.00012495681585278362,0.00012507321662269533,0.00012571149272844195,0.00012669160787481815,0.00012777812662534416,0.0001284596073674038,0.000128799001686275,0.00012891193910036236,0.00012902477465104312,0.0001295874681090936,0.00012981185864191502,0.00012981185864191502,0.00012981185864191502,0.00013081687211524695,0.00013081687211524695,0.0001309836225118488,0.00013131648302078247,0.00013181421672925353,0.00013208991731517017,0.0001322550670010969,0.0001323650503763929,0.00013247494644019753,0.00013258474064059556,0.00013302304432727396,0.00013302304432727396,0.00013362335448618978,0.00013362335448618978,0.00013508553092833608,0.000135193215101026,0.00013556942576542497,0.00013562307867687196,0.00013562307867687196,0.00013567671703640372,0.00013583750114776194,0.0001359445886919275,0.0001359445886919275,0.0001359445886919275,0.00013615851639769971,0.00013637209485750645,0.00013637209485750645,0.00013669184409081936,0.00013669184409081936,0.0001367982622468844,0.00013690459309145808,0.00013764662435278296,0.00013801614113617688,0.00013827948714606464,0.00013833209231961519,0.00013833209231961519,0.00013917111209593713,0.00013990112347528338,0.0001400051114615053,0.0001406790834153071,0.0001406790834153071,0.00014232451212592423,0.00014465702406596392,0.00014565950550604612,0.00014565950550604612,0.00014620795263908803,0.00014620795263908803,0.0001501847873441875,0.0001542949612485245,0.0001545776322018355,0.00015518833242822438,0.00015546938811894506,0.00015560972678940743,0.00015589002578053623,0.00015589002578053623,0.00015700618678238243,0.00016008099191822112,0.000160580180818215,0.000160580180818215,0.000162472075317055,0.00016832284745760262,0.0001684524759184569,0.0001686251489445567,0.00016866829537320882,0.00016888385289348662,0.00016922815120778978,0.00016922815120778978,0.00017593159282114357,0.00017601427680347115,0.0001769213704392314,0.00017725006910040975,0.00017725006910040975,0.00018054443353321403,0.0001808263041311875,0.00018150905088987201,0.00018401713168714195,0.00018496364646125585,0.00018535660638008267,0.00018594448920339346,0.00018594448920339346,0.00018617910973262042,0.00018935659318231046,0.00019417521252762526,0.0001946990960277617,0.00019507243996486068,0.00019548229465726763,0.00019548229465726763,0.00019603980763349682,0.000203255724045448,0.00020350614795461297,0.00020372055587358773,0.00020407739793881774,0.0002041486877715215,0.00020421994850039482,0.00020436241175048053,0.00020436241175048053,0.00020443361427169293,0.00020443361427169293,0.00020991236669942737,0.00021170711261220276,0.0002145067701349035,0.00021477795962709934,0.00021525171177927405,0.0002153193054255098,0.0002153193054255098,0.00021880539134144783,0.0002201315073762089,0.00022032973356544971,0.00022098919725976884,0.00022125244140625,0.00022125244140625,0.00022568053100258112,0.00022587389685213566,0.00022738284314982593,0.0002339750062674284,0.00024071917869150639,0.00024077962734736502,0.00024138324079103768,0.00024138324079103768,0.0002416844799881801,0.00024624750949442387,0.00024624750949442387,0.00024660181952640414,0.00024660181952640414,0.00024660181952640414,0.0002474559878464788,0.000247573567321524,0.00024772045435383916,0.0002479259856045246,0.0002479259856045246,0.0002515676314942539,0.00025341191212646663,0.00025504324003122747,0.00025569857098162174,0.00025575546897016466,0.00025575546897016466,0.00025612502940930426,0.00025892214034684,0.00025909068062901497,0.00025951158022508025,0.0002597637940198183,0.00026051898021250963,0.00026051898021250963,0.0002737028698902577,0.0002770846476778388,0.0002773208834696561,0.00027802836848422885,0.00027805453282780945,0.00027805453282780945,0.0002794900501612574,0.0002835220948327333,0.0002900675463024527,0.00029141889535821974,0.0002916435187216848,0.00029181811260059476,0.00029181811260059476,0.00029251541127450764,0.00029288826044648886,0.0002946467720903456,0.00029499229276552796,0.0002959280682262033,0.0002959280682262033,0.0002966647734865546,0.00029786411323584616,0.000304889545077458,0.00031261902768164873,0.0003126423107460141,0.00031364141614176333,0.00031391967786476016,0.00031391967786476016,0.00032413704320788383,0.0003243838727939874,0.00032483215909451246,0.00032498891232535243,0.0003253916511312127,0.0003253916511312127,0.0003273090405855328,0.0003274423652328551,0.0003277533105574548,0.0003282413526903838,0.0003282413526903838,0.0003340856055729091,0.00033867123420350254,0.00033970086951740086,0.0003431319782976061,0.0003471793606877327,0.00034814205719158053,0.0003486432833597064,0.0003487476205918938,0.0003487476205918938,0.00034945624065585434,0.0003506825305521488,0.000351117952959612,0.00035190454218536615,0.000352400413248688,0.0003525655483826995,0.0003525655483826995,0.00036195426946505904,0.00036213514977134764,0.00036217531305737793,0.00036233599530532956,0.00036245645605959,0.00036245645605959,0.0003725145070347935,0.0003782325657084584,0.0003841875586658716,0.0003881067968904972,0.0003938755835406482,0.0003972783451899886,0.0004018308827653527,0.00040226519922725856,0.000402337551349774,0.00040253641782328486,0.0004027171526104212,0.00040295193321071565,0.00040295193321071565,0.00040304221329279244,0.00040396186523139477,0.00040396186523139477,0.00042646200745366514,0.0004581767425406724,0.0004585259885061532,0.00045855771168135107,0.00045885908184573054,0.00045885908184573054,0.00046863366151228547,0.000468726793769747,0.00046897510765120387,0.00046897510765120387,0.00046905266935937107,0.000475492503028363,0.00047558429650962353,0.00047587486915290356,0.00047587486915290356,0.00047604303108528256,0.00047814761637710035,0.00047852788702584803,0.00047877110773697495,0.00047877110773697495,0.00047909014392644167,0.00047909014392644167,0.00048034900100901723,0.000484421500004828,0.0004917409387417138,0.0004918297054246068,0.0004919480415992439,0.0004919480415992439,0.0004923028755001724,0.0004969366127625108,0.0005056884256191552,0.0005061342963017523,0.000514871091581881,0.0005208284128457308,0.0005211635725572705,0.0005252936389297247,0.0005275189760141075,0.0005276982556097209,0.0005307366955094039,0.0005381968803703785,0.0005528153269551694,0.0005642658215947449,0.0005644849734380841,0.0005653479020111263,0.0005653479020111263,0.0005653479020111263,0.0005774826859124005,0.0005795578472316265,0.0005839976365678012,0.000585714413318783,0.000625773158390075,0.0006350182229653001,0.0006705191917717457,0.0006841827416792512,0.0006844698218628764,0.0006848417688161135,0.0006848417688161135,0.0006848523626103997,0.0007259459816850722,0.0007371748215518892,0.0007504295790567994,0.0007695767562836409,0.0007700115675106645,0.0007702194270677865,0.000771597377024591,0.000771597377024591,0.0007793660624884069,0.0007794967968948185,0.0007795154233463109,0.0007801685715094209,0.0007801685715094209,0.00078927370486781,0.00078927370486781,0.0007893197471275926,0.0007893197471275926,0.0007894487935118377,0.0008003594703041017,0.0008665662026032805,0.0009025448234751821,0.0009027463383972645,0.000903318403288722,0.0009037613053806126,0.0009037613053806126,0.0009039142169058323,0.0010071523720398545,0.0010658717947080731,0.00108122278470546,0.00122234714217484,0.001384288421832025,0.0015143291093409061,0.0015268560964614153,0.0015393615467473865,0.0030459349509328604,0.005477872211486101,0.008249020203948021,0.00825070682913065,0.008251500315964222,0.008251500315964222,0.00825241394340992,0.008255756460130215,0.01203783880919218,0.022650523111224174,0.023080559447407722,0.024541204795241356,0.024548906832933426,0.024554600939154625,0.024554600939154625,0.024559974670410156,0.02456156350672245,0.025319406762719154,0.025662411004304886,0.0360565148293972,0.03652072325348854,0.03878064081072807,0.03954428806900978,0.04048147797584534,0.04217694699764252,0.04888121411204338,0.051648300141096115,0.05221191793680191,0.056980572640895844,0.060550518333911896,0.06184002384543419,0.06362199038267136,0.06362535059452057,0.06578996032476425,0.07003512233495712,0.07445784658193588,0.07446347922086716,0.07446561753749847,0.07446561753749847,0.07446944713592529,0.07447198778390884,0.07588234543800354,0.07769101113080978,0.07769377529621124,0.0776984915137291,0.0776984915137291,0.07770130783319473,0.07770927995443344,0.07857192307710648,0.08349283039569855,0.08898534625768661,0.08898553252220154,0.09209518879652023,0.09568092226982117,0.09652448445558548,0.09708701074123383,0.09708701074123383,0.0970873162150383,0.09709049016237259,0.09929168224334717,0.09930513054132462,0.09954231232404709,0.1009950190782547,0.1009950190782547,0.10101192444562912,0.10101675987243652,0.10280168056488037,0.10299953818321228,0.10461533069610596,0.10461932420730591,0.10463321954011917,0.10463321954011917,0.10463687777519226,0.10464133322238922,0.11008013039827347,0.11108347028493881,0.11554903537034988,0.1176232323050499,0.1176232323050499,0.12003771960735321,0.12613873183727264,0.13564810156822205,0.14071042835712433,0.14148113131523132,0.14148879051208496,0.14237043261528015,0.14237338304519653,0.14237748086452484,0.14237748086452484,0.14238038659095764,0.1423809677362442,0.1472063511610031,0.149118572473526,0.15233582258224487,0.15334512293338776,0.15351900458335876,0.1535239815711975,0.15353386104106903,0.15353386104106903,0.15354005992412567,0.15354761481285095,0.15506625175476074,0.15562501549720764,0.15771318972110748,0.1592167317867279,0.1592167317867279,0.15922869741916656,0.15923301875591278,0.15935476124286652,0.16284996271133423,0.16284996271133423,0.16883176565170288,0.171363964676857,0.17214389145374298,0.18193551898002625,0.18468961119651794,0.18708600103855133,0.18946947157382965,0.19071945548057556,0.19071945548057556,0.19072388112545013,0.190761536359787,0.1910131275653839,0.19216811656951904,0.2021237164735794,0.20493589341640472,0.20493589341640472,0.20953689515590668,0.2095557600259781,0.21103279292583466,0.21637184917926788,0.22000552713871002,0.22258135676383972,0.22583340108394623,0.2301177978515625,0.2350013703107834,0.24047939479351044,0.24047939479351044,0.24193908274173737,0.24501000344753265,0.2470572143793106,0.25228214263916016,0.25228506326675415,0.25652727484703064,0.2565302550792694,0.2571536898612976,0.25836431980133057,0.25836628675460815,0.2632279396057129,0.2632279396057129,0.26323240995407104,0.26323264837265015,0.266875296831131,0.26687896251678467,0.26815882325172424,0.26816317439079285,0.26844659447669983,0.26844659447669983,0.27048519253730774,0.27259278297424316,0.2725967764854431,0.2772282660007477,0.2777051329612732,0.27937185764312744,0.27937185764312744,0.27937185764312744,0.2793732285499573,0.27951866388320923,0.27952685952186584,0.283231645822525,0.28323233127593994,0.2845456302165985,0.28555211424827576,0.2861363887786865,0.2884657680988312,0.2922910451889038,0.2925421893596649,0.2941340208053589,0.2941380739212036,0.2961338460445404,0.2992266118526459,0.3036663830280304,0.30450716614723206,0.3053090274333954,0.30724063515663147,0.3072419762611389,0.3164265751838684,0.31912994384765625,0.31912994384765625,0.319452166557312,0.31946149468421936,0.3194641172885895,0.3194641172885895,0.3194669187068939,0.31947189569473267,0.3223867118358612,0.3229687809944153,0.32305049896240234,0.3256053924560547,0.3257502615451813,0.3257502615451813,0.32767462730407715,0.32767635583877563,0.3286435008049011,0.3286549746990204,0.3286605179309845,0.3293367922306061,0.329534113407135,0.33163756132125854,0.33225804567337036,0.3322591483592987,0.3327041566371918,0.33449891209602356,0.33450353145599365,0.33451876044273376,0.3345205783843994,0.3345205783843994,0.3345242142677307,0.3345373272895813,0.3357400894165039,0.3357400894165039,0.33583590388298035,0.3364066481590271,0.33671513199806213,0.33672332763671875,0.3367302119731903,0.3382346034049988,0.3401612937450409,0.3418014645576477,0.34358617663383484,0.3453308939933777,0.3515664339065552,0.35349372029304504,0.35349568724632263,0.3534986078739166,0.35610294342041016,0.3568545877933502,0.3568545877933502,0.35719960927963257,0.35754716396331787,0.3575609624385834,0.35785335302352905,0.35805580019950867,0.35909128189086914,0.3590940535068512,0.359167218208313,0.359167218208313,0.359231173992157,0.359231173992157,0.36010777950286865,0.3619116246700287,0.36369967460632324,0.3638453483581543,0.3643348813056946,0.36516234278678894,0.36600756645202637,0.3660196363925934,0.36604127287864685,0.36748620867729187,0.3681015372276306,0.3698880672454834,0.3736932873725891,0.3736932873725891,0.37369412183761597,0.3736976981163025,0.37427857518196106,0.3784348666667938,0.38408520817756653,0.38540470600128174,0.3874392807483673,0.38949450850486755,0.38949450850486755,0.38949552178382874,0.3894995450973511,0.39003893733024597,0.39017292857170105,0.39017292857170105,0.39017820358276367,0.39018818736076355,0.39077135920524597,0.3928823173046112,0.3935604989528656,0.3937050998210907,0.39550265669822693,0.3957100510597229,0.39585673809051514,0.3964443802833557,0.3991805613040924,0.4030250906944275,0.4050958752632141,0.40846264362335205,0.40847229957580566,0.408637672662735,0.40946054458618164,0.4096241295337677,0.4096285104751587,0.4096760153770447,0.4096854031085968,0.41063275933265686,0.4130665063858032,0.41307151317596436,0.41308093070983887,0.41351908445358276,0.4162423014640808,0.4162423014640808,0.4167187213897705,0.4167414903640747,0.41737014055252075,0.4196547567844391,0.42088747024536133,0.4210590720176697,0.423053503036499,0.42543020844459534,0.42544856667518616,0.4263007342815399,0.42635491490364075,0.4263574481010437,0.4275166988372803,0.4290335476398468,0.4290335476398468,0.4291052222251892,0.434762179851532,0.4348091781139374,0.4349516034126282,0.43553441762924194,0.4372669458389282,0.4372754991054535,0.4389992952346802,0.44275471568107605,0.4436477720737457,0.4443542957305908,0.4465692937374115,0.4471176564693451,0.4479730427265167,0.45095762610435486,0.45217639207839966,0.4574967920780182,0.4576031565666199,0.4587450921535492,0.45874708890914917,0.45906609296798706,0.46499133110046387,0.46611353754997253,0.4661199748516083,0.4702525734901428,0.4702533781528473,0.4708547592163086,0.4708593785762787,0.4727855324745178,0.4727855324745178,0.4795236587524414,0.48382410407066345,0.48460903763771057,0.4860217869281769,0.488363116979599,0.488363116979599,0.4959176182746887,0.4971763491630554,0.5023117065429688,0.5042964816093445,0.5050824284553528,0.5050972104072571,0.505097508430481,0.505097508430481,0.5050978064537048,0.5051047205924988,0.5088903903961182,0.5088903903961182,0.5090233087539673,0.5090243220329285,0.5092368125915527,0.5092368125915527,0.5113470554351807,0.5137291550636292,0.5165554881095886,0.5168680548667908,0.5168849229812622,0.5178543925285339,0.5189054012298584,0.518925130367279,0.5189307928085327,0.5243127942085266,0.5243127942085266,0.5250057578086853,0.5256666541099548,0.5286405086517334,0.5324262380599976,0.5331915616989136,0.5331915616989136,0.5345459580421448,0.5399209260940552,0.5399259328842163,0.5430481433868408,0.5434662103652954,0.5449917912483215,0.5457623600959778,0.54756760597229,0.5487728714942932,0.5491310358047485,0.5505409240722656,0.5505409240722656,0.5508880019187927,0.551467776298523,0.5521489977836609,0.5541126132011414,0.5541126132011414,0.554396390914917,0.554894745349884,0.555088222026825,0.555088222026825,0.558111846446991,0.5602549910545349,0.5609023571014404,0.5613090991973877,0.5618491768836975,0.5647465586662292,0.5652133226394653,0.5656397342681885,0.565646231174469,0.5668230056762695,0.5691843032836914,0.5695197582244873,0.573432981967926,0.5744340419769287,0.5825794339179993,0.5825795531272888,0.5825795531272888,0.5825796127319336,0.582580029964447,0.5825810432434082,0.5825815796852112,0.5837964415550232,0.5846550464630127,0.5860182046890259,0.5904210805892944,0.5922104120254517,0.5962371826171875,0.5976076126098633,0.5983397364616394,0.5999302268028259,0.6009273529052734,0.6011806130409241,0.6033780574798584,0.6069674491882324,0.6090445518493652,0.610990583896637,0.6180011034011841,0.6180011034011841,0.6180048584938049,0.6180247664451599,0.619962751865387,0.6226824522018433,0.6276262402534485,0.6313779354095459,0.6313904523849487,0.6332095265388489,0.6351884603500366,0.6383557915687561,0.6416638493537903,0.6442606449127197,0.6442606449127197,0.6496574282646179,0.6513798832893372,0.6518263816833496,0.6529021859169006,0.6552501916885376,0.6552632451057434,0.660072386264801,0.6608012318611145,0.6609731912612915,0.6611005067825317,0.6611005067825317,0.662100076675415,0.662100076675415,0.6630004644393921,0.6678768992424011,0.6729322671890259,0.6729505062103271,0.674098789691925,0.674098789691925,0.6754745841026306,0.6797197461128235,0.6807955503463745,0.6823747754096985,0.6830898523330688,0.6846746802330017,0.6853594183921814,0.6880795955657959,0.6884888410568237,0.689618706703186,0.6907504200935364,0.6912476420402527,0.6912476420402527,0.6913639903068542,0.6913639903068542,0.6920415163040161,0.6920415163040161,0.6951441168785095,0.7021076679229736,0.7024878859519958,0.7034072279930115,0.7054291367530823,0.7054291367530823,0.7059946060180664,0.7060084939002991,0.7083004117012024,0.7090834379196167,0.7092223763465881,0.7092861533164978,0.7111043334007263,0.7111167907714844,0.7111309170722961,0.7187799215316772,0.7195215821266174,0.7233957052230835,0.7234109044075012,0.7234207391738892,0.7234207391738892,0.723429799079895,0.723432183265686,0.7250043749809265,0.7255299687385559,0.7273116111755371,0.7273116111755371,0.7278642058372498,0.7278642058372498,0.731401264667511,0.7343049645423889,0.7377973198890686,0.739340603351593,0.739495575428009,0.7412846088409424,0.7433462738990784,0.7451158761978149,0.7467190623283386,0.7480459213256836,0.7487056851387024,0.7533144950866699,0.7535225749015808,0.7535225749015808,0.7575500011444092,0.7575510740280151,0.7577317357063293,0.7613252997398376,0.7619670629501343,0.763778567314148,0.7658746838569641,0.7663120627403259,0.7676218748092651,0.7744508981704712,0.7744524478912354,0.7801703214645386,0.7801799178123474,0.7851488590240479,0.7891906499862671,0.7911887764930725,0.7919684052467346,0.7927255034446716,0.7932630181312561,0.797235906124115,0.7972487807273865,0.8004407286643982,0.812640905380249,0.8165396451950073,0.8165396451950073,0.8166940808296204,0.8176649808883667,0.8179557919502258,0.8196212649345398,0.8197438716888428,0.8199599385261536,0.8212286233901978,0.8212844729423523,0.8212844729423523,0.8238439559936523,0.8251259326934814,0.8254387378692627,0.8288801312446594,0.830030620098114,0.8307803869247437,0.8314699530601501,0.833355188369751,0.8333611488342285,0.8372481465339661,0.8409048914909363,0.8409048914909363,0.841296911239624,0.841296911239624,0.8413266539573669,0.8435357213020325,0.8435357213020325,0.8456830978393555,0.8456870913505554,0.8492451310157776,0.8495276570320129,0.8501108288764954,0.8537101745605469,0.8539178371429443,0.8539178371429443,0.8545756340026855,0.8553500771522522,0.855356752872467,0.8566988110542297,0.8584110140800476,0.8585273623466492,0.8618189096450806,0.8618201613426208,0.8618223667144775,0.8618223667144775,0.861824095249176,0.8618243336677551,0.8622800707817078,0.8666160106658936,0.8676528930664062,0.8676528930664062,0.8684753179550171,0.8688101768493652,0.8705454468727112,0.8733558654785156,0.8763723373413086,0.8763723373413086,0.8772287368774414,0.8772287368774414,0.8772348165512085,0.8772363066673279,0.8782873153686523,0.8824974894523621,0.8866346478462219,0.8866931200027466,0.8909333348274231,0.8909430503845215,0.8916671872138977,0.8949896693229675,0.8974927067756653,0.8975163102149963,0.9027025103569031,0.9043044447898865,0.9058942198753357,0.9058942198753357,0.9100490808486938,0.9100503921508789,0.9112115502357483,0.9112115502357483,0.9149564504623413,0.915652871131897,0.918688178062439,0.9190136790275574,0.9260053634643555,0.9260061979293823,0.9324339628219604,0.9324447512626648,0.9328678846359253,0.9328678846359253,0.9328727126121521,0.9328740835189819,0.9332227110862732,0.9332227110862732,0.9332234263420105,0.9332253336906433,0.9364520311355591,0.94004225730896,0.9439138174057007,0.9469943642616272,0.9502249956130981,0.9502249956130981,0.9509828090667725,0.9567432403564453,0.9595614671707153,0.9647497534751892,0.9705511331558228,0.9705511331558228,0.9717268347740173,0.9717411398887634,0.9717540144920349,0.9748754501342773,0.9748754501342773,0.980492115020752,0.9812118411064148,0.9812118411064148,0.9824295043945312,0.9898541569709778,0.9898556470870972,0.989858865737915,0.9906978607177734,0.9907060861587524,0.9951720237731934,0.9962278604507446,1.014529824256897,1.0154625177383423,1.0222524404525757,1.0251237154006958,1.0273258686065674,1.0287847518920898,1.0300544500350952,1.0316650867462158,1.033352255821228,1.0337995290756226,1.0338000059127808,1.0512748956680298,1.0553269386291504,1.0570780038833618,1.0732134580612183,1.0770326852798462,1.085732340812683,1.0859078168869019,1.086254596710205,1.0862584114074707,1.086276888847351,1.0877697467803955,1.0904651880264282,1.0915178060531616,1.0975029468536377,1.1004923582077026,1.1102373600006104,1.1174514293670654,1.1193609237670898,1.1261893510818481,1.1291612386703491,1.1291612386703491,1.1291687488555908,1.1291699409484863,1.1337075233459473,1.1361647844314575,1.1364305019378662,1.1390398740768433,1.142353892326355,1.1444547176361084,1.1447006464004517,1.1449612379074097,1.1492434740066528,1.1492527723312378,1.1566797494888306,1.1566797494888306,1.1600780487060547,1.1607236862182617,1.1607236862182617,1.1660089492797852,1.1683586835861206,1.1705363988876343,1.173093557357788,1.1781902313232422,1.1781902313232422,1.17819344997406,1.1781938076019287,1.182371735572815,1.1844407320022583,1.1917810440063477,1.1917893886566162,1.1940834522247314,1.2033251523971558,1.2063566446304321,1.2067933082580566,1.2107354402542114,1.2115461826324463,1.2238847017288208,1.2241111993789673,1.2241162061691284,1.2241184711456299,1.2241559028625488,1.2363617420196533,1.2420097589492798,1.2420097589492798,1.2424280643463135,1.2424280643463135,1.250899314880371,1.2509078979492188,1.2532089948654175,1.2544351816177368,1.2567633390426636,1.260742425918579,1.2632914781570435,1.2661958932876587,1.2671340703964233,1.2696493864059448,1.2703193426132202,1.2770941257476807,1.2835298776626587,1.2843855619430542,1.2875186204910278,1.2940630912780762,1.3000452518463135,1.3062292337417603,1.3068618774414062,1.3088096380233765,1.3088152408599854,1.3090457916259766,1.3207920789718628,1.3207920789718628,1.3216569423675537,1.3216569423675537,1.3388829231262207,1.342970848083496,1.3469185829162598,1.3471559286117554,1.3511338233947754,1.3511357307434082,1.354841947555542,1.3570562601089478,1.360901117324829,1.3614827394485474,1.3632797002792358,1.365458607673645,1.365645408630371,1.371476411819458,1.3796383142471313,1.3827394247055054,1.3869715929031372,1.3885576725006104,1.3990118503570557,1.3990265130996704,1.4002398252487183,1.4015954732894897,1.4123374223709106,1.4123437404632568,1.4123437404632568,1.4123437404632568,1.4123455286026,1.4123493432998657,1.4134701490402222,1.4179177284240723,1.4185954332351685,1.4196752309799194,1.419819951057434,1.430379033088684,1.4305185079574585,1.4368312358856201,1.4379833936691284,1.4434691667556763,1.4434691667556763,1.444564700126648,1.4482582807540894,1.4498363733291626,1.4514853954315186,1.45220947265625,1.4565643072128296,1.462360143661499,1.4762197732925415,1.477159857749939,1.4775327444076538,1.477537751197815,1.4801757335662842,1.481902837753296,1.481907606124878,1.48293936252594,1.4829415082931519,1.4840518236160278,1.4848257303237915,1.4913363456726074,1.4914838075637817,1.4924038648605347,1.4959056377410889,1.4996984004974365,1.5008009672164917,1.5185056924819946,1.5185080766677856,1.5220481157302856,1.522059679031372,1.5253818035125732,1.5336713790893555,1.5349916219711304,1.5376503467559814,1.540669322013855,1.5441397428512573,1.5441479682922363,1.5484205484390259,1.5484240055084229,1.5669448375701904,1.5669448375701904,1.567907452583313,1.5775190591812134,1.5785624980926514,1.5800299644470215,1.5806466341018677,1.5831838846206665,1.585568904876709,1.5855743885040283,1.5871846675872803,1.5871949195861816,1.5920705795288086,1.5920705795288086,1.593934178352356,1.5949573516845703,1.5994377136230469,1.6073031425476074,1.6073291301727295,1.612865924835205,1.61287260055542,1.6159136295318604,1.6167877912521362,1.6204866170883179,1.6204866170883179,1.6330788135528564,1.6402626037597656,1.6410046815872192,1.6451953649520874,1.6520675420761108,1.6540815830230713,1.6568201780319214,1.6568201780319214,1.6568856239318848,1.65688955783844,1.6574437618255615,1.6625102758407593,1.6664860248565674,1.6669766902923584,1.6756930351257324,1.6756943464279175,1.6756943464279175,1.6756972074508667,1.6757036447525024,1.6774789094924927,1.685190200805664,1.6851969957351685,1.6893930435180664,1.6900362968444824,1.6900362968444824,1.6952083110809326,1.70393705368042,1.7045284509658813,1.7107073068618774,1.710900902748108,1.7113020420074463,1.717665433883667,1.7176792621612549,1.722401738166809,1.7225558757781982,1.7304162979125977,1.7409740686416626,1.7577906847000122,1.7577906847000122,1.7658882141113281,1.7722673416137695,1.7838718891143799,1.800353765487671,1.8003571033477783,1.809327483177185,1.8093425035476685,1.8153513669967651,1.8153513669967651,1.8302674293518066,1.8319379091262817,1.8418132066726685,1.8418132066726685,1.8465386629104614,1.8530420064926147,1.8582911491394043,1.863723874092102,1.868141531944275,1.8764375448226929,1.88614022731781,1.8871053457260132,1.8885525465011597,1.8898725509643555,1.8898868560791016,1.892253041267395,1.8936375379562378,1.8937817811965942,1.8937817811965942,1.896453619003296,1.8964606523513794,1.8969674110412598,1.9069808721542358,1.909347653388977,1.9133156538009644,1.9197460412979126,1.922955870628357,1.9307878017425537,1.9395501613616943,1.9429652690887451,1.942966341972351,1.9429802894592285,1.9514836072921753,1.9515331983566284,1.952938199043274,1.9624741077423096,1.9624741077423096,1.9624789953231812,1.9624899625778198,1.9629026651382446,1.9638090133666992,1.9656604528427124,1.9656604528427124,1.9678983688354492,1.9693636894226074,1.9731491804122925,1.973465919494629,1.9738125801086426,1.9794143438339233,1.9794200658798218,1.9911998510360718,1.9912091493606567,1.9924306869506836,1.9924306869506836,1.9936580657958984,1.9966371059417725,1.997925043106079,2.0086312294006348,2.0110578536987305,2.025968074798584,2.025968074798584,2.0266098976135254,2.030493974685669,2.0323188304901123,2.0468339920043945,2.0472939014434814,2.0508038997650146,2.0542376041412354,2.0761215686798096,2.0761356353759766,2.078317642211914,2.0804221630096436,2.0804684162139893,2.089547872543335,2.0906710624694824,2.0951802730560303,2.1084866523742676,2.1087775230407715,2.1121721267700195,2.1204118728637695,2.1211354732513428,2.1223342418670654,2.1233391761779785,2.1250226497650146,2.1403496265411377,2.141495704650879,2.1428427696228027,2.1452696323394775,2.150036573410034,2.1504786014556885,2.1504786014556885,2.157637357711792,2.1595706939697266,2.164529323577881,2.1704702377319336,2.1704702377319336,2.171804666519165,2.17745041847229,2.179720640182495,2.1797232627868652,2.1835315227508545,2.1837313175201416,2.183785915374756,2.1977944374084473,2.2029879093170166,2.206237316131592,2.206251382827759,2.217878818511963,2.2283194065093994,2.246943950653076,2.249095916748047,2.2493398189544678,2.2589914798736572,2.2655766010284424,2.26581072807312,2.26582407951355,2.265873908996582,2.2848691940307617,2.2965075969696045,2.327195644378662,2.3453304767608643,2.3463101387023926,2.3524835109710693,2.3524835109710693,2.3549582958221436,2.3594918251037598,2.3594918251037598,2.36006236076355,2.362884044647217,2.3665096759796143,2.3721909523010254,2.3741343021392822,2.3789777755737305,2.382342576980591,2.402597427368164,2.411290407180786,2.4115209579467773,2.426743745803833,2.43196439743042,2.4335408210754395,2.4423940181732178,2.4601900577545166,2.4662342071533203,2.4662342071533203,2.4662387371063232,2.466240644454956,2.469766139984131,2.470979928970337,2.4709815979003906,2.473501443862915,2.473501443862915,2.4759418964385986,2.4780657291412354,2.487117052078247,2.4871227741241455,2.4872796535491943,2.4894440174102783,2.493403911590576,2.501417636871338,2.502908229827881,2.5029149055480957,2.507404088973999,2.507404088973999,2.5170528888702393,2.525351047515869,2.5340209007263184,2.5438811779022217,2.5439696311950684,2.5478789806365967,2.5552430152893066,2.5583934783935547,2.561108112335205,2.571084976196289,2.573629379272461,2.573629379272461,2.5736515522003174,2.57367205619812,2.5746052265167236,2.5753889083862305,2.581057071685791,2.6051738262176514,2.605185031890869,2.6056463718414307,2.624436616897583,2.624971389770508,2.6263527870178223,2.659972667694092,2.659980297088623,2.6716103553771973,2.682307481765747,2.684561014175415,2.6845617294311523,2.7026796340942383,2.7096645832061768,2.709669351577759,2.715580940246582,2.7198526859283447,2.7219769954681396,2.738957405090332,2.738961696624756,2.738961696624756,2.738970994949341,2.7389774322509766,2.774254322052002,2.779162645339966,2.788011312484741,2.7991466522216797,2.8115217685699463,2.829921245574951,2.8299684524536133,2.8396475315093994,2.845935821533203,2.850527286529541,2.8532745838165283,2.85329008102417,2.8617777824401855,2.873211622238159,2.873213529586792,2.9023330211639404,2.902336597442627,2.9096221923828125,2.9096503257751465,2.921546697616577,2.9279141426086426,2.955354690551758,2.9661991596221924,2.984853744506836,2.984853744506836,2.9848592281341553,2.9848649501800537,3.0136938095092773,3.0213301181793213,3.028913974761963,3.062980890274048,3.1004116535186768,3.100850820541382,3.1044654846191406,3.1153979301452637,3.115412712097168,3.1179628372192383,3.1179628372192383,3.132131814956665,3.1408324241638184,3.1720597743988037,3.179990530014038,3.202437400817871,3.2134993076324463,3.2571938037872314,3.3196358680725098,3.321406126022339,3.330950975418091,3.3468048572540283,3.415384292602539,3.440028190612793,3.4645187854766846,3.4872894287109375,3.5042026042938232,3.504216194152832,3.5085294246673584,3.5085577964782715,3.549659252166748,3.652848243713379,3.6798970699310303,3.7038590908050537,3.733917236328125,3.7629787921905518,3.7904012203216553,3.8320024013519287,3.9471168518066406,3.9648704528808594,3.9791147708892822,3.979132652282715,3.987490177154541,4.0088090896606445,4.03474760055542,4.0602498054504395,4.07943058013916,4.07943058013916,4.100521564483643,4.116880893707275,4.141443729400635,4.162281513214111,4.174187660217285,4.192168235778809,4.192168235778809,4.20224142074585,4.20224142074585,4.202242374420166,4.202254295349121,4.2054901123046875,4.378623962402344,4.393458843231201,4.417349815368652,4.506014823913574,4.5242180824279785,4.605929374694824,4.715191841125488,4.76943826675415,4.769464492797852,5.057713985443115,5.130300045013428,5.177319526672363,5.194574356079102,5.413733959197998,5.4236860275268555,5.431927680969238,5.431956768035889,5.484041690826416,5.676769733428955,5.676874160766602,5.818920612335205,5.916632175445557,5.916671276092529,6.0907063484191895,6.136951446533203,6.137069225311279,6.164646148681641,6.347757339477539,6.401012420654297,7.222805023193359,7.411506175994873,7.411506175994873,7.580981254577637,7.62407922744751,7.624763488769531,7.713517665863037,7.713517665863037,7.860332489013672,7.949744701385498,8.196724891662598,8.264861106872559,8.45398998260498,8.5648193359375,9.017565727233887,9.017690658569336,9.931218147277832,10.545502662658691,10.8806791305542,12.28197956085205,13.024867057800293,13.024970054626465,13.165056228637695,13.165092468261719,14.621964454650879,14.894187927246094,15.86564826965332,15.865677833557129,20.029396057128906,20.26714324951172,20.267480850219727,65.23036193847656,65.4332275390625,70.78983306884766,72.65277099609375,98.24201202392578,98.50687408447266,98.5245361328125],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"margin\":{\"l\":10,\"r\":10,\"b\":25,\"t\":25},\"autosize\":false,\"width\":990,\"height\":300,\"xaxis\":{\"title\":{\"text\":\"Instance\"}},\"yaxis\":{\"title\":{\"text\":\"Euclidian distance\"}}},                        {\"responsive\": true}                    )                };                            </script>        </div>"
      ],
      "text/plain": [
       "Figure({\n",
       "    'data': [{'mode': 'markers',\n",
       "              'type': 'scatter',\n",
       "              'x': [0, 1, 2, ..., 3007, 3008, 3009],\n",
       "              'y': array([2.38227767e-05, 2.39750007e-05, 2.41262642e-05, ..., 9.82420120e+01,\n",
       "                          9.85068741e+01, 9.85245361e+01])}],\n",
       "    'layout': {'autosize': False,\n",
       "               'height': 300,\n",
       "               'margin': {'b': 25, 'l': 10, 'r': 10, 't': 25},\n",
       "               'template': '...',\n",
       "               'width': 990,\n",
       "               'xaxis': {'title': {'text': 'Instance'}},\n",
       "               'yaxis': {'title': {'text': 'Euclidian distance'}}}\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x = list(range(distances_sorted.shape[0])),\n",
    "        y = distances_sorted[:, -1],\n",
    "        mode=\"markers\",\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=990,\n",
    "    height=300,\n",
    "    margin=dict(\n",
    "        l=10,\n",
    "        r=10,\n",
    "        b=25,\n",
    "        t=25,\n",
    "    ),\n",
    "    xaxis_title=\"Instance\",\n",
    "    yaxis_title=\"Euclidian distance\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69aeb1a0-ed29-42fd-a383-db1b9cec649f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.64, min_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1d5d9f9-6edc-4b1a-b64d-fe2ec39934db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscan.fit(feature_arr)\n",
    "dbscan.labels_.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b16201-984a-41a2-b133-90594c029e63",
   "metadata": {},
   "source": [
    "## Comparing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1a956f6-7c0e-4758-b53c-6d03d6871dbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_dict = {f\"Class {i}\": list() for i in range(dbscan.labels_.max() + 1)}\n",
    "class_dict[\"Outliers\"] = list()\n",
    "for index, path in enumerate(simulation_file_paths):\n",
    "    class_ = dbscan.labels_[index]\n",
    "    if class_ == -1:\n",
    "        class_dict[\"Outliers\"].append(str(path))\n",
    "    else:\n",
    "        class_dict[f\"Class {class_}\"].append(str(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a6cd0bd-33cf-4d8b-8040-52e6a4922393",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/paper-2023-machine-learning-based-classification-of-magnetization-main/.venv/lib/python3.11/site-packages/IPython/core/formatters.py:925\u001b[0m, in \u001b[0;36mIPythonDisplayFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    923\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 925\u001b[0m     \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    926\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/paper-2023-machine-learning-based-classification-of-magnetization-main/.venv/lib/python3.11/site-packages/plotly/basedatatypes.py:832\u001b[0m, in \u001b[0;36mBaseFigure._ipython_display_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpio\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pio\u001b[38;5;241m.\u001b[39mrenderers\u001b[38;5;241m.\u001b[39mrender_on_display \u001b[38;5;129;01mand\u001b[39;00m pio\u001b[38;5;241m.\u001b[39mrenderers\u001b[38;5;241m.\u001b[39mdefault:\n\u001b[0;32m--> 832\u001b[0m     \u001b[43mpio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n",
      "File \u001b[0;32m~/paper-2023-machine-learning-based-classification-of-magnetization-main/.venv/lib/python3.11/site-packages/plotly/io/_renderers.py:394\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    390\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m         )\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nbformat \u001b[38;5;129;01mor\u001b[39;00m Version(nbformat\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 394\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    395\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    396\u001b[0m         )\n\u001b[1;32m    398\u001b[0m     ipython_display\u001b[38;5;241m.\u001b[39mdisplay(bundle, raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    400\u001b[0m \u001b[38;5;66;03m# external renderers\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "#2E91E5",
          "size": 11
         },
         "mode": "markers",
         "name": "Class 0",
         "opacity": 0.7,
         "type": "scatter",
         "x": [
          0.6698909203044445,
          0.6698909203044445,
          0.6698909203044445,
          0.6698909203044445,
          0.6698909203044445,
          0.6698909203044445,
          0.6698909203044445,
          0.6699039315395161,
          0.6699039315395161,
          0.6699039315395161,
          0.6699039315395161,
          0.6699039315395161,
          0.6699039315395161,
          0.6699039315395161
         ],
         "y": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ]
        },
        {
         "marker": {
          "color": "#E15F99",
          "size": 11
         },
         "mode": "markers",
         "name": "Class 1",
         "opacity": 0.7,
         "type": "scatter",
         "x": [
          0.55779369174165,
          0.55779369174165,
          0.55779369174165,
          0.55779369174165,
          0.55779369174165,
          0.55779369174165,
          0.55779369174165,
          0.55779369174165
         ],
         "y": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ]
        },
        {
         "marker": {
          "color": "#1CA71C",
          "size": 11
         },
         "mode": "markers",
         "name": "Class 2",
         "opacity": 0.7,
         "type": "scatter",
         "x": [
          0.5823933515367479,
          0.5823933515367479,
          0.5823933515367479,
          0.5823933515367479,
          0.5823933515367479,
          0.5823933515367479,
          0.5823933515367479,
          0.5823933515367479,
          0.5814367798799912,
          0.5814367798799912,
          0.5814367798799912,
          0.5814367798799912,
          0.5814367798799912,
          0.5814367798799912,
          0.5814367798799912,
          0.5814367798799912,
          0.5785806608969681,
          0.5785806608969681,
          0.5785806608969681,
          0.5785806608969681,
          0.5785806608969681,
          0.5785806608969681,
          0.5785806608969681,
          0.5785806608969681,
          0.5851306000927129,
          0.5851306000927129,
          0.5851306000927129,
          0.5851306000927129,
          0.5851306000927129,
          0.5851306000927129,
          0.5851306000927129,
          0.5851306000927129
         ],
         "y": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ]
        },
        {
         "marker": {
          "color": "#FB0D0D",
          "size": 11
         },
         "mode": "markers",
         "name": "Class 3",
         "opacity": 0.7,
         "type": "scatter",
         "x": [
          0.7108584663581602,
          0.7108584663581602,
          0.7108584663581602,
          0.7108584663581602,
          0.7108584663581602,
          0.7108584663581602,
          0.7108584663581602,
          0.7125494922138771,
          0.7125494922138771,
          0.7125494922138771,
          0.7125494922138771,
          0.7125494922138771,
          0.7125494922138771,
          0.7125494922138771,
          0.7140948789521357,
          0.7140948789521357,
          0.7140948789521357,
          0.7140948789521357,
          0.7140948789521357,
          0.7140948789521357,
          0.7140948789521357
         ],
         "y": [
          1.5954744660000286e-19,
          1.5954744660000286e-19,
          1.5954744660000286e-19,
          1.5954744660000286e-19,
          1.5954744660000286e-19,
          1.5954744660000286e-19,
          1.5954744660000286e-19,
          1.6709709300000117e-19,
          1.6709709300000117e-19,
          1.6709709300000117e-19,
          1.6709709300000117e-19,
          1.6709709300000117e-19,
          1.6709709300000117e-19,
          1.6709709300000117e-19,
          1.7398201589999568e-19,
          1.7398201589999568e-19,
          1.7398201589999568e-19,
          1.7398201589999568e-19,
          1.7398201589999568e-19,
          1.7398201589999568e-19,
          1.7398201589999568e-19
         ]
        },
        {
         "marker": {
          "color": "#DA16FF",
          "size": 11
         },
         "mode": "markers",
         "name": "Class 4",
         "opacity": 0.7,
         "type": "scatter",
         "x": [
          0.27819278671534964,
          0.27819278671534964,
          0.27819278671534964,
          0.27819278671534964,
          0.27819278671534964,
          0.27819278671534964,
          0.280929955271993,
          0.280929955271993,
          0.280929955271993,
          0.280929955271993,
          0.280929955271993,
          0.280929955271993,
          0.2794146286864358,
          0.2794146286864358,
          0.2794146286864358,
          0.2794146286864358,
          0.2794146286864358,
          0.2794146286864358,
          0.2780322901650048,
          0.2780322901650048,
          0.2780322901650048,
          0.2780322901650048,
          0.2780322901650048,
          0.2780322901650048,
          0.27785719330458286,
          0.27785719330458286,
          0.27785719330458286,
          0.27785719330458286,
          0.27785719330458286,
          0.27785719330458286,
          0.2797978667076925,
          0.2797978667076925,
          0.2797978667076925,
          0.2797978667076925,
          0.2797978667076925,
          0.2797978667076925
         ],
         "y": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ]
        },
        {
         "marker": {
          "color": "#222A2A",
          "size": 11
         },
         "mode": "markers",
         "name": "Class 5",
         "opacity": 0.7,
         "type": "scatter",
         "x": [
          0.27819278671534964,
          0.27819278671534964,
          0.2780322901650048,
          0.2780322901650048,
          0.27785719330458286,
          0.27785719330458286
         ],
         "y": [
          2.0976509775e-18,
          2.0976509775e-18,
          2.097074522199999e-18,
          2.097074522199999e-18,
          2.0964450875000004e-18,
          2.0964450875000004e-18
         ]
        },
        {
         "marker": {
          "color": "#B68100",
          "size": 11
         },
         "mode": "markers",
         "name": "Class 6",
         "opacity": 0.7,
         "type": "scatter",
         "x": [
          0.27819278671534964,
          0.280929955271993,
          0.2794146286864358,
          0.2780322901650048,
          0.27785719330458286,
          0.2797978667076925
         ],
         "y": [
          5.007640918999985e-19,
          4.979730655e-19,
          4.995117306000009e-19,
          5.00929373600001e-19,
          5.011098965000003e-19,
          4.99121072099999e-19
         ]
        },
        {
         "marker": {
          "color": "#750D86",
          "size": 11
         },
         "mode": "markers",
         "name": "Class 7",
         "opacity": 0.7,
         "type": "scatter",
         "x": [
          0.27819278671534964,
          0.280929955271993,
          0.2794146286864358,
          0.2780322901650048,
          0.27785719330458286,
          0.2797978667076925
         ],
         "y": [
          1.4787812652999993e-18,
          1.4747627033000015e-18,
          1.4770033800000011e-18,
          1.4790128853999986e-18,
          1.479265067700001e-18,
          1.4764404298000002e-18
         ]
        },
        {
         "marker": {
          "color": "#EB663B",
          "size": 11
         },
         "mode": "markers",
         "name": "Class 8",
         "opacity": 0.7,
         "type": "scatter",
         "x": [
          0.21342597313549733,
          0.21342597313549733,
          0.21342597313549733,
          0.21342597313549733,
          0.21342597313549733,
          0.21342597313549733,
          0.21342597313549733
         ],
         "y": [
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ]
        },
        {
         "marker": {
          "color": "#511CFB",
          "size": 11
         },
         "mode": "markers",
         "name": "Class 9",
         "opacity": 0.7,
         "type": "scatter",
         "x": [
          0.6238164836260325,
          0.6238164836260325,
          0.6238164836260325,
          0.6238164836260325,
          0.6238164836260325,
          0.6238164836260325,
          0.6238164836260325,
          0.6238164836260325,
          0.6203451822046695,
          0.6203451822046695,
          0.6203451822046695,
          0.6203451822046695,
          0.6203451822046695,
          0.6203451822046695,
          0.6203451822046695,
          0.6203451822046695,
          0.6218801135687254,
          0.6218801135687254,
          0.6218801135687254,
          0.6218801135687254,
          0.6218801135687254,
          0.6218801135687254,
          0.6218801135687254,
          0.6218801135687254,
          0.6207519568266823,
          0.6207519568266823,
          0.6207519568266823,
          0.6207519568266823,
          0.6207519568266823,
          0.6207519568266823,
          0.6207519568266823,
          0.6207519568266823
         ],
         "y": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ]
        },
        {
         "marker": {
          "color": "#00A08B",
          "size": 11
         },
         "mode": "markers",
         "name": "Class 10",
         "opacity": 0.7,
         "type": "scatter",
         "x": [
          1.0250054051919253,
          1.0250054051919253,
          1.0250054051919253,
          1.0250054051919253,
          1.0250054051919253,
          1.0250054051919253,
          1.0263514491692831,
          1.0269934826491744,
          1.0202856143980115,
          1.0202856143980115,
          1.0202856143980115,
          1.0202856143980115,
          1.0202856143980115,
          1.0202856143980115,
          1.0138643716232256,
          1.0138643716232256,
          1.0138643716232256,
          1.0138643716232256,
          1.0138643716232256,
          1.0138643716232256,
          1.0238498196198644,
          1.005939071376994,
          1.0235853459745574,
          1.0045093174691133,
          1.0282460428447024,
          1.0282460428447024,
          1.0282460428447024,
          1.0282460428447024,
          1.0282460428447024,
          1.0282460428447024,
          1.0236103138012014,
          1.016188363672831,
          1.016188363672831,
          1.016188363672831,
          1.016188363672831,
          1.016188363672831,
          1.016188363672831,
          1.0092104846623406,
          1.0274713182492725,
          1.0274713182492725,
          1.0274713182492725,
          1.0274713182492725,
          1.0274713182492725,
          1.0274713182492725,
          1.0229688740778602,
          1.0273665437929667,
          1.0273665437929667,
          1.0273665437929667,
          1.0273665437929667,
          1.0273665437929667,
          1.0273665437929667,
          1.017422486013861,
          1.017422486013861,
          1.017422486013861,
          1.017422486013861,
          1.017422486013861,
          1.017422486013861
         ],
         "y": [
          1.1637222261999984e-18,
          1.1637222261999984e-18,
          1.1637222261999984e-18,
          1.1637222261999984e-18,
          1.1637222261999984e-18,
          1.1637222261999984e-18,
          1.1663659086999982e-18,
          1.1676229729999993e-18,
          1.1543639775999984e-18,
          1.1543639775999984e-18,
          1.1543639775999984e-18,
          1.1543639775999984e-18,
          1.1543639775999984e-18,
          1.1543639775999984e-18,
          1.1414084479999952e-18,
          1.1414084479999952e-18,
          1.1414084479999952e-18,
          1.1414084479999952e-18,
          1.1414084479999952e-18,
          1.1414084479999952e-18,
          1.1614437178000064e-18,
          1.1250558982000056e-18,
          1.1609210872999995e-18,
          1.1220625241000013e-18,
          1.1700681595999963e-18,
          1.1700681595999963e-18,
          1.1700681595999963e-18,
          1.1700681595999963e-18,
          1.1700681595999963e-18,
          1.1700681595999963e-18,
          1.1609704449999998e-18,
          1.146127385300005e-18,
          1.146127385300005e-18,
          1.146127385300005e-18,
          1.146127385300005e-18,
          1.146127385300005e-18,
          1.146127385300005e-18,
          1.1318549900999972e-18,
          1.1685569105000012e-18,
          1.1685569105000012e-18,
          1.1685569105000012e-18,
          1.1685569105000012e-18,
          1.1685569105000012e-18,
          1.1685569105000012e-18,
          1.1597011884000042e-18,
          1.1683522464999949e-18,
          1.1683522464999949e-18,
          1.1683522464999949e-18,
          1.1683522464999949e-18,
          1.1683522464999949e-18,
          1.1683522464999949e-18,
          1.1486194154999892e-18,
          1.1486194154999892e-18,
          1.1486194154999892e-18,
          1.1486194154999892e-18,
          1.1486194154999892e-18,
          1.1486194154999892e-18
         ]
        },
        {
         "marker": {
          "color": "#FB00D1",
          "size": 11
         },
         "mode": "markers",
         "name": "Class 11",
         "opacity": 0.7,
         "type": "scatter",
         "x": [
          1.0250054051919253,
          1.0250054051919253,
          1.0202856143980115,
          1.0202856143980115,
          1.0138643716232256,
          1.0138643716232256,
          1.0282460428447024,
          1.0282460428447024,
          1.016188363672831,
          1.016188363672831,
          1.0274713182492725,
          1.0274713182492725,
          1.0273665437929667,
          1.0273665437929667,
          1.017422486013861,
          1.017422486013861
         ],
         "y": [
          6.428819245599994e-18,
          6.428819245599994e-18,
          6.39803315e-18,
          6.39803315e-18,
          6.3556923965e-18,
          6.3556923965e-18,
          6.4497925722000005e-18,
          6.4497925722000005e-18,
          6.371077221800001e-18,
          6.371077221800001e-18,
          6.444790761899994e-18,
          6.444790761899994e-18,
          6.444113724599996e-18,
          6.444113724599996e-18,
          6.379219093899989e-18,
          6.379219093899989e-18
         ]
        },
        {
         "marker": {
          "color": "#FC0080",
          "size": 11
         },
         "mode": "markers",
         "name": "Class 12",
         "opacity": 0.7,
         "type": "scatter",
         "x": [
          1.0250054051919253,
          1.0202856143980115,
          1.0282460428447024,
          1.0274713182492725,
          1.0273665437929667
         ],
         "y": [
          2.4052888850999946e-18,
          2.388963853699996e-18,
          2.416381296099992e-18,
          2.4137380708999967e-18,
          2.413380185000005e-18
         ]
        },
        {
         "marker": {
          "color": "#B2828D",
          "size": 11
         },
         "mode": "markers",
         "name": "Class 13",
         "opacity": 0.7,
         "type": "scatter",
         "x": [
          1.0250054051919253,
          0.9646048372886914,
          0.9808002518152286,
          1.0263514491692831,
          0.9864011704620863,
          1.0269934826491744,
          1.0202856143980115,
          1.0138643716232256,
          0.9545452567039938,
          1.0019658059640772,
          0.9934355497864474,
          0.9748296910160761,
          0.9817613249810861,
          1.0238498196198644,
          0.9698279207025753,
          0.9713599753359391,
          1.005939071376994,
          0.9641370033042524,
          1.0235853459745574,
          0.9581704014515433,
          1.0045093174691133,
          0.9935376695424457,
          0.9742161584909454,
          0.9898962581019028,
          1.0282460428447024,
          0.9981815390658192,
          1.0236103138012014,
          0.9953320671441747,
          0.9951803409357836,
          1.035969243607655,
          0.9861663886355949,
          1.016188363672831,
          1.0092104846623406,
          0.9952270358071662,
          0.9586195626295599,
          1.0356299817446473,
          1.0274713182492725,
          0.9813592490631781,
          0.9965448251651002,
          0.9553442344939065,
          1.0229688740778602,
          0.9488281907779279,
          1.0273665437929667,
          0.9691994577359738,
          1.017422486013861
         ],
         "y": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ]
        },
        {
         "marker": {
          "color": "#6C7C32",
          "size": 11
         },
         "mode": "markers",
         "name": "Class 14",
         "opacity": 0.7,
         "type": "scatter",
         "x": [
          0.6516358443230307,
          0.6516358443230307,
          0.6516358443230307,
          0.6516358443230307,
          0.6516358443230307,
          0.6516358443230307,
          0.6516358443230307,
          0.6516358443230307,
          0.6597066901473676,
          0.6597066901473676,
          0.6597066901473676,
          0.6597066901473676,
          0.6597066901473676,
          0.6597066901473676,
          0.6597066901473676,
          0.657065121899311,
          0.657065121899311,
          0.657065121899311,
          0.657065121899311,
          0.657065121899311,
          0.657065121899311,
          0.657065121899311,
          0.6570880888695172,
          0.6570880888695172,
          0.6570880888695172,
          0.6570880888695172,
          0.6570880888695172,
          0.6570880888695172,
          0.6570880888695172,
          0.6519406712010998,
          0.6519406712010998,
          0.6519406712010998,
          0.6519406712010998,
          0.6519406712010998,
          0.6519406712010998,
          0.6519406712010998,
          0.6519406712010998,
          0.6488495684507151,
          0.6488495684507151,
          0.6488495684507151,
          0.6488495684507151,
          0.6488495684507151,
          0.6488495684507151,
          0.6488495684507151,
          0.6488495684507151,
          0.6486426687537004,
          0.6486426687537004,
          0.6486426687537004,
          0.6486426687537004,
          0.6486426687537004,
          0.6486426687537004,
          0.6486426687537004,
          0.6486426687537004,
          0.6587923843405451,
          0.6587923843405451,
          0.6587923843405451,
          0.6587923843405451,
          0.6587923843405451,
          0.6587923843405451,
          0.6587923843405451,
          0.6594397013397775,
          0.6594397013397775,
          0.6594397013397775,
          0.6594397013397775,
          0.6594397013397775,
          0.6594397013397775,
          0.6594397013397775,
          0.6546227281234838,
          0.6546227281234838,
          0.6546227281234838,
          0.6546227281234838,
          0.6546227281234838,
          0.6546227281234838,
          0.6546227281234838,
          0.6546227281234838
         ],
         "y": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ]
        },
        {
         "marker": {
          "color": "#778AAE",
          "size": 11
         },
         "mode": "markers",
         "name": "Class 15",
         "opacity": 0.7,
         "type": "scatter",
         "x": [
          0.6516358443230307,
          0.6597066901473676,
          0.657065121899311,
          0.6570880888695172,
          0.6519406712010998,
          0.6488495684507151,
          0.6486426687537004,
          0.6587923843405451,
          0.6594397013397775,
          0.6546227281234838
         ],
         "y": [
          5.997239247000024e-19,
          6.116449411000012e-19,
          6.07709588500001e-19,
          6.077436646e-19,
          6.001685661000004e-19,
          5.956804409000002e-19,
          5.953816866999983e-19,
          6.102791717999984e-19,
          6.112457209999993e-19,
          6.040999254999959e-19
         ]
        },
        {
         "marker": {
          "color": "#862A16",
          "size": 11
         },
         "mode": "markers",
         "name": "Class 16",
         "opacity": 0.7,
         "type": "scatter",
         "x": [
          0.10404936148175352,
          0.10404936148175352,
          0.10862032555585044,
          0.10862032555585044,
          0.10628000491945659,
          0.10628000491945659,
          0.10282549835843335,
          0.10282549835843335,
          0.104560520146578,
          0.104560520146578
         ],
         "y": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ]
        },
        {
         "marker": {
          "color": "#A777F1",
          "size": 11
         },
         "mode": "markers",
         "name": "Class 17",
         "opacity": 0.7,
         "type": "scatter",
         "x": [
          0.10404936148175352,
          0.10628000491945659,
          0.10282549835843335,
          0.10282549835843335,
          0.104560520146578
         ],
         "y": [
          4.662922290000003e-19,
          4.740104345999992e-19,
          4.620557874000015e-19,
          4.620557874000015e-19,
          4.680612645999995e-19
         ]
        },
        {
         "marker": {
          "color": "#620042",
          "size": 11
         },
         "mode": "markers",
         "name": "Class 18",
         "opacity": 0.7,
         "type": "scatter",
         "x": [
          0.10404936148175352,
          0.10404936148175352,
          0.10404936148175352,
          0.10628000491945659,
          0.10628000491945659,
          0.10628000491945659,
          0.10282549835843335,
          0.10282549835843335,
          0.10282549835843335,
          0.104560520146578,
          0.104560520146578,
          0.104560520146578
         ],
         "y": [
          3.578805318499999e-18,
          3.578805318499999e-18,
          3.578805318499999e-18,
          3.629275993799999e-18,
          3.629275993799999e-18,
          3.629275993799999e-18,
          3.551109412300001e-18,
          3.551109412300001e-18,
          3.551109412300001e-18,
          3.590371861e-18,
          3.590371861e-18,
          3.590371861e-18
         ]
        },
        {
         "marker": {
          "color": "#1616A7",
          "size": 11
         },
         "mode": "markers",
         "name": "Class 19",
         "opacity": 0.7,
         "type": "scatter",
         "x": [
          0.10404936148175352,
          0.10404936148175352,
          0.10862032555585044,
          0.10862032555585044,
          0.10628000491945659,
          0.10628000491945659,
          0.10282549835843335,
          0.104560520146578,
          0.104560520146578
         ],
         "y": [
          8.931615961000003e-19,
          8.931615961000003e-19,
          9.254756024999998e-19,
          9.254756024999998e-19,
          9.089289329999998e-19,
          9.089289329999998e-19,
          8.845125361000001e-19,
          8.967743599999991e-19,
          8.967743599999991e-19
         ]
        },
        {
         "marker": {
          "color": "#DA60CA",
          "size": 11
         },
         "mode": "markers",
         "name": "Class 20",
         "opacity": 0.7,
         "type": "scatter",
         "x": [
          0.12314500844208708,
          0.12314500844208708,
          0.1200051235924728,
          0.1200051235924728,
          0.12152269818476434,
          0.12152269818476434,
          0.12024626663464288,
          0.12024626663464288,
          0.12282567902694742,
          0.12282567902694742
         ],
         "y": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ]
        },
        {
         "marker": {
          "color": "#6C4516",
          "size": 11
         },
         "mode": "markers",
         "name": "Class 21",
         "opacity": 0.7,
         "type": "scatter",
         "x": [
          0.12314500844208708,
          0.12314500844208708,
          0.12314500844208708,
          0.1200051235924728,
          0.1200051235924728,
          0.1200051235924728,
          0.12152269818476434,
          0.12152269818476434,
          0.12152269818476434,
          0.12024626663464288,
          0.12024626663464288,
          0.12024626663464288,
          0.12282567902694742,
          0.12282567902694742,
          0.12282567902694742
         ],
         "y": [
          4.0102519944000025e-18,
          4.0102519944000025e-18,
          4.0102519944000025e-18,
          3.939432427099998e-18,
          3.939432427099998e-18,
          3.939432427099998e-18,
          3.9736688873e-18,
          3.9736688873e-18,
          3.9736688873e-18,
          3.944873550400001e-18,
          3.944873550400001e-18,
          3.944873550400001e-18,
          4.003052486799999e-18,
          4.003052486799999e-18,
          4.003052486799999e-18
         ]
        },
        {
         "marker": {
          "color": "#0D2A63",
          "size": 11
         },
         "mode": "markers",
         "name": "Class 22",
         "opacity": 0.7,
         "type": "scatter",
         "x": [
          0.12314500844208708,
          0.12314500844208708,
          0.1200051235924728,
          0.1200051235924728,
          0.12152269818476434,
          0.12152269818476434,
          0.12024626663464288,
          0.12024626663464288,
          0.12282567902694742,
          0.12282567902694742
         ],
         "y": [
          1.0281957872000015e-18,
          1.0281957872000015e-18,
          1.0059955242000005e-18,
          1.0059955242000005e-18,
          1.0167265328000001e-18,
          1.0167265328000001e-18,
          1.0077008012000006e-18,
          1.0077008012000006e-18,
          1.0259384502000004e-18,
          1.0259384502000004e-18
         ]
        },
        {
         "marker": {
          "color": "#AF0038",
          "size": 11
         },
         "mode": "markers",
         "name": "Class 23",
         "opacity": 0.7,
         "type": "scatter",
         "x": [
          1.0520917899467686,
          1.0520917899467686,
          1.0520917899467686,
          1.0520917899467686,
          1.0520917899467686,
          1.0520917899467686,
          1.051788883420381,
          1.0505179873860966,
          1.0505179873860966,
          1.0505179873860966,
          1.0505179873860966,
          1.0505179873860966,
          1.0505179873860966,
          1.0515676079188805,
          1.0515676079188805,
          1.0515676079188805,
          1.0515676079188805,
          1.0515676079188805,
          1.0515676079188805,
          1.0526020064240975,
          1.0539468285340443,
          1.0521215565114765,
          1.0465188935411227,
          1.0465188935411227,
          1.0465188935411227,
          1.0465188935411227,
          1.0465188935411227,
          1.0465188935411227,
          1.0518182900141038,
          1.0469586493867697,
          1.0469586493867697,
          1.0469586493867697,
          1.0469586493867697,
          1.0469586493867697,
          1.0469586493867697,
          1.0485608360241712,
          1.0485608360241712,
          1.0485608360241712,
          1.0485608360241712,
          1.0485608360241712,
          1.0485608360241712,
          1.0544923781969306
         ],
         "y": [
          1.2148364558000085e-18,
          1.2148364558000085e-18,
          1.2148364558000085e-18,
          1.2148364558000085e-18,
          1.2148364558000085e-18,
          1.2148364558000085e-18,
          1.2142884794000052e-18,
          1.2119836753999996e-18,
          1.2119836753999996e-18,
          1.2119836753999996e-18,
          1.2119836753999996e-18,
          1.2119836753999996e-18,
          1.2119836753999996e-18,
          1.2138878497000071e-18,
          1.2138878497000071e-18,
          1.2138878497000071e-18,
          1.2138878497000071e-18,
          1.2138878497000071e-18,
          1.2138878497000071e-18,
          1.2157582940999994e-18,
          1.2181810161999985e-18,
          1.214890277299997e-18,
          1.2046710714000021e-18,
          1.2046710714000021e-18,
          1.2046710714000021e-18,
          1.2046710714000021e-18,
          1.2046710714000021e-18,
          1.2046710714000021e-18,
          1.2143417004999926e-18,
          1.2054796825000017e-18,
          1.2054796825000017e-18,
          1.2054796825000017e-18,
          1.2054796825000017e-18,
          1.2054796825000017e-18,
          1.2054796825000017e-18,
          1.2084163384000002e-18,
          1.2084163384000002e-18,
          1.2084163384000002e-18,
          1.2084163384000002e-18,
          1.2084163384000002e-18,
          1.2084163384000002e-18,
          1.2191609278000074e-18
         ]
        }
       ],
       "layout": {
        "autosize": false,
        "height": 600,
        "margin": {
         "b": 25,
         "l": 10,
         "r": 10,
         "t": 25
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 990,
        "xaxis": {
         "title": {
          "text": "$\\mu_0 \\mathbf{H} \\text{ (T)}$"
         }
        },
        "yaxis": {
         "title": {
          "text": "$\\Delta \\text{E (J)}$"
         }
        }
       }
      },
      "text/html": [
       "<div>                        <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.29.1.min.js\"></script>                <div id=\"80e7fa53-528f-454e-bd80-c2d38cc48e98\" class=\"plotly-graph-div\" style=\"height:600px; width:990px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"80e7fa53-528f-454e-bd80-c2d38cc48e98\")) {                    Plotly.newPlot(                        \"80e7fa53-528f-454e-bd80-c2d38cc48e98\",                        [{\"marker\":{\"color\":\"#2E91E5\",\"size\":11},\"mode\":\"markers\",\"name\":\"Class 0\",\"opacity\":0.7,\"x\":[0.6698909203044445,0.6698909203044445,0.6698909203044445,0.6698909203044445,0.6698909203044445,0.6698909203044445,0.6698909203044445,0.6699039315395161,0.6699039315395161,0.6699039315395161,0.6699039315395161,0.6699039315395161,0.6699039315395161,0.6699039315395161],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#E15F99\",\"size\":11},\"mode\":\"markers\",\"name\":\"Class 1\",\"opacity\":0.7,\"x\":[0.55779369174165,0.55779369174165,0.55779369174165,0.55779369174165,0.55779369174165,0.55779369174165,0.55779369174165,0.55779369174165],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#1CA71C\",\"size\":11},\"mode\":\"markers\",\"name\":\"Class 2\",\"opacity\":0.7,\"x\":[0.5823933515367479,0.5823933515367479,0.5823933515367479,0.5823933515367479,0.5823933515367479,0.5823933515367479,0.5823933515367479,0.5823933515367479,0.5814367798799912,0.5814367798799912,0.5814367798799912,0.5814367798799912,0.5814367798799912,0.5814367798799912,0.5814367798799912,0.5814367798799912,0.5785806608969681,0.5785806608969681,0.5785806608969681,0.5785806608969681,0.5785806608969681,0.5785806608969681,0.5785806608969681,0.5785806608969681,0.5851306000927129,0.5851306000927129,0.5851306000927129,0.5851306000927129,0.5851306000927129,0.5851306000927129,0.5851306000927129,0.5851306000927129],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#FB0D0D\",\"size\":11},\"mode\":\"markers\",\"name\":\"Class 3\",\"opacity\":0.7,\"x\":[0.7108584663581602,0.7108584663581602,0.7108584663581602,0.7108584663581602,0.7108584663581602,0.7108584663581602,0.7108584663581602,0.7125494922138771,0.7125494922138771,0.7125494922138771,0.7125494922138771,0.7125494922138771,0.7125494922138771,0.7125494922138771,0.7140948789521357,0.7140948789521357,0.7140948789521357,0.7140948789521357,0.7140948789521357,0.7140948789521357,0.7140948789521357],\"y\":[1.5954744660000286e-19,1.5954744660000286e-19,1.5954744660000286e-19,1.5954744660000286e-19,1.5954744660000286e-19,1.5954744660000286e-19,1.5954744660000286e-19,1.6709709300000117e-19,1.6709709300000117e-19,1.6709709300000117e-19,1.6709709300000117e-19,1.6709709300000117e-19,1.6709709300000117e-19,1.6709709300000117e-19,1.7398201589999568e-19,1.7398201589999568e-19,1.7398201589999568e-19,1.7398201589999568e-19,1.7398201589999568e-19,1.7398201589999568e-19,1.7398201589999568e-19],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#DA16FF\",\"size\":11},\"mode\":\"markers\",\"name\":\"Class 4\",\"opacity\":0.7,\"x\":[0.27819278671534964,0.27819278671534964,0.27819278671534964,0.27819278671534964,0.27819278671534964,0.27819278671534964,0.280929955271993,0.280929955271993,0.280929955271993,0.280929955271993,0.280929955271993,0.280929955271993,0.2794146286864358,0.2794146286864358,0.2794146286864358,0.2794146286864358,0.2794146286864358,0.2794146286864358,0.2780322901650048,0.2780322901650048,0.2780322901650048,0.2780322901650048,0.2780322901650048,0.2780322901650048,0.27785719330458286,0.27785719330458286,0.27785719330458286,0.27785719330458286,0.27785719330458286,0.27785719330458286,0.2797978667076925,0.2797978667076925,0.2797978667076925,0.2797978667076925,0.2797978667076925,0.2797978667076925],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#222A2A\",\"size\":11},\"mode\":\"markers\",\"name\":\"Class 5\",\"opacity\":0.7,\"x\":[0.27819278671534964,0.27819278671534964,0.2780322901650048,0.2780322901650048,0.27785719330458286,0.27785719330458286],\"y\":[2.0976509775e-18,2.0976509775e-18,2.097074522199999e-18,2.097074522199999e-18,2.0964450875000004e-18,2.0964450875000004e-18],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#B68100\",\"size\":11},\"mode\":\"markers\",\"name\":\"Class 6\",\"opacity\":0.7,\"x\":[0.27819278671534964,0.280929955271993,0.2794146286864358,0.2780322901650048,0.27785719330458286,0.2797978667076925],\"y\":[5.007640918999985e-19,4.979730655e-19,4.995117306000009e-19,5.00929373600001e-19,5.011098965000003e-19,4.99121072099999e-19],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#750D86\",\"size\":11},\"mode\":\"markers\",\"name\":\"Class 7\",\"opacity\":0.7,\"x\":[0.27819278671534964,0.280929955271993,0.2794146286864358,0.2780322901650048,0.27785719330458286,0.2797978667076925],\"y\":[1.4787812652999993e-18,1.4747627033000015e-18,1.4770033800000011e-18,1.4790128853999986e-18,1.479265067700001e-18,1.4764404298000002e-18],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#EB663B\",\"size\":11},\"mode\":\"markers\",\"name\":\"Class 8\",\"opacity\":0.7,\"x\":[0.21342597313549733,0.21342597313549733,0.21342597313549733,0.21342597313549733,0.21342597313549733,0.21342597313549733,0.21342597313549733],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#511CFB\",\"size\":11},\"mode\":\"markers\",\"name\":\"Class 9\",\"opacity\":0.7,\"x\":[0.6238164836260325,0.6238164836260325,0.6238164836260325,0.6238164836260325,0.6238164836260325,0.6238164836260325,0.6238164836260325,0.6238164836260325,0.6203451822046695,0.6203451822046695,0.6203451822046695,0.6203451822046695,0.6203451822046695,0.6203451822046695,0.6203451822046695,0.6203451822046695,0.6218801135687254,0.6218801135687254,0.6218801135687254,0.6218801135687254,0.6218801135687254,0.6218801135687254,0.6218801135687254,0.6218801135687254,0.6207519568266823,0.6207519568266823,0.6207519568266823,0.6207519568266823,0.6207519568266823,0.6207519568266823,0.6207519568266823,0.6207519568266823],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#00A08B\",\"size\":11},\"mode\":\"markers\",\"name\":\"Class 10\",\"opacity\":0.7,\"x\":[1.0250054051919253,1.0250054051919253,1.0250054051919253,1.0250054051919253,1.0250054051919253,1.0250054051919253,1.0263514491692831,1.0269934826491744,1.0202856143980115,1.0202856143980115,1.0202856143980115,1.0202856143980115,1.0202856143980115,1.0202856143980115,1.0138643716232256,1.0138643716232256,1.0138643716232256,1.0138643716232256,1.0138643716232256,1.0138643716232256,1.0238498196198644,1.005939071376994,1.0235853459745574,1.0045093174691133,1.0282460428447024,1.0282460428447024,1.0282460428447024,1.0282460428447024,1.0282460428447024,1.0282460428447024,1.0236103138012014,1.016188363672831,1.016188363672831,1.016188363672831,1.016188363672831,1.016188363672831,1.016188363672831,1.0092104846623406,1.0274713182492725,1.0274713182492725,1.0274713182492725,1.0274713182492725,1.0274713182492725,1.0274713182492725,1.0229688740778602,1.0273665437929667,1.0273665437929667,1.0273665437929667,1.0273665437929667,1.0273665437929667,1.0273665437929667,1.017422486013861,1.017422486013861,1.017422486013861,1.017422486013861,1.017422486013861,1.017422486013861],\"y\":[1.1637222261999984e-18,1.1637222261999984e-18,1.1637222261999984e-18,1.1637222261999984e-18,1.1637222261999984e-18,1.1637222261999984e-18,1.1663659086999982e-18,1.1676229729999993e-18,1.1543639775999984e-18,1.1543639775999984e-18,1.1543639775999984e-18,1.1543639775999984e-18,1.1543639775999984e-18,1.1543639775999984e-18,1.1414084479999952e-18,1.1414084479999952e-18,1.1414084479999952e-18,1.1414084479999952e-18,1.1414084479999952e-18,1.1414084479999952e-18,1.1614437178000064e-18,1.1250558982000056e-18,1.1609210872999995e-18,1.1220625241000013e-18,1.1700681595999963e-18,1.1700681595999963e-18,1.1700681595999963e-18,1.1700681595999963e-18,1.1700681595999963e-18,1.1700681595999963e-18,1.1609704449999998e-18,1.146127385300005e-18,1.146127385300005e-18,1.146127385300005e-18,1.146127385300005e-18,1.146127385300005e-18,1.146127385300005e-18,1.1318549900999972e-18,1.1685569105000012e-18,1.1685569105000012e-18,1.1685569105000012e-18,1.1685569105000012e-18,1.1685569105000012e-18,1.1685569105000012e-18,1.1597011884000042e-18,1.1683522464999949e-18,1.1683522464999949e-18,1.1683522464999949e-18,1.1683522464999949e-18,1.1683522464999949e-18,1.1683522464999949e-18,1.1486194154999892e-18,1.1486194154999892e-18,1.1486194154999892e-18,1.1486194154999892e-18,1.1486194154999892e-18,1.1486194154999892e-18],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#FB00D1\",\"size\":11},\"mode\":\"markers\",\"name\":\"Class 11\",\"opacity\":0.7,\"x\":[1.0250054051919253,1.0250054051919253,1.0202856143980115,1.0202856143980115,1.0138643716232256,1.0138643716232256,1.0282460428447024,1.0282460428447024,1.016188363672831,1.016188363672831,1.0274713182492725,1.0274713182492725,1.0273665437929667,1.0273665437929667,1.017422486013861,1.017422486013861],\"y\":[6.428819245599994e-18,6.428819245599994e-18,6.39803315e-18,6.39803315e-18,6.3556923965e-18,6.3556923965e-18,6.4497925722000005e-18,6.4497925722000005e-18,6.371077221800001e-18,6.371077221800001e-18,6.444790761899994e-18,6.444790761899994e-18,6.444113724599996e-18,6.444113724599996e-18,6.379219093899989e-18,6.379219093899989e-18],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#FC0080\",\"size\":11},\"mode\":\"markers\",\"name\":\"Class 12\",\"opacity\":0.7,\"x\":[1.0250054051919253,1.0202856143980115,1.0282460428447024,1.0274713182492725,1.0273665437929667],\"y\":[2.4052888850999946e-18,2.388963853699996e-18,2.416381296099992e-18,2.4137380708999967e-18,2.413380185000005e-18],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#B2828D\",\"size\":11},\"mode\":\"markers\",\"name\":\"Class 13\",\"opacity\":0.7,\"x\":[1.0250054051919253,0.9646048372886914,0.9808002518152286,1.0263514491692831,0.9864011704620863,1.0269934826491744,1.0202856143980115,1.0138643716232256,0.9545452567039938,1.0019658059640772,0.9934355497864474,0.9748296910160761,0.9817613249810861,1.0238498196198644,0.9698279207025753,0.9713599753359391,1.005939071376994,0.9641370033042524,1.0235853459745574,0.9581704014515433,1.0045093174691133,0.9935376695424457,0.9742161584909454,0.9898962581019028,1.0282460428447024,0.9981815390658192,1.0236103138012014,0.9953320671441747,0.9951803409357836,1.035969243607655,0.9861663886355949,1.016188363672831,1.0092104846623406,0.9952270358071662,0.9586195626295599,1.0356299817446473,1.0274713182492725,0.9813592490631781,0.9965448251651002,0.9553442344939065,1.0229688740778602,0.9488281907779279,1.0273665437929667,0.9691994577359738,1.017422486013861],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#6C7C32\",\"size\":11},\"mode\":\"markers\",\"name\":\"Class 14\",\"opacity\":0.7,\"x\":[0.6516358443230307,0.6516358443230307,0.6516358443230307,0.6516358443230307,0.6516358443230307,0.6516358443230307,0.6516358443230307,0.6516358443230307,0.6597066901473676,0.6597066901473676,0.6597066901473676,0.6597066901473676,0.6597066901473676,0.6597066901473676,0.6597066901473676,0.657065121899311,0.657065121899311,0.657065121899311,0.657065121899311,0.657065121899311,0.657065121899311,0.657065121899311,0.6570880888695172,0.6570880888695172,0.6570880888695172,0.6570880888695172,0.6570880888695172,0.6570880888695172,0.6570880888695172,0.6519406712010998,0.6519406712010998,0.6519406712010998,0.6519406712010998,0.6519406712010998,0.6519406712010998,0.6519406712010998,0.6519406712010998,0.6488495684507151,0.6488495684507151,0.6488495684507151,0.6488495684507151,0.6488495684507151,0.6488495684507151,0.6488495684507151,0.6488495684507151,0.6486426687537004,0.6486426687537004,0.6486426687537004,0.6486426687537004,0.6486426687537004,0.6486426687537004,0.6486426687537004,0.6486426687537004,0.6587923843405451,0.6587923843405451,0.6587923843405451,0.6587923843405451,0.6587923843405451,0.6587923843405451,0.6587923843405451,0.6594397013397775,0.6594397013397775,0.6594397013397775,0.6594397013397775,0.6594397013397775,0.6594397013397775,0.6594397013397775,0.6546227281234838,0.6546227281234838,0.6546227281234838,0.6546227281234838,0.6546227281234838,0.6546227281234838,0.6546227281234838,0.6546227281234838],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#778AAE\",\"size\":11},\"mode\":\"markers\",\"name\":\"Class 15\",\"opacity\":0.7,\"x\":[0.6516358443230307,0.6597066901473676,0.657065121899311,0.6570880888695172,0.6519406712010998,0.6488495684507151,0.6486426687537004,0.6587923843405451,0.6594397013397775,0.6546227281234838],\"y\":[5.997239247000024e-19,6.116449411000012e-19,6.07709588500001e-19,6.077436646e-19,6.001685661000004e-19,5.956804409000002e-19,5.953816866999983e-19,6.102791717999984e-19,6.112457209999993e-19,6.040999254999959e-19],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#862A16\",\"size\":11},\"mode\":\"markers\",\"name\":\"Class 16\",\"opacity\":0.7,\"x\":[0.10404936148175352,0.10404936148175352,0.10862032555585044,0.10862032555585044,0.10628000491945659,0.10628000491945659,0.10282549835843335,0.10282549835843335,0.104560520146578,0.104560520146578],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#A777F1\",\"size\":11},\"mode\":\"markers\",\"name\":\"Class 17\",\"opacity\":0.7,\"x\":[0.10404936148175352,0.10628000491945659,0.10282549835843335,0.10282549835843335,0.104560520146578],\"y\":[4.662922290000003e-19,4.740104345999992e-19,4.620557874000015e-19,4.620557874000015e-19,4.680612645999995e-19],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#620042\",\"size\":11},\"mode\":\"markers\",\"name\":\"Class 18\",\"opacity\":0.7,\"x\":[0.10404936148175352,0.10404936148175352,0.10404936148175352,0.10628000491945659,0.10628000491945659,0.10628000491945659,0.10282549835843335,0.10282549835843335,0.10282549835843335,0.104560520146578,0.104560520146578,0.104560520146578],\"y\":[3.578805318499999e-18,3.578805318499999e-18,3.578805318499999e-18,3.629275993799999e-18,3.629275993799999e-18,3.629275993799999e-18,3.551109412300001e-18,3.551109412300001e-18,3.551109412300001e-18,3.590371861e-18,3.590371861e-18,3.590371861e-18],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#1616A7\",\"size\":11},\"mode\":\"markers\",\"name\":\"Class 19\",\"opacity\":0.7,\"x\":[0.10404936148175352,0.10404936148175352,0.10862032555585044,0.10862032555585044,0.10628000491945659,0.10628000491945659,0.10282549835843335,0.104560520146578,0.104560520146578],\"y\":[8.931615961000003e-19,8.931615961000003e-19,9.254756024999998e-19,9.254756024999998e-19,9.089289329999998e-19,9.089289329999998e-19,8.845125361000001e-19,8.967743599999991e-19,8.967743599999991e-19],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#DA60CA\",\"size\":11},\"mode\":\"markers\",\"name\":\"Class 20\",\"opacity\":0.7,\"x\":[0.12314500844208708,0.12314500844208708,0.1200051235924728,0.1200051235924728,0.12152269818476434,0.12152269818476434,0.12024626663464288,0.12024626663464288,0.12282567902694742,0.12282567902694742],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#6C4516\",\"size\":11},\"mode\":\"markers\",\"name\":\"Class 21\",\"opacity\":0.7,\"x\":[0.12314500844208708,0.12314500844208708,0.12314500844208708,0.1200051235924728,0.1200051235924728,0.1200051235924728,0.12152269818476434,0.12152269818476434,0.12152269818476434,0.12024626663464288,0.12024626663464288,0.12024626663464288,0.12282567902694742,0.12282567902694742,0.12282567902694742],\"y\":[4.0102519944000025e-18,4.0102519944000025e-18,4.0102519944000025e-18,3.939432427099998e-18,3.939432427099998e-18,3.939432427099998e-18,3.9736688873e-18,3.9736688873e-18,3.9736688873e-18,3.944873550400001e-18,3.944873550400001e-18,3.944873550400001e-18,4.003052486799999e-18,4.003052486799999e-18,4.003052486799999e-18],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#0D2A63\",\"size\":11},\"mode\":\"markers\",\"name\":\"Class 22\",\"opacity\":0.7,\"x\":[0.12314500844208708,0.12314500844208708,0.1200051235924728,0.1200051235924728,0.12152269818476434,0.12152269818476434,0.12024626663464288,0.12024626663464288,0.12282567902694742,0.12282567902694742],\"y\":[1.0281957872000015e-18,1.0281957872000015e-18,1.0059955242000005e-18,1.0059955242000005e-18,1.0167265328000001e-18,1.0167265328000001e-18,1.0077008012000006e-18,1.0077008012000006e-18,1.0259384502000004e-18,1.0259384502000004e-18],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#AF0038\",\"size\":11},\"mode\":\"markers\",\"name\":\"Class 23\",\"opacity\":0.7,\"x\":[1.0520917899467686,1.0520917899467686,1.0520917899467686,1.0520917899467686,1.0520917899467686,1.0520917899467686,1.051788883420381,1.0505179873860966,1.0505179873860966,1.0505179873860966,1.0505179873860966,1.0505179873860966,1.0505179873860966,1.0515676079188805,1.0515676079188805,1.0515676079188805,1.0515676079188805,1.0515676079188805,1.0515676079188805,1.0526020064240975,1.0539468285340443,1.0521215565114765,1.0465188935411227,1.0465188935411227,1.0465188935411227,1.0465188935411227,1.0465188935411227,1.0465188935411227,1.0518182900141038,1.0469586493867697,1.0469586493867697,1.0469586493867697,1.0469586493867697,1.0469586493867697,1.0469586493867697,1.0485608360241712,1.0485608360241712,1.0485608360241712,1.0485608360241712,1.0485608360241712,1.0485608360241712,1.0544923781969306],\"y\":[1.2148364558000085e-18,1.2148364558000085e-18,1.2148364558000085e-18,1.2148364558000085e-18,1.2148364558000085e-18,1.2148364558000085e-18,1.2142884794000052e-18,1.2119836753999996e-18,1.2119836753999996e-18,1.2119836753999996e-18,1.2119836753999996e-18,1.2119836753999996e-18,1.2119836753999996e-18,1.2138878497000071e-18,1.2138878497000071e-18,1.2138878497000071e-18,1.2138878497000071e-18,1.2138878497000071e-18,1.2138878497000071e-18,1.2157582940999994e-18,1.2181810161999985e-18,1.214890277299997e-18,1.2046710714000021e-18,1.2046710714000021e-18,1.2046710714000021e-18,1.2046710714000021e-18,1.2046710714000021e-18,1.2046710714000021e-18,1.2143417004999926e-18,1.2054796825000017e-18,1.2054796825000017e-18,1.2054796825000017e-18,1.2054796825000017e-18,1.2054796825000017e-18,1.2054796825000017e-18,1.2084163384000002e-18,1.2084163384000002e-18,1.2084163384000002e-18,1.2084163384000002e-18,1.2084163384000002e-18,1.2084163384000002e-18,1.2191609278000074e-18],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"margin\":{\"l\":10,\"r\":10,\"b\":25,\"t\":25},\"autosize\":false,\"width\":990,\"height\":600,\"xaxis\":{\"title\":{\"text\":\"$\\\\mu_0 \\\\mathbf{H} \\\\text{ (T)}$\"}},\"yaxis\":{\"title\":{\"text\":\"$\\\\Delta \\\\text{E (J)}$\"}}},                        {\"responsive\": true}                    )                };                            </script>        </div>"
      ],
      "text/plain": [
       "Figure({\n",
       "    'data': [{'marker': {'color': '#2E91E5', 'size': 11},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Class 0',\n",
       "              'opacity': 0.7,\n",
       "              'type': 'scatter',\n",
       "              'x': [0.6698909203044445, 0.6698909203044445, 0.6698909203044445,\n",
       "                    0.6698909203044445, 0.6698909203044445, 0.6698909203044445,\n",
       "                    0.6698909203044445, 0.6699039315395161, 0.6699039315395161,\n",
       "                    0.6699039315395161, 0.6699039315395161, 0.6699039315395161,\n",
       "                    0.6699039315395161, 0.6699039315395161],\n",
       "              'y': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0]},\n",
       "             {'marker': {'color': '#E15F99', 'size': 11},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Class 1',\n",
       "              'opacity': 0.7,\n",
       "              'type': 'scatter',\n",
       "              'x': [0.55779369174165, 0.55779369174165, 0.55779369174165,\n",
       "                    0.55779369174165, 0.55779369174165, 0.55779369174165,\n",
       "                    0.55779369174165, 0.55779369174165],\n",
       "              'y': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]},\n",
       "             {'marker': {'color': '#1CA71C', 'size': 11},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Class 2',\n",
       "              'opacity': 0.7,\n",
       "              'type': 'scatter',\n",
       "              'x': [0.5823933515367479, 0.5823933515367479, 0.5823933515367479,\n",
       "                    0.5823933515367479, 0.5823933515367479, 0.5823933515367479,\n",
       "                    0.5823933515367479, 0.5823933515367479, 0.5814367798799912,\n",
       "                    0.5814367798799912, 0.5814367798799912, 0.5814367798799912,\n",
       "                    0.5814367798799912, 0.5814367798799912, 0.5814367798799912,\n",
       "                    0.5814367798799912, 0.5785806608969681, 0.5785806608969681,\n",
       "                    0.5785806608969681, 0.5785806608969681, 0.5785806608969681,\n",
       "                    0.5785806608969681, 0.5785806608969681, 0.5785806608969681,\n",
       "                    0.5851306000927129, 0.5851306000927129, 0.5851306000927129,\n",
       "                    0.5851306000927129, 0.5851306000927129, 0.5851306000927129,\n",
       "                    0.5851306000927129, 0.5851306000927129],\n",
       "              'y': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]},\n",
       "             {'marker': {'color': '#FB0D0D', 'size': 11},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Class 3',\n",
       "              'opacity': 0.7,\n",
       "              'type': 'scatter',\n",
       "              'x': [0.7108584663581602, 0.7108584663581602, 0.7108584663581602,\n",
       "                    0.7108584663581602, 0.7108584663581602, 0.7108584663581602,\n",
       "                    0.7108584663581602, 0.7125494922138771, 0.7125494922138771,\n",
       "                    0.7125494922138771, 0.7125494922138771, 0.7125494922138771,\n",
       "                    0.7125494922138771, 0.7125494922138771, 0.7140948789521357,\n",
       "                    0.7140948789521357, 0.7140948789521357, 0.7140948789521357,\n",
       "                    0.7140948789521357, 0.7140948789521357, 0.7140948789521357],\n",
       "              'y': [1.5954744660000286e-19, 1.5954744660000286e-19,\n",
       "                    1.5954744660000286e-19, 1.5954744660000286e-19,\n",
       "                    1.5954744660000286e-19, 1.5954744660000286e-19,\n",
       "                    1.5954744660000286e-19, 1.6709709300000117e-19,\n",
       "                    1.6709709300000117e-19, 1.6709709300000117e-19,\n",
       "                    1.6709709300000117e-19, 1.6709709300000117e-19,\n",
       "                    1.6709709300000117e-19, 1.6709709300000117e-19,\n",
       "                    1.7398201589999568e-19, 1.7398201589999568e-19,\n",
       "                    1.7398201589999568e-19, 1.7398201589999568e-19,\n",
       "                    1.7398201589999568e-19, 1.7398201589999568e-19,\n",
       "                    1.7398201589999568e-19]},\n",
       "             {'marker': {'color': '#DA16FF', 'size': 11},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Class 4',\n",
       "              'opacity': 0.7,\n",
       "              'type': 'scatter',\n",
       "              'x': [0.27819278671534964, 0.27819278671534964, 0.27819278671534964,\n",
       "                    0.27819278671534964, 0.27819278671534964, 0.27819278671534964,\n",
       "                    0.280929955271993, 0.280929955271993, 0.280929955271993,\n",
       "                    0.280929955271993, 0.280929955271993, 0.280929955271993,\n",
       "                    0.2794146286864358, 0.2794146286864358, 0.2794146286864358,\n",
       "                    0.2794146286864358, 0.2794146286864358, 0.2794146286864358,\n",
       "                    0.2780322901650048, 0.2780322901650048, 0.2780322901650048,\n",
       "                    0.2780322901650048, 0.2780322901650048, 0.2780322901650048,\n",
       "                    0.27785719330458286, 0.27785719330458286, 0.27785719330458286,\n",
       "                    0.27785719330458286, 0.27785719330458286, 0.27785719330458286,\n",
       "                    0.2797978667076925, 0.2797978667076925, 0.2797978667076925,\n",
       "                    0.2797978667076925, 0.2797978667076925, 0.2797978667076925],\n",
       "              'y': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]},\n",
       "             {'marker': {'color': '#222A2A', 'size': 11},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Class 5',\n",
       "              'opacity': 0.7,\n",
       "              'type': 'scatter',\n",
       "              'x': [0.27819278671534964, 0.27819278671534964, 0.2780322901650048,\n",
       "                    0.2780322901650048, 0.27785719330458286, 0.27785719330458286],\n",
       "              'y': [2.0976509775e-18, 2.0976509775e-18, 2.097074522199999e-18,\n",
       "                    2.097074522199999e-18, 2.0964450875000004e-18,\n",
       "                    2.0964450875000004e-18]},\n",
       "             {'marker': {'color': '#B68100', 'size': 11},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Class 6',\n",
       "              'opacity': 0.7,\n",
       "              'type': 'scatter',\n",
       "              'x': [0.27819278671534964, 0.280929955271993, 0.2794146286864358,\n",
       "                    0.2780322901650048, 0.27785719330458286, 0.2797978667076925],\n",
       "              'y': [5.007640918999985e-19, 4.979730655e-19, 4.995117306000009e-19,\n",
       "                    5.00929373600001e-19, 5.011098965000003e-19,\n",
       "                    4.99121072099999e-19]},\n",
       "             {'marker': {'color': '#750D86', 'size': 11},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Class 7',\n",
       "              'opacity': 0.7,\n",
       "              'type': 'scatter',\n",
       "              'x': [0.27819278671534964, 0.280929955271993, 0.2794146286864358,\n",
       "                    0.2780322901650048, 0.27785719330458286, 0.2797978667076925],\n",
       "              'y': [1.4787812652999993e-18, 1.4747627033000015e-18,\n",
       "                    1.4770033800000011e-18, 1.4790128853999986e-18,\n",
       "                    1.479265067700001e-18, 1.4764404298000002e-18]},\n",
       "             {'marker': {'color': '#EB663B', 'size': 11},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Class 8',\n",
       "              'opacity': 0.7,\n",
       "              'type': 'scatter',\n",
       "              'x': [0.21342597313549733, 0.21342597313549733, 0.21342597313549733,\n",
       "                    0.21342597313549733, 0.21342597313549733, 0.21342597313549733,\n",
       "                    0.21342597313549733],\n",
       "              'y': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]},\n",
       "             {'marker': {'color': '#511CFB', 'size': 11},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Class 9',\n",
       "              'opacity': 0.7,\n",
       "              'type': 'scatter',\n",
       "              'x': [0.6238164836260325, 0.6238164836260325, 0.6238164836260325,\n",
       "                    0.6238164836260325, 0.6238164836260325, 0.6238164836260325,\n",
       "                    0.6238164836260325, 0.6238164836260325, 0.6203451822046695,\n",
       "                    0.6203451822046695, 0.6203451822046695, 0.6203451822046695,\n",
       "                    0.6203451822046695, 0.6203451822046695, 0.6203451822046695,\n",
       "                    0.6203451822046695, 0.6218801135687254, 0.6218801135687254,\n",
       "                    0.6218801135687254, 0.6218801135687254, 0.6218801135687254,\n",
       "                    0.6218801135687254, 0.6218801135687254, 0.6218801135687254,\n",
       "                    0.6207519568266823, 0.6207519568266823, 0.6207519568266823,\n",
       "                    0.6207519568266823, 0.6207519568266823, 0.6207519568266823,\n",
       "                    0.6207519568266823, 0.6207519568266823],\n",
       "              'y': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]},\n",
       "             {'marker': {'color': '#00A08B', 'size': 11},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Class 10',\n",
       "              'opacity': 0.7,\n",
       "              'type': 'scatter',\n",
       "              'x': [1.0250054051919253, 1.0250054051919253, 1.0250054051919253,\n",
       "                    1.0250054051919253, 1.0250054051919253, 1.0250054051919253,\n",
       "                    1.0263514491692831, 1.0269934826491744, 1.0202856143980115,\n",
       "                    1.0202856143980115, 1.0202856143980115, 1.0202856143980115,\n",
       "                    1.0202856143980115, 1.0202856143980115, 1.0138643716232256,\n",
       "                    1.0138643716232256, 1.0138643716232256, 1.0138643716232256,\n",
       "                    1.0138643716232256, 1.0138643716232256, 1.0238498196198644,\n",
       "                    1.005939071376994, 1.0235853459745574, 1.0045093174691133,\n",
       "                    1.0282460428447024, 1.0282460428447024, 1.0282460428447024,\n",
       "                    1.0282460428447024, 1.0282460428447024, 1.0282460428447024,\n",
       "                    1.0236103138012014, 1.016188363672831, 1.016188363672831,\n",
       "                    1.016188363672831, 1.016188363672831, 1.016188363672831,\n",
       "                    1.016188363672831, 1.0092104846623406, 1.0274713182492725,\n",
       "                    1.0274713182492725, 1.0274713182492725, 1.0274713182492725,\n",
       "                    1.0274713182492725, 1.0274713182492725, 1.0229688740778602,\n",
       "                    1.0273665437929667, 1.0273665437929667, 1.0273665437929667,\n",
       "                    1.0273665437929667, 1.0273665437929667, 1.0273665437929667,\n",
       "                    1.017422486013861, 1.017422486013861, 1.017422486013861,\n",
       "                    1.017422486013861, 1.017422486013861, 1.017422486013861],\n",
       "              'y': [1.1637222261999984e-18, 1.1637222261999984e-18,\n",
       "                    1.1637222261999984e-18, 1.1637222261999984e-18,\n",
       "                    1.1637222261999984e-18, 1.1637222261999984e-18,\n",
       "                    1.1663659086999982e-18, 1.1676229729999993e-18,\n",
       "                    1.1543639775999984e-18, 1.1543639775999984e-18,\n",
       "                    1.1543639775999984e-18, 1.1543639775999984e-18,\n",
       "                    1.1543639775999984e-18, 1.1543639775999984e-18,\n",
       "                    1.1414084479999952e-18, 1.1414084479999952e-18,\n",
       "                    1.1414084479999952e-18, 1.1414084479999952e-18,\n",
       "                    1.1414084479999952e-18, 1.1414084479999952e-18,\n",
       "                    1.1614437178000064e-18, 1.1250558982000056e-18,\n",
       "                    1.1609210872999995e-18, 1.1220625241000013e-18,\n",
       "                    1.1700681595999963e-18, 1.1700681595999963e-18,\n",
       "                    1.1700681595999963e-18, 1.1700681595999963e-18,\n",
       "                    1.1700681595999963e-18, 1.1700681595999963e-18,\n",
       "                    1.1609704449999998e-18, 1.146127385300005e-18,\n",
       "                    1.146127385300005e-18, 1.146127385300005e-18,\n",
       "                    1.146127385300005e-18, 1.146127385300005e-18,\n",
       "                    1.146127385300005e-18, 1.1318549900999972e-18,\n",
       "                    1.1685569105000012e-18, 1.1685569105000012e-18,\n",
       "                    1.1685569105000012e-18, 1.1685569105000012e-18,\n",
       "                    1.1685569105000012e-18, 1.1685569105000012e-18,\n",
       "                    1.1597011884000042e-18, 1.1683522464999949e-18,\n",
       "                    1.1683522464999949e-18, 1.1683522464999949e-18,\n",
       "                    1.1683522464999949e-18, 1.1683522464999949e-18,\n",
       "                    1.1683522464999949e-18, 1.1486194154999892e-18,\n",
       "                    1.1486194154999892e-18, 1.1486194154999892e-18,\n",
       "                    1.1486194154999892e-18, 1.1486194154999892e-18,\n",
       "                    1.1486194154999892e-18]},\n",
       "             {'marker': {'color': '#FB00D1', 'size': 11},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Class 11',\n",
       "              'opacity': 0.7,\n",
       "              'type': 'scatter',\n",
       "              'x': [1.0250054051919253, 1.0250054051919253, 1.0202856143980115,\n",
       "                    1.0202856143980115, 1.0138643716232256, 1.0138643716232256,\n",
       "                    1.0282460428447024, 1.0282460428447024, 1.016188363672831,\n",
       "                    1.016188363672831, 1.0274713182492725, 1.0274713182492725,\n",
       "                    1.0273665437929667, 1.0273665437929667, 1.017422486013861,\n",
       "                    1.017422486013861],\n",
       "              'y': [6.428819245599994e-18, 6.428819245599994e-18, 6.39803315e-18,\n",
       "                    6.39803315e-18, 6.3556923965e-18, 6.3556923965e-18,\n",
       "                    6.4497925722000005e-18, 6.4497925722000005e-18,\n",
       "                    6.371077221800001e-18, 6.371077221800001e-18,\n",
       "                    6.444790761899994e-18, 6.444790761899994e-18,\n",
       "                    6.444113724599996e-18, 6.444113724599996e-18,\n",
       "                    6.379219093899989e-18, 6.379219093899989e-18]},\n",
       "             {'marker': {'color': '#FC0080', 'size': 11},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Class 12',\n",
       "              'opacity': 0.7,\n",
       "              'type': 'scatter',\n",
       "              'x': [1.0250054051919253, 1.0202856143980115, 1.0282460428447024,\n",
       "                    1.0274713182492725, 1.0273665437929667],\n",
       "              'y': [2.4052888850999946e-18, 2.388963853699996e-18,\n",
       "                    2.416381296099992e-18, 2.4137380708999967e-18,\n",
       "                    2.413380185000005e-18]},\n",
       "             {'marker': {'color': '#B2828D', 'size': 11},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Class 13',\n",
       "              'opacity': 0.7,\n",
       "              'type': 'scatter',\n",
       "              'x': [1.0250054051919253, 0.9646048372886914, 0.9808002518152286,\n",
       "                    1.0263514491692831, 0.9864011704620863, 1.0269934826491744,\n",
       "                    1.0202856143980115, 1.0138643716232256, 0.9545452567039938,\n",
       "                    1.0019658059640772, 0.9934355497864474, 0.9748296910160761,\n",
       "                    0.9817613249810861, 1.0238498196198644, 0.9698279207025753,\n",
       "                    0.9713599753359391, 1.005939071376994, 0.9641370033042524,\n",
       "                    1.0235853459745574, 0.9581704014515433, 1.0045093174691133,\n",
       "                    0.9935376695424457, 0.9742161584909454, 0.9898962581019028,\n",
       "                    1.0282460428447024, 0.9981815390658192, 1.0236103138012014,\n",
       "                    0.9953320671441747, 0.9951803409357836, 1.035969243607655,\n",
       "                    0.9861663886355949, 1.016188363672831, 1.0092104846623406,\n",
       "                    0.9952270358071662, 0.9586195626295599, 1.0356299817446473,\n",
       "                    1.0274713182492725, 0.9813592490631781, 0.9965448251651002,\n",
       "                    0.9553442344939065, 1.0229688740778602, 0.9488281907779279,\n",
       "                    1.0273665437929667, 0.9691994577359738, 1.017422486013861],\n",
       "              'y': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]},\n",
       "             {'marker': {'color': '#6C7C32', 'size': 11},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Class 14',\n",
       "              'opacity': 0.7,\n",
       "              'type': 'scatter',\n",
       "              'x': [0.6516358443230307, 0.6516358443230307, 0.6516358443230307,\n",
       "                    0.6516358443230307, 0.6516358443230307, 0.6516358443230307,\n",
       "                    0.6516358443230307, 0.6516358443230307, 0.6597066901473676,\n",
       "                    0.6597066901473676, 0.6597066901473676, 0.6597066901473676,\n",
       "                    0.6597066901473676, 0.6597066901473676, 0.6597066901473676,\n",
       "                    0.657065121899311, 0.657065121899311, 0.657065121899311,\n",
       "                    0.657065121899311, 0.657065121899311, 0.657065121899311,\n",
       "                    0.657065121899311, 0.6570880888695172, 0.6570880888695172,\n",
       "                    0.6570880888695172, 0.6570880888695172, 0.6570880888695172,\n",
       "                    0.6570880888695172, 0.6570880888695172, 0.6519406712010998,\n",
       "                    0.6519406712010998, 0.6519406712010998, 0.6519406712010998,\n",
       "                    0.6519406712010998, 0.6519406712010998, 0.6519406712010998,\n",
       "                    0.6519406712010998, 0.6488495684507151, 0.6488495684507151,\n",
       "                    0.6488495684507151, 0.6488495684507151, 0.6488495684507151,\n",
       "                    0.6488495684507151, 0.6488495684507151, 0.6488495684507151,\n",
       "                    0.6486426687537004, 0.6486426687537004, 0.6486426687537004,\n",
       "                    0.6486426687537004, 0.6486426687537004, 0.6486426687537004,\n",
       "                    0.6486426687537004, 0.6486426687537004, 0.6587923843405451,\n",
       "                    0.6587923843405451, 0.6587923843405451, 0.6587923843405451,\n",
       "                    0.6587923843405451, 0.6587923843405451, 0.6587923843405451,\n",
       "                    0.6594397013397775, 0.6594397013397775, 0.6594397013397775,\n",
       "                    0.6594397013397775, 0.6594397013397775, 0.6594397013397775,\n",
       "                    0.6594397013397775, 0.6546227281234838, 0.6546227281234838,\n",
       "                    0.6546227281234838, 0.6546227281234838, 0.6546227281234838,\n",
       "                    0.6546227281234838, 0.6546227281234838, 0.6546227281234838],\n",
       "              'y': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0]},\n",
       "             {'marker': {'color': '#778AAE', 'size': 11},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Class 15',\n",
       "              'opacity': 0.7,\n",
       "              'type': 'scatter',\n",
       "              'x': [0.6516358443230307, 0.6597066901473676, 0.657065121899311,\n",
       "                    0.6570880888695172, 0.6519406712010998, 0.6488495684507151,\n",
       "                    0.6486426687537004, 0.6587923843405451, 0.6594397013397775,\n",
       "                    0.6546227281234838],\n",
       "              'y': [5.997239247000024e-19, 6.116449411000012e-19,\n",
       "                    6.07709588500001e-19, 6.077436646e-19, 6.001685661000004e-19,\n",
       "                    5.956804409000002e-19, 5.953816866999983e-19,\n",
       "                    6.102791717999984e-19, 6.112457209999993e-19,\n",
       "                    6.040999254999959e-19]},\n",
       "             {'marker': {'color': '#862A16', 'size': 11},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Class 16',\n",
       "              'opacity': 0.7,\n",
       "              'type': 'scatter',\n",
       "              'x': [0.10404936148175352, 0.10404936148175352, 0.10862032555585044,\n",
       "                    0.10862032555585044, 0.10628000491945659, 0.10628000491945659,\n",
       "                    0.10282549835843335, 0.10282549835843335, 0.104560520146578,\n",
       "                    0.104560520146578],\n",
       "              'y': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]},\n",
       "             {'marker': {'color': '#A777F1', 'size': 11},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Class 17',\n",
       "              'opacity': 0.7,\n",
       "              'type': 'scatter',\n",
       "              'x': [0.10404936148175352, 0.10628000491945659, 0.10282549835843335,\n",
       "                    0.10282549835843335, 0.104560520146578],\n",
       "              'y': [4.662922290000003e-19, 4.740104345999992e-19,\n",
       "                    4.620557874000015e-19, 4.620557874000015e-19,\n",
       "                    4.680612645999995e-19]},\n",
       "             {'marker': {'color': '#620042', 'size': 11},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Class 18',\n",
       "              'opacity': 0.7,\n",
       "              'type': 'scatter',\n",
       "              'x': [0.10404936148175352, 0.10404936148175352, 0.10404936148175352,\n",
       "                    0.10628000491945659, 0.10628000491945659, 0.10628000491945659,\n",
       "                    0.10282549835843335, 0.10282549835843335, 0.10282549835843335,\n",
       "                    0.104560520146578, 0.104560520146578, 0.104560520146578],\n",
       "              'y': [3.578805318499999e-18, 3.578805318499999e-18,\n",
       "                    3.578805318499999e-18, 3.629275993799999e-18,\n",
       "                    3.629275993799999e-18, 3.629275993799999e-18,\n",
       "                    3.551109412300001e-18, 3.551109412300001e-18,\n",
       "                    3.551109412300001e-18, 3.590371861e-18, 3.590371861e-18,\n",
       "                    3.590371861e-18]},\n",
       "             {'marker': {'color': '#1616A7', 'size': 11},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Class 19',\n",
       "              'opacity': 0.7,\n",
       "              'type': 'scatter',\n",
       "              'x': [0.10404936148175352, 0.10404936148175352, 0.10862032555585044,\n",
       "                    0.10862032555585044, 0.10628000491945659, 0.10628000491945659,\n",
       "                    0.10282549835843335, 0.104560520146578, 0.104560520146578],\n",
       "              'y': [8.931615961000003e-19, 8.931615961000003e-19,\n",
       "                    9.254756024999998e-19, 9.254756024999998e-19,\n",
       "                    9.089289329999998e-19, 9.089289329999998e-19,\n",
       "                    8.845125361000001e-19, 8.967743599999991e-19,\n",
       "                    8.967743599999991e-19]},\n",
       "             {'marker': {'color': '#DA60CA', 'size': 11},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Class 20',\n",
       "              'opacity': 0.7,\n",
       "              'type': 'scatter',\n",
       "              'x': [0.12314500844208708, 0.12314500844208708, 0.1200051235924728,\n",
       "                    0.1200051235924728, 0.12152269818476434, 0.12152269818476434,\n",
       "                    0.12024626663464288, 0.12024626663464288, 0.12282567902694742,\n",
       "                    0.12282567902694742],\n",
       "              'y': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]},\n",
       "             {'marker': {'color': '#6C4516', 'size': 11},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Class 21',\n",
       "              'opacity': 0.7,\n",
       "              'type': 'scatter',\n",
       "              'x': [0.12314500844208708, 0.12314500844208708, 0.12314500844208708,\n",
       "                    0.1200051235924728, 0.1200051235924728, 0.1200051235924728,\n",
       "                    0.12152269818476434, 0.12152269818476434, 0.12152269818476434,\n",
       "                    0.12024626663464288, 0.12024626663464288, 0.12024626663464288,\n",
       "                    0.12282567902694742, 0.12282567902694742, 0.12282567902694742],\n",
       "              'y': [4.0102519944000025e-18, 4.0102519944000025e-18,\n",
       "                    4.0102519944000025e-18, 3.939432427099998e-18,\n",
       "                    3.939432427099998e-18, 3.939432427099998e-18, 3.9736688873e-18,\n",
       "                    3.9736688873e-18, 3.9736688873e-18, 3.944873550400001e-18,\n",
       "                    3.944873550400001e-18, 3.944873550400001e-18,\n",
       "                    4.003052486799999e-18, 4.003052486799999e-18,\n",
       "                    4.003052486799999e-18]},\n",
       "             {'marker': {'color': '#0D2A63', 'size': 11},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Class 22',\n",
       "              'opacity': 0.7,\n",
       "              'type': 'scatter',\n",
       "              'x': [0.12314500844208708, 0.12314500844208708, 0.1200051235924728,\n",
       "                    0.1200051235924728, 0.12152269818476434, 0.12152269818476434,\n",
       "                    0.12024626663464288, 0.12024626663464288, 0.12282567902694742,\n",
       "                    0.12282567902694742],\n",
       "              'y': [1.0281957872000015e-18, 1.0281957872000015e-18,\n",
       "                    1.0059955242000005e-18, 1.0059955242000005e-18,\n",
       "                    1.0167265328000001e-18, 1.0167265328000001e-18,\n",
       "                    1.0077008012000006e-18, 1.0077008012000006e-18,\n",
       "                    1.0259384502000004e-18, 1.0259384502000004e-18]},\n",
       "             {'marker': {'color': '#AF0038', 'size': 11},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Class 23',\n",
       "              'opacity': 0.7,\n",
       "              'type': 'scatter',\n",
       "              'x': [1.0520917899467686, 1.0520917899467686, 1.0520917899467686,\n",
       "                    1.0520917899467686, 1.0520917899467686, 1.0520917899467686,\n",
       "                    1.051788883420381, 1.0505179873860966, 1.0505179873860966,\n",
       "                    1.0505179873860966, 1.0505179873860966, 1.0505179873860966,\n",
       "                    1.0505179873860966, 1.0515676079188805, 1.0515676079188805,\n",
       "                    1.0515676079188805, 1.0515676079188805, 1.0515676079188805,\n",
       "                    1.0515676079188805, 1.0526020064240975, 1.0539468285340443,\n",
       "                    1.0521215565114765, 1.0465188935411227, 1.0465188935411227,\n",
       "                    1.0465188935411227, 1.0465188935411227, 1.0465188935411227,\n",
       "                    1.0465188935411227, 1.0518182900141038, 1.0469586493867697,\n",
       "                    1.0469586493867697, 1.0469586493867697, 1.0469586493867697,\n",
       "                    1.0469586493867697, 1.0469586493867697, 1.0485608360241712,\n",
       "                    1.0485608360241712, 1.0485608360241712, 1.0485608360241712,\n",
       "                    1.0485608360241712, 1.0485608360241712, 1.0544923781969306],\n",
       "              'y': [1.2148364558000085e-18, 1.2148364558000085e-18,\n",
       "                    1.2148364558000085e-18, 1.2148364558000085e-18,\n",
       "                    1.2148364558000085e-18, 1.2148364558000085e-18,\n",
       "                    1.2142884794000052e-18, 1.2119836753999996e-18,\n",
       "                    1.2119836753999996e-18, 1.2119836753999996e-18,\n",
       "                    1.2119836753999996e-18, 1.2119836753999996e-18,\n",
       "                    1.2119836753999996e-18, 1.2138878497000071e-18,\n",
       "                    1.2138878497000071e-18, 1.2138878497000071e-18,\n",
       "                    1.2138878497000071e-18, 1.2138878497000071e-18,\n",
       "                    1.2138878497000071e-18, 1.2157582940999994e-18,\n",
       "                    1.2181810161999985e-18, 1.214890277299997e-18,\n",
       "                    1.2046710714000021e-18, 1.2046710714000021e-18,\n",
       "                    1.2046710714000021e-18, 1.2046710714000021e-18,\n",
       "                    1.2046710714000021e-18, 1.2046710714000021e-18,\n",
       "                    1.2143417004999926e-18, 1.2054796825000017e-18,\n",
       "                    1.2054796825000017e-18, 1.2054796825000017e-18,\n",
       "                    1.2054796825000017e-18, 1.2054796825000017e-18,\n",
       "                    1.2054796825000017e-18, 1.2084163384000002e-18,\n",
       "                    1.2084163384000002e-18, 1.2084163384000002e-18,\n",
       "                    1.2084163384000002e-18, 1.2084163384000002e-18,\n",
       "                    1.2084163384000002e-18, 1.2191609278000074e-18]}],\n",
       "    'layout': {'autosize': False,\n",
       "               'height': 600,\n",
       "               'margin': {'b': 25, 'l': 10, 'r': 10, 't': 25},\n",
       "               'template': '...',\n",
       "               'width': 990,\n",
       "               'xaxis': {'title': {'text': '$\\\\mu_0 \\\\mathbf{H} \\\\text{ (T)}$'}},\n",
       "               'yaxis': {'title': {'text': '$\\\\Delta \\\\text{E (J)}$'}}}\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.graph_objs as go\n",
    "import plotly.express as ptx\n",
    "\n",
    "\n",
    "traces = list()\n",
    "for class_id, colour in zip(class_dict, ptx.colors.qualitative.Dark24):\n",
    "    traces.append(\n",
    "        go.Scatter(\n",
    "            x=[\n",
    "                parameters_dict[f][\"H\"]\n",
    "                for f in class_dict[class_id]\n",
    "            ],\n",
    "            y=[\n",
    "                parameters_dict[f][\"E\"]\n",
    "                for f in class_dict[class_id]\n",
    "            ],\n",
    "            mode=\"markers\",\n",
    "            name=class_id,\n",
    "            opacity=0.7,\n",
    "            marker=dict(\n",
    "                size=11,\n",
    "                color=colour,\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig = go.Figure(data=traces)\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=990,\n",
    "    height=600,\n",
    "    margin=dict(\n",
    "        l=10,\n",
    "        r=10,\n",
    "        b=25,\n",
    "        t=25,\n",
    "    ),\n",
    "    xaxis_title=r\"$\\mu_0 \\mathbf{H} \\text{ (T)}$\",\n",
    "    yaxis_title=r\"$\\Delta \\text{E (J)}$\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bd71ed-f4d5-4ad4-bb74-d3af9197cdb0",
   "metadata": {},
   "source": [
    "![Published results](images/phase-paper.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
